# Introduction
Human speech perception is now understood to be highly adaptive. Listeners' interpretation of acoustic input can change within minutes of exposure to an unfamiliar talker, improving recognition accuracy [@bradlow2008perceptual; @clarke2004rapid; @xie2018rapid; @xie2021cross]. One of mechanisms thought to underlie this rapid adaptivity is distributional learning [@clayards2008; @idemaru-hold2011; @kleinschmidt-jaeger2015; @davis-sohoglu2020]. This hypothesis has gained considerable influence over the past decade, with findings that changes in listener perception are qualitatively predicted by statistics of exposure stimuli [@bejjanki2011; @clayards2008; @idemaru2021; @kleinschmidt2012; @kleinschmidt-jaeger2015cogsci; @munson2011-thesis; @nixon2016; @theodore2019distributional; @schertz-clare2019; @tan2021; for important caveats, see @harmon2018]. 

<!-- TO DO: find fMRI paper that claims to have rejected kleinschmidt-jaeger15 [wrongly], published somewhere around 2018-2020 -->

We investigate an important constraints on this type of adaptivity that is suggested by recent findings. @kleinschmidt-jaeger2016 exposed L1 US English listeners to over 200 recordings of /b/-/p/ minimal pair words like *beach* and *peach*. In English, the primary cue to this stop voicing contrast is voice onset timing (VOT), with /b/s having shorter VOTs (mean = XXX msecs) than /p/s (mean = XXX msecs). Kleinschmidt and Jaeger exposed separate groups of listeners to VOT distributions for which these category means had been shifted by XXX, XXX, ..., or XXX msecs. In line with the distributional learning hypothesis, listeners' category boundary or point of subjective equality (PSEs)---i.e., the VOT for which listeners are equally likely to respond "d" and "t"---shifted in the same direction as the exposure distribution. Also in line with the distributional learning hypothesis, these shifts were larger the further the exposure distributions were shifted. <!-- perhaps replotting the figure from kj16 might help here? --> However, Kleinschmidt and Jaeger also observed a previously undocumented property of these adaptive changes: shifts in the exposure distribution had less than proportional (sublinear) effect on shifts in PSE. While this finding---recently replicated in one more experiment [@kleinschmidt2020, Experiment 4]---<!-- TO DO: is this correct: did K's final experiment replicate 'shrinkage'?-->is compatible with the hypothesis of distributional learning, it points to important not well-understood constraints on adaptive speech perception. 

For example, the only distributional learning model that has been more extensively tested against adaptive speech perception---incremental Bayesian belief-updating [@kleinschmidt-jaeger2011]---predicts proportional, rather than sublinear, shifts (for proof, see SI \@ref(sec:ibbu-proof)). This model had previously been found to closely predict the cumulative effects of exposure in perceptual recalibration to audio-visually [@kleinschmidt2011-jaeger; @kleinschmidt-jaeger2012] or lexically labeled speech [@cummings2023], as well as the type of exposure to unlabelled minimal pair words employed by Kleinschmidt and Jaeger [@theodore-monto2019]. However, all of these studies employed comparatively smaller changes in cue distributions, and lacked the design necessary to detect deviation from proportionality (we return to this point below). The findings presented in @kleinschmidt-jaeger2016 would seem to reject this specific distributional learning model [though not necessarily the theory it is derived from, @kleinschmidt-jaeger2015; for discussion of the relation between theory and model, see also @kleinschmidt2020; for a recent discussion of the importance of strongly predictive computational models, see @martin-XXX2021]  <!-- TO DO: make sure we do --> Similarly, existing models of perceptual normalization---an alternative, but mutually compatible, hypothesis---also predict proportional changes in PSE (SI \@ref(sec:ibbu-proof)). <!-- TO DO: write these sections for SI. along a single continuum normalization shift of cue mean just shifts cat function. for multi-dimensional cues, the same is true under cue integration models (variance and thus weighting does not change; shift along each dimension follows same logic as for single cue). for multi-dimensional multivariate models with interacting cues viewed from the perspective of a single cue, shifts can *appear* non-proportional but the pattern observed in KJ16---non proportionality without changes in slopes---would seem to be impossible to create as long as the test stimuli form a line in the multidimensional cue space -->

One possib

Xie and colleagues [-@xie2018, p. 229] distinguish between two types of mechanisms that might underlie representational changes, <!--- link representational change and distributional learning --> *model learning* and *model selection*. The former refers to the learning of a new category representations---for example, learning a new generative model for the talker [@kleinschmidt-jaeger2015, Part II] or storage of new talker-specific exemplars [@sumner2011]. @xie2018 hypothesize that this process might be much slower than is often assumed in the literature, potentially requiring multiple days of exposure and memory consolidation during sleep [see also @fenn2013; @tamminen2012; @xie2018sleep]. Rapid adaptation that occurs within minutes of exposure might instead be achieved by selecting between *existing* talker-specific representations that were learned from previous speech input---e.g., previously learned talker-specific generative models [see mixture model in @kleinschmidt-jaeger2015, p. 180-181] or previously stored exemplars from other talkers [@johnson1997]. Model learning and model selection both offer explanations for the sublinear effects observed in @kleinschmidt-jaeger2016. But they suggest different predictions for the evolution of this effect over the course of exposure.

Under the hypothesis of model learning, sublinear shifts in PSEs can be explained by assuming a hierarchical prior over talker-specific generative models [$p(\Theta)$ in @kleinschmidt-jaeger2015, p. 180]. This prior would 'shrink' adaptation towards listeners' priors---similar to the effect of random by-subject or by-item effects in generalized linear mixed-effect models, which shrink group-level effect estimates towards the population mean of the data [@bates]. Critically, as long as these priors attribute non-zero probability to even extreme shifts (e.g., the type of Gaussian prior used in mixed-effects models), this predicts listeners' PSEs will continue to change with increasing exposure until they have converged against the PSE that is ideal for the exposure statistics. In contrast, the hypothesis of model selection predicts that rapid adaptation is more strongly constrained by previous experience: listeners can only adapt their categorisation functions up to a point that corresponds to (a mixture of) previously experienced talker-specific generative models.


 

Contrastive tests against alternative hypotheses remain lacking [@xie2023]. This is at least in part due to often informal and vague 




- THE AIM OF THIS STUDY-
The study we report here builds on the pioneering work of @clayards2008 and @kleinschmidt-jaeger2016 with the aim to shed more light on how listeners' initial interpretation of cues from a novel talker incrementally change as they receive progressively more informative input of her cue-to-category mappings.


POINTS-TO-MAKE


  - The strength of these beliefs has bearing on listener propensity to adapt to a new talker -- the stronger the prior beliefs the longer it takes to adapt. Listeners' strengths in prior beliefs about the means and variances are represented by parameters in the computational model. Listener behaviour observed collectively, thus far which speaks to this framework of thinking should by now be able to indicate roughly what those parameter values are. But it looks like those parameters are biased by the length of exposure and the outcome during experiments. No one has confronted this issue of very quick but limited adaptation which can't be solved by giving more exposure trials. 
  - How do we distinguish the results from normalization accounts which can also explain adaptation but is not usually regarded as learning? + will discuss constrain under other hypotheses


A secondary aim of the present study was to *begin* to address possible concerns about ecological validity in research on distributional learning. The pioneering works that inspired the present study employed highly unnatural sounding stimuli that were clearly identifiable as robotic speech [@clayards2008; @kleinschmidt-jaeger2016]. These studies also followed the majority of research on distributional learning in language [e.g., @maye2003; @pajak2012] and *designed* rather than *sampled* the exposure distributions. As a consequence, exposure distributions in these experiments tend to be symmetrically balanced around the category means---unlike in everyday speech input. Indeed, all of the works we follow here further used categories with *identical* variances [e.g., identical variance along VOT for /b/ and /p/, @clayards2008; @kleinschmidt-jaeger2016; or /g/ and /k/, @theodore-monto2019]. This, too, is highly atypical for everyday speech input [@chodroff2017structure; @lisker-abrahamson1964]. We take modest steps to improve the ecological validity of our stimuli [building on @nixon2016; @theodore-monto2019], and exposure distributions. 

All data and code for this article can be downloaded from [XXX](OSF). <!-- TO DO: fill in URL --> The article is written in R markdown, allowing readers to replicate our analyses with the press of a button using freely available software [R, @R; @RStudio], while changing any of the parameters of our models (see SI, \@ref(sec:software)). 
