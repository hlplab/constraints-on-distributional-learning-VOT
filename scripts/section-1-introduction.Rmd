# Introduction
Human speech perception is now understood to be highly adaptive. Listeners' interpretation of acoustic input can change within minutes of exposure to an unfamiliar talker, improving recognition accuracy [@bradlow2008perceptual; @clarke2004rapid; @xie2018rapid; @xie2021cross]. One of mechanisms thought to underlie this rapid adaptivity is distributional learning [@clayards2008; @idemaru-hold2011; @kleinschmidt-jaeger2015; @davis-sohoglu2020]. This hypothesis has gained considerable influence over the past decade, with findings that changes in listener perception are qualitatively predicted by statistics of exposure stimuli [@bejjanki2011; @clayards2008; @idemaru2021; @kleinschmidt2012; @kleinschmidt-jaeger2015cogsci; @munson2011-thesis; @nixon2016; @theodore2019distributional; @tan2021; for important caveats, see @harmon2018]. Bayesian belief-updating [@kleinschmidt-jaeger2015] has been found to closely predict the cumulative effects of exposure in perceptual recalibration to audio-visually [@kleinschmidt-jaeger2012] or lexically labeled speech [@cummings2023], as well as learning from unlabelled minimal pair stimuli [@kleinschmidt2016; for important constraints, see @kleinschmidt2020].

<!-- TO DO: find fMRI paper that claims to have rejected kleinschmidt-jaeger15 [wrongly], published somewhere around 2018-2020 -->

We investigate an important constraints on this type of adaptivity that has been proposed in recent work. @kleinschmidt-jaeger2016 exposed L1 US English listeners to over 200 recordings of /b/-/p/ minimal pair words like *beach* and *peach*. In US English, the primary cue to this contrast is voice onset timing (VOT), with /b/ having shorter VOTs (mean = XXX msecs) than /p/ (mean = XXX msecs). Kleinschmidt and Jaeger exposed
separate groups of listeners to VOT distributions for which these category means had been shifted by XXX, XXX, ..., or XXX msecs. In line with the distributional learning hypothesis, listeners' points of subjective equality (PSEs)---i.e., the VOT for which listeners responded "t" equally often as "d"---shifted in the same direction as the exposure distribution. Also in line with the distributional learning hypothesis, these shifts were larger the further the exposure distributions were shifted. <!-- perhaps replotting the figure from kj16 might help here? --> However, Kleinschmidt and Jaeger also observed a previously undocumented property of these adaptive changes: shifts in the exposure distribution had less than proportional (sublinear) effect on shifts in PSE. While this finding---recently replicated [@kleinschmidt2020, Experiment 4]---is compatible with the hypothesis of distributional learning, it points to important not well-understood constraints on adaptive speech perception. 

 + For example, the only existing fully-specified model of distributional learning---naive Bayesian belief-updating---is rejected by this finding. 
[seelingly seems to contradict finding that shifts in previous work were well predicted but A) all those tests assessed was correlation. there was no clear reference to compare against, and B) the investigated shifts were small --- always at most half-way between the category means. this constrasts with kj16]

 + Two competing explanations exist in the literature: A) 'shrinkage' to the prior, which is larger for more extreme 'outliers' (Same is also predicted by existing exemplar models, johnson 1997) vs. B) model selection from previously experienced talkers (vs. model induction, xie et al 18)

Contrastive tests against alternative hypotheses remain lacking [@xie2023]. This is at least in part due to often informal and vague 




- THE AIM OF THIS STUDY-
The study we report here builds on the pioneering work of @clayards2008 and @kleinschmidt2016you with the aim to shed more light on how listeners' initial interpretation of cues from a novel talker incrementally change as they receive progressively more informative input of her cue-to-category mappings.


POINTS-TO-MAKE


  - The strength of these beliefs has bearing on listener propensity to adapt to a new talker -- the stronger the prior beliefs the longer it takes to adapt. Listeners' strengths in prior beliefs about the means and variances are represented by parameters in the computational model. Listener behaviour observed collectively, thus far which speaks to this framework of thinking should by now be able to indicate roughly what those parameter values are. But it looks like those parameters are biased by the length of exposure and the outcome during experiments. No one has confronted this issue of very quick but limited adaptation which can't be solved by giving more exposure trials. 
  - How do we distinguish the results from normalization accounts which can also explain adaptation but is not usually regarded as learning?


A secondary aim of the present study was to *begin* to address possible concerns about ecological validity in research on distributional learning. The pioneering works that inspired the present study employed highly unnatural sounding stimuli that were clearly identifiable as robotic speech [@clayards2008; @kleinschmidt-jaeger2016]. These studies also followed the majority of research on distributional learning in language [e.g., @maye2003; @pajak2012] and *designed* rather than *sampled* the exposure distributions. As a consequence, exposure distributions in these experiments tend to be symmetrically balanced around the category means---unlike in everyday speech input. Indeed, all of the works we follow here further used categories with *identical* variances [e.g., identical variance along VOT for /b/ and /p/, @clayards2008; @kleinschmidt-jaeger2016; or /g/ and /k/, @theodore-monto2019]. This, too, is highly atypical for everyday speech input [@chodroff2017structure; @lisker-abrahamson1964]. We take modest steps to improve the ecological validity of our stimuli [building on @nixon2016; @theodore-monto2019], and exposure distributions. 

All data and code for this article can be downloaded from [XXX](OSF). <!-- TO DO: fill in URL --> The article is written in R markdown, allowing readers to replicate our analyses with the press of a button using freely available software [R, @R; @RStudio], while changing any of the parameters of our models (see SI, \@ref(sec:software)). 
