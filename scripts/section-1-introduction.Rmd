```{r setup, include=FALSE, message=FALSE}
if (!exists("PREAMBLE_LOADED")) source("preamble.R")
```

# Introduction
Adaptivity is a hallmark of human speech perception, supporting faster and more accurate speech recognition. On first encounters with an unfamiliar accent, the processing difficulty listeners might initially experience tends to alleviate with exposure [e.g., @bradlow-bent2008; @bradlow2023; @clarke-garrett2004; @sidaras2009; @xie2018; @xie2021jep]. Research over the last few decades has made strides in identifying the conditions required for successful adaptation, its generalizability across talkers, and its longevity [for reviews, see @bent-baeseberk2021; @cummings-theodore2023; @zheng-samuel2023]. It is now clear that listeners' categorization function---the mapping from acoustic or phonetic inputs to linguistic categories and, ultimately, word meanings---changes based on the phonetic properties of recent input [e.g., @bertelson2003; @clayards2008; @mcmurray2011; @eisner-mcqueen2005; @idemaru-holt2011; @kraljic-samuel2005; @kurumada2013; @mcmurray-jongman2011; @norris2003; @reinisch-holt2014; @xie2017; for review, @schertz-clare2020; @xie2023]. This has led to the development of stronger theories of adaptive speech perception that explicitly link the distribution of phonetic properties in recent speech input to changes in subsequent speech recognition [e.g., @apfelbaum-mcmurray2015; @harmon2019; @johnson1997; @kleinschmidt-jaeger2015; @magnuson2020; @assmann-nearey2007; @lancia-winter2013; @sohoglu-davis2016; @xie2023]. 

Previous work has typically framed questions as an 'either-or'---adaptation is either observed or not---consistent with the focus on identifying the necessary conditions for adaptation and generalization [see discussion in @cummings-theodore2023]. Recent reviews of the field instead emphasize the need to move towards stronger tests of existing theories, requiring the development of paradigms that support quantitative comparison to more strongly constrain the space of theoretical possibilities [@baese-berk2018; @schertz-clare2020; @xie2023]. This includes the need for data that characterize how adaptation develops *incrementally* as a function of exposure. While existing theories differ in important aspects, they share critical predictions about incremental adaptation that have remained largely untested: listeners' categorizations are predicted to change incrementally with exposure, and the direction and magnitude of that change should gradiently depend on (1) listeners' prior expectations based on previously experienced speech input from other talkers, and both (2a) the amount and (2b) distribution of phonetic evidence in the exposure input from the unfamiliar talker [for review, see @xie2023]. We report initial results from a novel repeated exposure-test paradigm designed to test these predictions during the early moments of adaptation. The paradigm we develop for this purpose also lay the foundation for strong quantitative tests, as we briefly demonstrate at the of this article. <!-- TO DO: revisit later to see whether we would like to keep this sentence -->

Figure \@ref(fig:block-design-figure) illustrates our approach. The experiment builds on computational and behavioral findings from separate lines of research on unsupervised distributional learning during speech perception [DL, @clayards2008; @kleinschmidt2020; @theodore-monto2019], lexically- or visually-guided perceptual learning [LGPL, @cummings-theodore2023; VGPL, @kleinschmidt-jaeger2012; @vroomen2007], and accent adaptation [AA, @hitczenko-feldman2016; @tan2021]. These paradigms have complementing strengths that we seek to combine and extend. <!-- TO DO: consider briefly elaborating here? -->  Following previous work on distributional learning in speech perception, we expose different groups of listeners to phonetic distributions that are shifted to different degrees [@bejjanki2011; @clayards2008; @kleinschmidt2015; @munson2011; @nixon2016; @theodore-monto2019]. Unlike this work, we incrementally assess changes in listeners' categorization from pre-exposure onward.

```{r block-design-figure, fig.height=3, fig.width=5, fig.cap="Exposure-test design of the experiment. Exposure conditions (rows) differed in the distribution of voice onset time (VOT), the primary phonetic cue to word-initial /d/ and /t/ in English (e.g., \"dip\" vs. \"tip\"). Test blocks assessed listeners' categorization functions over VOT stimuli that were held identical within and across conditions."}
knitr::include_graphics("../figures/block_design.png")
```

Following previous DL studies, we use phonetically manipulated stimuli. This gives researchers control over the distribution of acoustic-phonetic properties that listeners experience during exposure and test (unlike traditional AA, LGPL, and VGPL paradigms). Such control is an important prerequisite for stronger tests of predictions (1) and (2a,b). For example, recent findings from LGPL and VGPL provide evidence in support of prediction (2a)---that the amount of phonetic evidence during exposure gradiently affects the magnitude of shifts in listeners' categorization boundary [@cummings-theodore2023; see also @liu-jaeger2018; @liu-jaeger2019]. This includes some initial evidence that these changes accumulate incrementally [@kleinschmidt-jaeger2012; @vroomen2007], in ways consistent with models of adaptive speech perception. LGPL and VGPL paradigms---at least as used traditionally---do, however, limit experimenters' control over the phonetic properties of the exposure stimuli: consistent with the goals of those studies, shifted sound instances are selected to be perceptually ambiguous (e.g., between "s" and "sh"), rather than to exhibit specific phonetic distributions. To the extent that LGPL/VGPL research has assessed the effects of phonetic properties, this has largely been limited to qualitative post-hoc analyses [@drouin2016; @kraljic-samuel2007; @tzeng2021]. This makes it difficult to shed light on predictions (1) and (2b) about the effects of phonetic distributions in prior and recent experience.

Support for prediction (2b) has thus primarily come from DL studies. In an important early study, @clayards2008 exposed two different groups of US English listeners to instances of "b" and "p" that differed in their distribution along the voice onset time continuum (VOT). VOT is the primary phonetic cue to word-initial /b/-/p/, /d/-/t/, /g/-/k/ in US English: the voiced category (e.g. /b/) is produced with lower VOT than the voiceless category (e.g., /p/). Clayards and colleagues held the VOT means of /b/ and /p/ constant between the two exposure groups, but manipulated whether both /b/ and /p/ had wide or narrow variance along VOT. Exposure was unlabeled: on any trial, listeners saw pictures of, e.g., bees and peas on the screen while hearing a synthesized recording along the "bees"-"peas" continuum (obtained by manipulating VOT). Listeners' task was to click on the picture corresponding to the word they heard. If listeners adapt by learning how /b/ and /p/ are distributed along VOT, listeners in the wide variance group were predicted to exhibit a more shallow categorization function than the narrow variance group. This is precisely what Clayards and colleagues found [see also @nixon2016; @theodore-monto2019]. Together with more recent findings from adaptation to natural accents [@hitczenko-feldman2016; @tan2021; @xie2021cognition], this important finding suggests that the *outcome* of adaptation qualitatively follows the predictions of distributional learning models [e.g., exemplar theory, @johnson1997; ideal adaptors, @kleinschmidt-jaeger2015]. The findings in this line of work did, however, rely on tests that either averaged over, or followed, hundreds of trials of exposure. This leaves open how adaptation proceeds from the earliest moments of exposure---i.e., whether listeners' categorization behavior indeed changes in the way predicted by models of adaptive speech perception, developing from expectations based on previously experienced phonetic distributions to increasing integration of the phonetic distributions observed during exposure to the unfamiliar talker. It also leaves open whether potential constraints on changes in listeners' behavior reflect hard limits on adaptivity or simply the incremental learning outcome---'how far the learner has gotten'---at the only point at which adaptation is assessed [for discussion, see @cummings-theodore2023; @kleinschmidt-jaeger2016; @kleinschmidt2020].

The repeated exposure-test paradigm in Figure \@ref(fig:block-design-figure) begins to address these knowledge gaps. The experiment starts with a test block that assesses listeners' state prior to informative exposure---often assumed, but not tested, to be identical across exposure conditions. Additional intermittent tests---opaque to participants---then assess incremental changes up to the first 144 informative exposure trials. The use of physically identical test trials both across block within exposure conditions and across exposure conditions, we aim to facilitate assumption-free comparison of cumulative exposure effects (we additionally also measure adaptation during exposure). As we detail under Methods, the use of repeated testing deviates from previous work [@clayards2008; @harmon2019; @idemaru-holt2011; @idemaru-holt2020; @kleinschmidt-jaeger2016; @kleinschmidt2020; @munson2011; @nixon2016; @theodore-monto2019], and is not without challenges. This design allows tests of prediction (2a) by comparing between participants, and of prediction (2b) by comparing within and across participants. The design also lets us assess how the joint effect exposure amount and exposure distributions---corresponding to predictions (2a) and (2b)---unfolds incrementally with exposure. And, by comparing the direction of adaptation not only across conditions, but also relative to the distribution of phonetic cues in listeners' prior experience, we can begin to assess prediction (1). 

Finally, we took several modest steps towards addressing concerns about ecological validity that have been argued to limit the generalizability of DL results. This includes concerns about the ecological validity of both the stimuli and their distribution in the experiment [see discussion in @baseberk2018]. For example, previous distributional learning studies have often used highly unnatural, 'robotic'-sounding, speech. Beyond raising questions about what types of expectations listeners apply to such speech, these stimuli also failed to exhibit naturally occurring covariation between phonetic cues that listeners are known to expect [see, e.g., @idemaru-holt2011; @schertz2016]. We instead developed stimuli that both sound natural and exhibit the type of phonetic covariation that listeners expect from everyday speech perception. We return to these and additional steps we took to increase the ecological validity of the phonetic *distributions* under Methods.

All data and code for this article can be downloaded from [https://osf.io/hxcy4/](OSF). Following @xie2023, both this article and its supplementary information (SI) are written in R Markdown. This allows other researchers to replicate and validate our analyses with the press of a button using freely available software [R, @R; @RStudio, see also SI, \@ref(sec:software)]. 
