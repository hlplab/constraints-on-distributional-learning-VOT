---
title: "Sandboxing of AE DLVOT"
author: "Maryann Tan and Florian Jaeger"
date: \today
geometry: margin=2cm
header-includes:
  - \usepackage{booktabs}
  - \usepackage{siunitx}
  - \usepackage{tabto}
  - \usepackage{soul}
  - \usepackage{xcolor}
  - \usepackage{placeins}
  - \usepackage{lscape}
  - \usepackage{animate}
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
  - \makeatletter\renewcommand{\fps@table}{!ht}\makeatother
  - \setstcolor{red}
  - \usepackage{sectsty}
  - \sectionfont{\color{blue}} 
  - \subsectionfont{\color{blue}}
  - \subsubsectionfont{\color{darkgray}}
output:
  pdf_document: 
    fig_caption: yes
    fig_width: 7
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 4
  fontsize: 10pt
---

```{r, include=F}
library(knitr)

opts_chunk$set(dev = 'pdf',
               comment="", 
               echo=FALSE, warning=TRUE, message=TRUE,
               cache=FALSE, 
               size="small",
               tidy.opts = list(width.cutoff = 200),
               fig.width = 8, fig.height = 4.5, fig.align = "center")


def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

color_block = function(color) {
  function(x, options) sprintf('\\color{%s}\\begin{verbatim}%s\\end{verbatim}\\color{black}',
                               color, x)
}
knitr::knit_hooks$set(error = color_block('red'))
knitr::knit_hooks$set(warning = color_block('orange'))
```

# Preamble 
Loading libraries, functions, and setting constants.

```{r, include=F}
library(tidyverse)
library(magrittr)

library(broom)          # for extraction of coefficients

library(gganimate)      # to animate plots
library(RColorBrewer)   # to select brewer colors
library(kableExtra) 
```

```{r, include=F}
options(width = 110)

theme_set(theme_bw())
```

```{r functions, include=FALSE}
source("functions-for-experiment-reports.R")
```

# Data import
Loading and formatting data.

```{r, message=F}
experiment = "AE-DLVOT"

d <- 
  read_tsv(
    "../../data/raw/AE-Swedish-DLVOT/sandbox/experiment-B-URLPARAMS-sandbox-batch2-results_040322.tab",
    show_col_types = FALSE) %>%
  formatData(experiment = experiment) %>%
  sortVars()
```


# Assessing the data

## Are all variable names present that you expected?
We expect the following information to be stored in the data frame:

 * Participant-level information:
   * Participant/worker ID
   * List exposure materials (always A).
   * List exposure block order (A, B, C)
   * List image selection (backward/forward)
   * Survey responses
     * RSRB survey
     * Our experiment-specific survey
 * Phase (exposure, test)
 * Block (1:9)
 * Trial (currently coded within block)
 * Item-level information:
   * Correct (expected) response
   * Item/minimal pair
   * Filename with VOT and F0 information
   
 * MORE HERE?  
 
```{r}
knitr::include_graphics("../../figures/DLVOT_experiment_design.png")
```
 
 

After data importing, formating, and sorting, these are all the variable names present in the data:

```{r}
names(d)
```

\newpage

### Checking on variables, Block.AllowFeedback, Trial.ProvidedFeedback, Trial.ImageSelection 

```{r}

d %>% select(c(Block.AllowFeedback, Trial.ProvidedFeedback, Trial.ImageSelection)) %>% 
  group_by(Block.AllowFeedback, Trial.ProvidedFeedback, Trial.ImageSelection) %>% 
  summarise() %>% 
  kable(longtable = T, booktabs = T) %>% 
  kable_styling(latex_options = c("striped")) 

```




## Carefully read comments provided by participants
Comments provided in the sandbox HITs.

```{r}
d %>%
  select(ParticipantID, Assignment.Comment) %>%
  distinct() %>% 
  kable(longtable = T, booktabs = T) %>% 
  kable_styling(latex_options = c("striped")) 
```

## Matching beween YAML file and conditions in this data

 1. Get the HIT ID for each participant. 
```{r}
```
 
 2. Go to the YAML success file (.success.yaml). 
 3. Look up that HIT ID.
 4. Count what *k*th HIT corresponds to that HIT ID from the top of the success file (e.g., it might be the 6th HIT ID).
 
```{r}

```

## Have any participants taken the experiment more than once?

If a worker shows up more than once below, it is a duplicate take. For sandboxing, this is not an issue. We include this debugging step here since we will use it during production.

```{r}
d %>%
  group_by(workerid, Assignment.Submit.DateTime.UTC) %>%
  summarise() %>%
  group_by(workerid) %>%
  tally() %>% filter(n != 1)
```


## How did participants perform on catch trials
There should be 18 catch trials (3 items * 2 instances * 3 exposure blocks) per participant. We will exclude participants who scored lower than 85% on catch trials.

```{r}
d %>% 
  filter(is.na(Item.VOT)) %>% 
  group_by(workerid, ParticipantID) %>% 
  tally() %>% 
  kable(longtable = T, booktabs = T) %>% 
  kable_styling(latex_options = c("striped", cpation = "No. of catch trials")) 

d %>% 
  filter(is.na(Item.VOT)) %>% 
  select(Item.ExpectedResponse, Response, ParticipantID) %>%
  group_by(ParticipantID) %>% 
  summarise(`Prop of catch correct` = mean(Response == Item.ExpectedResponse)) %>% 
  filter(`Prop of catch correct` < 0.85) %>% 
  kable(longtable = T, booktabs = T) %>% 
  kable_styling(latex_options = c("striped")) 
  
```




```{r}

```


## Block structure and trials per block
We expected 54 (3 critical minimal pair items * 2 categories * 8 instances each = 48 critical + 3 catch items * 2 instances each = 6) stimuli per exposure block and 12 stimuli per test block.

```{r}
#xtabs(~ Phase + Block + ParticipantID, d)
```

### What is the distribution during exposure

```{r, fig.width=8, fig.height=5}
d %>%
  group_by(ParticipantID) %>% 
  filter(Phase == "exposure") %>%
  drop_na(Item.VOT) %>%
  ggplot() +
  geom_density(aes(x = Item.VOT, fill = Item.ExpectedResponse.Voicing), alpha = .5) +
  xlim(-50, 130) +
  facet_grid(Condition.Exposure ~ Block, margins = T, scales = "free")
```

### Are all minimal pair items occurring exactly four times in each test block?
Show all minimal pair items that occur more or less than four times per test block. If everything worked, this should be an empty data frame:

```{r}
d %>%
  filter(Phase == "test") %>%
  group_by(ParticipantID, Block, Item.MinimalPair) %>%
  tally() %>%
  filter(n != 4)
```

### Are all VOTs occurring exactly once in each test block?
Show all VOTs that occur more or less than once per test block. If everything worked, this should be an empty data frame:

```{r}
d %>%
  filter(Phase == "test") %>%
  group_by(ParticipantID, Block, Item.VOT) %>%
  tally() %>%
  filter(n != 1)
```

## Did participants show increasing voiceless responses for stimuli with increasing VOT?
We fit separate logistic regressions to each participant's responses with the VOT continuum as the sole (linear) predictor.

```{r}
d %<>%
  group_by(ParticipantID) %>%
  nest() %>%
  mutate(
    CategorizationModel = 
      map(
        data, 
        ~ tryCatch(
          expr = {
            glm(Response.Voicing == "voiceless" ~ Item.VOT, data = .x, family = binomial) %>% 
            tidy() }, 
          error = ~ NA)),
    Categorization.Intercept = 
      map(
        CategorizationModel, 
        ~ .x %>% 
          filter(term == "(Intercept)") %>% 
          pull(estimate)) %>% 
      unlist(),
    Categorization.Slope = 
      map(
        CategorizationModel, 
        ~ .x %>% 
          filter(term == "Item.VOT") %>% 
          pull(estimate)) %>% 
      unlist()) %>%
  select(-CategorizationModel) %>%
  unnest(data)

```



```{r, fig.width=13.5, fig.height=3, warning=FALSE}
d %>%
  group_by(Condition.Exposure, Item.VOT, Categorization.Slope) %>%
  mutate(Response.ProportionVoiceless = ifelse(Response.Voicing == "voiceless", 1, 0)) %>%
  ggplot(aes(
    x = Item.VOT, 
    y = Response.ProportionVoiceless, 
    color = Condition.Exposure,
    linetype = Categorization.Slope < 0)) +
  geom_smooth(
    formula = y ~ x, 
    method = "glm", 
    method.args = list(family = "binomial"),
    se = FALSE) +
  scale_x_continuous("VOT") +
  scale_y_continuous("Proportion of voiceless responses", limits = c(0,1)) +
  scale_linetype_manual(
    "Unexpected\ncategorization\nslope",
    breaks = c(T, F),
    labels = c("yes", "no"),
    values = c(2, 1)) +
  facet_grid(Condition.Exposure ~ Block) +
  theme(legend.position = "top")
```



## Distribution across trials: Random when it should be?

### Item minimal pair across trials

```{r, fig.width=30, fig.height=4.5}
d %>%
  ggplot(aes(x = Trial)) +
  geom_bar(mapping = aes(fill = Item.MinimalPair)) +
  scale_x_continuous(breaks = 10 * 1:10) +
  coord_cartesian(expand = F) +
  facet_grid(Condition.Exposure + ParticipantID ~ Block, scales = "free_x", space = "free_x") +
  theme(legend.position = "top")
```

### Category across trials

```{r, fig.width=30, fig.height=4.5}
d %>%
  ggplot(aes(x = Trial)) +
  geom_bar(mapping = aes(fill = Item.ExpectedResponse.Voicing)) +
  scale_x_continuous(breaks = 10 * 1:10) +
  coord_cartesian(expand = F) +
  facet_grid(Condition.Exposure + ParticipantID ~ Block, scales = "free_x", space = "free_x") +
  theme(legend.position = "top")
```

### VOT across trials

```{r, fig.width=30, fig.height=4.5}
d %>%
  mutate(count = 1) %>%
  ggplot(aes(x = Trial, y = count)) +
  geom_col(mapping = aes(fill = Item.VOT)) +
  scale_x_continuous(breaks = 10 * 1:10) +
  scale_fill_viridis_b() +
  coord_cartesian(expand = F) +
  facet_grid(Condition.Exposure + ParticipantID ~ Block, scales = "free_x", space = "free_x") +
  theme(legend.position = "top")
```


## How long did it take participants to complete the experiment?
We have two ways of assessing the overall duration participants took to complete the experiment. The time between accepting and submitting the assignment includes any time that might pass before the participant actually starts the experiment (workers often select a few HITs---reserving them---and only then start working on them), time spent reading the instructions, and time spent on the survey: 

```{r}
d %>%
  select(ParticipantID, Duration.Assignment) %>%
  distinct() %>%
  ggplot(aes(x = Duration.Assignment)) +
  geom_density() +
  geom_rug() +
  scale_x_continuous("Duration of assignment (in minutes)")
```

A second, perhaps more informative measure, is the time between the start of the first trial and the end of the last trial, which measures how much time was spent on the actual experiment.

```{r}
d %>%
  select(ParticipantID, Duration.AllPhases) %>%
  distinct() %>%
  ggplot(aes(x = Duration.AllPhases)) +
  geom_density() +
  geom_rug() +
  scale_x_continuous("Duration of exposure & test phase (in minutes)")
```


### Were some participants particularly slow/fast to respond?
We can also examine the pacing and variability in pacing across trials. For this, we plot the mean and standard deviation of each participants logarithm-transformed response times for all non-catch trials.

Participant with high SDs are those who might have, for example, just one or two slow trials. Participant with high mean RTs but comparatively low SDs of those RTs, on the other hand, were consistently slow in responding.

```{r}
d %>%
  group_by(ParticipantID) %>%
  mutate(Response.log_RT = log10(Response.RT)) %>%
  summarise_at("Response.log_RT", .funs = list("mean" = mean, "sd" = sd)) %>%
  ggplot(aes(x = mean, y = sd, label = ParticipantID)) +
  geom_text(alpha = .8) +
  geom_rug() +
  scale_x_continuous("mean log-RT (log10 of msec)") +
  scale_y_continuous("SD of log-RT") +
  scale_color_manual(
    "Unexpected\ncategorization\nslope",
    breaks = c(T, F),
    labels = c("yes", "no"),
    values = c("red", "black"))
```


## Exclusions

32 participants were excluded due to catch trials (Shift0 = 12, Shift10 = 8, Shift40 = 12)
297 trials were excluded due to RTs
No participant was excluded due to RT
The proportion of data excluded was 36.5%

```{r}


d %<>% group_by(ParticipantID) %>%
  mutate(Response.log_RT = log10(ifelse(Response.RT <= 0, NA_real_, Response.RT)),
         Response.log_RT.scaled = scale(Response.log_RT), # deducts each value with subject's own mean, div by own SD
         Response.log_RT.mean = mean(Response.log_RT, na.rm = T), # this gives each subject's mean log_RT
         Excluded.trial.due.to.RT = ifelse(abs(Response.log_RT.scaled) > 3, TRUE, FALSE)) %>% 
  ungroup() %>% 
  mutate(Excluded.participant.due.to.RT = ifelse(abs(scale(Response.log_RT.mean)) > 3, TRUE, FALSE)) # scales each subject's mean log RT against whole cohort's mean and SD

d.excluded <- d %>% 
  filter(Excluded.due.to.CatchTrial == TRUE | 
           Excluded.trial.due.to.RT == TRUE | 
           Excluded.participant.due.to.RT == TRUE |
           Excluded.due.to.wrong.sex.answer == TRUE)
proportion.excluded <- nrow(d.excluded)/nrow(d)

d %>% filter(Excluded.trial.due.to.RT == TRUE) 

d %>% filter(Excluded.due.to.CatchTrial == TRUE) %>% 
  group_by(Condition.Exposure, ParticipantID) %>% 
  summarise() %>% tally()
```








# Session info
```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
