```{r}
require(tidyverse)
require(magrittr)

require(brms)
require(MVBeliefUpdatr)
require(phonR)
require(rsample)

source("functions.R")
```




## Behavioral results
We first present participants' categorisation responses. Given that this experiment was designed to give pre-exposure test data, we run an analysis on test block 1 that is similar to the IO analysis of experiment 1. 



### Analysis approach


```{r load-br-model-block1}
# make Block 1 subset
d.block1 <- d.test_exposure_for_analysis %>% 
  filter(Block == 1) 

# set the mean and SD values for scaling/unscaling purposes. 
d.mean_sd <- d.test_exposure_for_analysis %>% 
  filter(Phase == "test") %>% 
  ungroup() %>% 
  summarise(across(c(Item.VOT, Item.Mel_F0_5ms), list(mean = mean, sd = sd), .names = "{.col}.{.fn}"))

VOT.mean_testblock1 <- d.mean_sd %>% pull(Item.VOT.mean)
VOT.sd_test <- d.mean_sd %>% pull(Item.VOT.sd)
f0.mean_testblock1 <- d.mean_sd %>% pull(Item.Mel_F0_5ms.mean)
f0.sd_test <- d.mean_sd %>% pull(Item.Mel_F0_5ms.sd)

d.block1 %<>% 
  mutate(
    Response.Voiceless = ifelse(Response.Voicing == "voiceless", 1, 0),
    VOT_gs = (Item.VOT - VOT.mean_testblock1)/ (2 * VOT.sd_test),
    F0_gs = (Item.Mel_F0_5ms - f0.mean_testblock1) /(2 * f0.sd_test))

# load the full experiment fit to obtain lapse rate
fit_mix_uniform_bias <- readRDS("../models/Exp-AE-DLVOT-labelled-lapsing-GLMM-difference-no-RTexcl.rds")
lapse_exp2 <- as.numeric(summary(fit_mix_uniform_bias)$fixed["theta1_Intercept", 1])

# run brms model of data for block 1 using lapse rate from full model (section X.X) 
fit_mix_block1 <- brm(
  bf(
    Response.Voiceless ~ 1,
    mu1 ~ 0 + offset(0),
    mu2 ~ 1 + VOT_gs + (1 + VOT_gs | ParticipantID),
    theta1 ~ 0 + offset(lapse) + (1 | ParticipantID)),
  data = d.block1 %>% 
    mutate(lapse = lapse_exp2),
  cores = 4,
  iter = 3000, # iterations to run
  warmup = 1500, # samples used to fit
  chains = chains,
  family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
  control = list(adapt_delta = .999),
  file = "../models/Exp-AE-DLVOT-Block1-lapse-no-RTexcl.rds")
```






```{r}
# get PSE of Block 1 from model summary
PSE.fit_mix_block1 <- descale(-(as.numeric(summary(fit_mix_block1)$fixed["mu2_Intercept", 1])) / as.numeric(summary(fit_mix_block1)$fixed["mu2_VOT_gs", 1]), VOT.mean_testblock1, VOT.sd_test)

# get posterior samples of intercept and slope, and median qi of the PSE 
post_sample_block1 <- fit_mix_block1 %>% 
  spread_draws(b_mu2_Intercept, b_mu2_VOT_gs) %>% 
  mutate(PSE = descale(-(b_mu2_Intercept/b_mu2_VOT_gs),VOT.mean_testblock1, VOT.sd_test)) %>% 
  median_qi(PSE)

#plot the fitted psychometric function for Block 1
psychometric_fit_block1 <- conditional_effects(
    fit_mix_block1, 
    effects = "VOT_gs",
    method = "posterior_epred",
    plot = F)[[1]]

# make base plot
p.fit_block1 <- psychometric_fit_block1 %>% 
  ggplot(aes(x = descale(VOT_gs, VOT.mean_testblock1, VOT.sd_test), 
             y = estimate__)) +
  scale_x_continuous("VOT (ms)", limits = c(-5, 70)) +
  scale_y_continuous("Fitted proportion of 't' responses") +
  geom_ribbon(aes(ymin = lower__, ymax = upper__), alpha = .1) +
  geom_line(linewidth = 1.5, 
            colour = "#333333",
            alpha = .8) +
   geom_errorbarh(
    data = post_sample_block1 %>% 
      mutate(y = .01),
    mapping = aes(xmin = .lower, xmax = .upper, y = y), 
    color = "#333333",
    height = 0,
    alpha = .5,
    size = 1, 
    inherit.aes = F) +
  geom_label(
    data = post_sample_block1 %>% 
      median_qi(PSE) %>% 
      mutate(y = 0.01),
    mapping = aes(x = PSE, y = y, label = round(PSE)),
    color = "#333333", 
    size = 1.8,
    label.padding = unit(0.18, "lines"),
    alpha = .5) +
  annotate(
    geom = "text",
    x = 55,
    y = 0.02, 
    label = paste(round(post_sample_block1[[2]]), "ms", "-", round(post_sample_block1[[3]]), "ms"),
    size = 3.5,
    colour = "darkgray") +
   geom_rug(
    data = d.block1 %>% 
      reframe(Item.VOT) %>% 
      distinct(Item.VOT),
    mapping = aes(x = Item.VOT),
    alpha = .6,
    inherit.aes = F)
```


```{r prepare-production-database}
# prepare production corpus from Chodroff & Wilson
d.chodroff_wilson <-
  get_ChodroffWilson_data(
    database_filename = "../data/all_observations_with_non-missing_vot_cog_f0.csv",
    min.n_per_talker_and_stop = 25,
    limits.VOT = c(-Inf, Inf),
    limits.f0 = c(0, 350),
    max.p_for_multimodality = .1
  ) %>%
  mutate_at(
    c("VOT", "f0_Mel"),
    list("centered" = function(x) apply_ccure(x, data = .)))

d.chodroff_wilson.selected <-
  d.chodroff_wilson %>%
  filter(poa == "/d/-/t/") %>%
  group_by(Talker, category) %>%
  mutate(n = n()) %>%
  group_by(Talker) %>%
  # subsample n tokens, as determined by category with fewer tokens
  mutate(
    n_min = min(n),
    n_category = n_distinct(category)) %>%
  # select talkers with both /d/ and /t/ observations
  filter(n_category == 2) %>%
  group_by(Talker, category) %>%
  sample_n(size = first(n_min)) %>%
  ungroup() %>%
  mutate_at(
      c("VOT", "f0", "f0_Mel", "f0_semitones"),
      list("centered" = function(x) apply_ccure(x, data = .))) %>% 
  mutate(category = factor(category))
```



```{r IO-categorization-VOT-f0-centered-input-block1, message=FALSE}
# prepare data for IO that centers perceptual input relative to database mean before categorization
chodroff.means <- d.chodroff_wilson.selected %>% 
  group_by(Talker) %>% 
  summarise(across(c(VOT, f0_Mel), mean)) %>% 
  ungroup() %>% 
  summarise(across(c(VOT, f0_Mel), mean)) 

chodroff.mean_VOT <- chodroff.means %>% pull(VOT)
chodroff.mean_f0 <- chodroff.means %>% pull(f0_Mel)

# get means and SDs from entire experiment for centering purposes
d.mean_sd <- d.test_exposure_for_analysis %>% 
  ungroup() %>% 
  summarise(across(c(Item.VOT, Item.Mel_F0_5ms), list(mean = mean, sd = sd), .names = "{.col}.{.fn}"))

VOT.mean_exp2 <- d.mean_sd %>% pull(Item.VOT.mean)
VOT.sd_exp2 <- d.mean_sd %>% pull(Item.VOT.sd)
f0.mean_exp2 <- d.mean_sd %>% pull(Item.Mel_F0_5ms.mean)
f0.sd_exp2 <- d.mean_sd %>% pull(Item.Mel_F0_5ms.sd)
```





```{r, message=FALSE}
# prepare data for IO that centers perceptual input relative to database mean before categorization
chodroff.means <- d.chodroff_wilson.selected %>% 
  group_by(Talker) %>% 
  summarise(across(c(VOT, f0_Mel), mean)) %>% 
  ungroup() %>% 
  summarise(across(c(VOT, f0_Mel), mean)) 

chodroff.mean_VOT <- chodroff.means %>% pull(VOT)
chodroff.mean_f0 <- chodroff.means %>% pull(f0_Mel)

# center exposure data relative to database mean
psychometric_fit_block1_centered <- psychometric_fit_block1 %>% 
  mutate(Item.VOT = descale(VOT_gs, VOT.mean_testblock1, VOT.sd_test),
         Item.VOT = Item.VOT + (chodroff.mean_VOT - VOT.mean_testblock1),
         VOT_gs = (Item.VOT - VOT.mean_testblock1)/(2 * VOT.sd_test))


# get expected values of the centered EXPOSURE VOT under the linear model
if (file.exists("../models/centered_exposure_block1_exp2.rds")) {
  epred_centered_block1 <- read_rds("../models/epred_centered_exposure_block1_exp2.rds")
} else {
  epred_centered_block1 <- epred_draws(
    object = fit_mix_block1,
    newdata = psychometric_fit_block1_centered,
    re_formula = NA,
    ndraws = 2000)
  write_rds(epred_centered_block1, file = "../models/epred_centered_exposure_block1_exp2.rds")
}
```







## Regression analysis
The regression analysis addresses two main questions: 
Do participants shift their categorisation behaviour in an incremental fashion, i.e. do they exhibit categorisation behaviour that draws closer to the ideal categorisation function with each successive exposure block?
Are the differences in shifts between the conditions proportional to the magnitude of the shifts between exposure distributions i.e. is the PSE of the +40ms condition 3 times that of the +10ms condition?

As with experiment 1 we fit a Bayesian mixed-effects psychometric model with lapse and perceptual components. Continuous predictors were standardised to twice the standard deviation and priors and sampling parameters were identical to those specified in experiment 1. 

To analyse the incremental effects of exposure condition on the proportion of /t/ responses at test, the perceptual model contained exposure condition (backward difference coded, comparing the +10ms against the +0ms shift condition, and the +40ms against the +10ms shift condition), test block (backward difference coded from the first to last test block), VOT (Gelman scaled), and their full factorial interaction. For the perceptual model, "t"-responses were regressed on the three-way interaction of VOT, condition, and block. Random effects were modelled with varying intercepts and slopes by participant and varying intercepts and slopes by minimal pair item. The lapsing model which estimates participant bias on trials with attention lapses was fitted without an intercept but with an offset [how does one describe this? what does offset(0) represent]. Finally, a population-level intercept was fitted to estimate the lapse rate. Random effects for the lapsing model and lapse rates were not fitted to limit the number of parameters and to ensure model convergence.

### Expectations
Given previous findings of @kleinschmidt2016you we expected participants in the various exposure conditions to shift their average categorization functions towards the direction of the ideal categorization function implied by their respective exposure distributions. We expected the differences between the groups to be most pronounced after the final exposure block as they would have had the complete exposure to all the tokens that make up the exposure distributions. This follows from predictions of incremental Bayesian belief-updating -- that listeners would integrate their prior expectations with the current input to infer the present talker's cue-to-category-mapping (the posterior distribution). 
Also based on previous findings, we expected the +40ms group to not fully  converge on the ideal categorization function as it was previously found that the further an exposure talker's cue distributions deviated from a *typical* talker's, the further the distance of categorization function from the ideal boundary. We therefore expected to see differences in categorizations between the +10ms and +40ms conditions such that listeners in the +40ms condition would shift more than those in the +10ms condition but to have an average categorization function located to the left of the ideal function. [@kleinschmidt2016you].


```{r model-test-blocks, warning=FALSE}
d.test_exposure_for_analysis %<>% 
  mutate(Response.Voiceless = ifelse(Response.Voicing == "voiceless", 1, 0))
levels_Condition.Exposure = c("Shift0", "Shift10", "Shift40")
contrast_type <- "difference"

my_priors <- c(
  prior(student_t(3, 0, 2.5), class = "b", dpar = "mu2"),
  prior(student_t(3, 0, 2.5), class = "b", dpar = "theta1"),
  prior(cauchy(0, 2.5), class = "sd"),
  prior(lkj(1), class = "cor"))

# simplifying model with uniform bias
fit_mix_uniform_bias <- brm(
  bf(
    Response.Voiceless ~ 1,
    mu1 ~ 0 + offset(0),
    mu2 ~ 1 + VOT_gs * Condition.Exposure * Block + (1 + VOT_gs * Block | ParticipantID) + (1 + VOT_gs * Condition.Exposure * Block | Item.MinimalPair),
    theta1 ~ 1),
  data = d.test_exposure_for_analysis %>% 
    filter(Phase == "test") %>% 
    prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = contrast_type),
  cores = 4,
  chains = chains,
  init = 0,
  iter = 4000, # iterations to run
  warmup = 2000, # samples used to fit
  family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
  control = list(adapt_delta = .99),
  file = "../models/Exp-AE-DLVOT-labelled-lapsing-GLMM-difference-no-RTexcl.rds")

fixed_eff_exp2 <- tidy(fit_mix_uniform_bias, effects = "fixed") %>% 
  select(-c(effect, component))

# load helmert contrast-coded model
fit_mix_helmert <- read_rds("../models/Exp-AE-DLVOT-labelled-lapsing-GLMM-helmert-no-RTexcl.rds")

fixed_eff_exp2_helmert <- tidy(fit_mix_helmert, effects = "fixed") %>% 
  select(-c(effect, component))

#fixed_eff_exp2
#fixed_eff_exp2_helmert

kable(fixed_eff_exp2, booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "repeat_header", "scale_down"), position = "center") 
```


Fig. XX summarizes participantsâ€™ categorization functions across the different test blocks. A first point to note are the average categorization functions of the respective conditions before exposure to the talker. As depicted in the first panel, the average functions converge on the same boundary or PSE (4xms, CI = ) which suggests that participants largely had similar expectations about the cue distribution corresponding to /d/ and /t/ for this type of talker. What it also shows is that in setting our baseline condition we may have underestimated the perceived boundary for our test stimuli by approximately 20ms which implies that the +10ms shift and the +40ms shift were in fact -10ms and +20ms respectively.[ELABORATION]

There was a main effect of VOT $\hat{\beta} =$ `r get_CI(fit_mix_uniform_bias, "mu2_VOT_gs", "mu2_VOT_gs > 0")`; participants were more likely to respond "t" as VOT increased. Condition had a main effect on responses such that with larger shifts, participants on average responded with fewer "t"s.  Additionally, the difference in average "t" responses between the +40ms and +10ms conditions ($\hat{\beta} =$ `r get_CI(fit_mix_uniform_bias, "mu2_Condition.Exposure_Shift40vs.Shift10", "mu2_Condition.Exposure_Shift40vs.Shift10 < 0")` reduction in log-odds) was *larger* than the difference between the +10 and +0 conditions ($\hat{\beta} =$ `r get_CI(fit_mix_uniform_bias, "mu2_Condition.Exposure_Shift10vs.Shift0", "mu2_Condition.Exposure_Shift10vs.Shift0 < 0")` reduction in log-odds). 
Qualitatively, the results indicate listeners adjust their expectations to align with the statistics of the exposure talker, consonant with previous findings of studies employing this paradigm (e.g., @clayards2008; @kleinschmidt2016you; @theodore2019distributional). 

While there was weak evidence for a main effect of block its interaction with condition revealed how participants in the respective exposure groups responded as they progressively received more informative input. Most of the change took place after the first exposure block. Participants in the +10ms condition responded with fewer "ts" compared to participants in the +0ms condition in test block 2 relative to that in test block 1 ($\hat{\beta} =$ `r get_CI(fit_mix_uniform_bias, "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test2vs.Test1", "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test2vs.Test1 < 0")`). The difference between the  +40ms and +10ms condition in test block 2 relative to that in block 1 was more pronounced, reflecting the wider separation between the two exposure conditions in block 2 ($\hat{\beta} =$ `r get_CI(fit_mix_uniform_bias, "mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test2vs.Test1", "mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test2vs.Test1 < 0")`). 

In test block 3, the difference in average log-odds between conditions +0ms and +10ms, relative to block 2 was *positive* such that the difference between the two conditions in test block 3 was smaller than the corresponding difference in block 2 ($\hat{\beta} =$ `r get_CI(fit_mix_uniform_bias, "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test3vs.Test2", "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test3vs.Test2 >0")`). In test blocks 4 and 5, the  average log-odds difference between +0ms and +10ms increased marginally when compared to the preceding block, respectively (as indicated by the negative signs of the estimates; see table xx) while in test block 6 the difference between the two exposure conditions narrowed substantially. Looking at the  the difference between the +40ms and +10ms conditions, this continued to widen in test blocks 3 and block 4 relative to their respective preceding blocks, albeit by progressively smaller increments. This widening trend would then reverse in test blocks 5 and 6. In all, the respective conditions hit their maximal shifts between blocks 2 and 3 and began to display a reversal of the exposure effects by the end of block 4. This "unlearning" of the exposure distribution, observed in the final 3 test blocks was expected given previous findings that distributional learning effects can begin to dissipate with prolonged testing with tokens from a uniform distribution. 

An examination of the block-by-block changes in the intercepts and slopes of the respective conditions, confirmed that the changes in categorization behaviour were driven predominantly by changes in the intercept (fig xx). the slopes of all 3 conditions in test block 4, which immediately follows the final exposure block, and where participants would have had full exposure to their respective distributions, did not differ substantially from each other nor from their estimated starting point in test block 1. Conversely, the intercepts at these points in the experiment were more distinct from each other and from where they were estimated to be at test block 1. 

In summary, the analysis shows that the groups diverged in their categorisation behaviour very early on in the experiment -- only after 24 exposures to each category. This suggests a readiness to adapt to a new talker by integrating current input with prior expectations. This prompt shift was however tempered by participants reaching the limits of their adaptation almost as quickly; the +40ms condition for example achieved more than 95% of its maximal shift in the experiment in test block 2. Only a marginal change in categorization behaviour was observed after the second exposure block while the third exposure block barely resulted in further shifts. 

 **Glaringly, all three conditions undershot the ideal categorization boundaries implied by their respective exposure distributions: 14.5ms in the +0ms, 7.2ms in the +10ms, and 14.5ms in the +40ms conditions. 

  **Like this study's predecessor, we also find that participants had a greater propensity to shift their categorisations upwards than downwards as the +40ms group showed the widest deviation from the baseline.

Under the Bayesian ideal adapter framework quick adaptation is characterised as listeners having weak beliefs in their prior cue means and variances. Listeners' strength in prior beliefs influences the speed of adaptation, and this is what we observed. On the other hand, weak prior beliefs also predict that it would take few trials for listeners to converge on the implied categorisation boundary. But this is not what we observed in our data. 



```{r model-exposure-blocks}
exposure_block_stats <- d.test_exposure_for_analysis %>% 
    filter(Phase == "exposure" & Item.Labeled == FALSE) %>% 
  summarise(VOT.mean_exposure = mean(Item.VOT),
            VOT.sd_exposure = sd(Item.VOT))

VOT.mean_exposure <- exposure_block_stats[[1]]
VOT.sd_exposure <- exposure_block_stats[[2]]

# set priors for psychometric model
my_priors <- c(
  prior(student_t(3, 0, 2.5), class = "b", dpar = "mu2"), # prior 
  prior(student_t(3, 0, 2.5), class = "b", dpar = "theta1"), 
  prior(cauchy(0, 2.5), class = "sd"),
  prior(lkj(1), class = "cor")
)

# fit difference coded model
fit_mix_exposure <- brm(
  bf(
    Response.Voiceless ~ 1,
    mu1 ~ 0 + offset(0),
    mu2 ~ 1 + VOT_gs * Condition.Exposure * Block + (1 + VOT_gs * Block | ParticipantID) + (1 + VOT_gs * Condition.Exposure * Block | Item.MinimalPair),
    theta1 ~ 1),
  data = d.test_exposure_for_analysis %>% 
    filter(Phase == "exposure" & Item.Labeled == FALSE) %>% 
    prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = contrast_type),
  cores = 4,
  chains = chains,
  init = 0,
  iter = 4000, # iterations to run
  warmup = 2000, # samples used to fit
  family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
  control = list(adapt_delta = .99),
  file = "../models/Exp-AE-DLVOT-lapsing-GLMM-differencecoded-exposureblocks.rds")

tidy(fit_mix_exposure, effects = "fixed") %>% 
  select(-c(effect, component))
```


```{r plot-exposure-fit, fig.width=6, fig.height=2}
cond_fit_exposure <- conditional_effects(
    fit_mix_exposure,
    effects = "VOT_gs:Condition.Exposure",
    conditions = make_conditions(
      d.test_exposure_for_analysis %>% 
        filter(Phase == "exposure") %>% 
        prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = "difference"), 
      vars = c("Block")),
    method = "posterior_epred",
    ndraws = 500,
    re_formula = NA)

cond_fit_exposure[[1]] %>% 
  mutate(Condition.Exposure = case_when(Condition.Exposure == "Shift0" ~ "+0ms",
                                        Condition.Exposure == "Shift10" ~ "+10ms",
                                        Condition.Exposure == "Shift40" ~ "+40ms"),
         Exposure_block = factor(case_when(Block == 2 ~ "Exposure 1",
                                Block == 4 ~ "Exposure 2",
                                Block == 6 ~ "Exposure 3"))) %>% 
           ggplot(aes(x = descale(VOT_gs, VOT.mean_exposure, VOT.sd_exposure), 
                      y = estimate__, 
                      group = Condition.Exposure)) +
           geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = Condition.Exposure), alpha = .1) +
           geom_line(aes(color = Condition.Exposure), 
                     size = 1) +
           stat_summary(
             data = d.test_exposure_for_analysis %>%
               filter(Phase == "exposure" & Item.Labeled == FALSE) %>%
               mutate(Condition.Exposure =
                        case_when(Condition.Exposure == "Shift0" ~ "+0ms",
                                  Condition.Exposure == "Shift10" ~ "+10ms",
                                  Condition.Exposure == "Shift40" ~ "+40ms"),
                      Exposure_block = factor(case_when(Block == 2 ~ "Exposure 1",
                                Block == 4 ~ "Exposure 2",
                                Block == 6 ~ "Exposure 3"))) %>%
               group_by(Condition.Exposure, Exposure_block),
             fun.data = mean_cl_boot,
             mapping = aes(x = Item.VOT,
                           y = Response.Voiceless,
               colour = Condition.Exposure),
             geom = "pointrange",
             size = 0.2,
             position = position_dodge2(width = 2),
             inherit.aes = F) +
           scale_x_continuous("VOT (msec)", limits = c(-20, 135)) +
           scale_y_continuous("Proportion \"t\"-responses") +
           scale_color_manual(
             "Condition",
             labels = c("+0ms", "+10ms", "+40ms"),
             values = c("#cc0000", "#12D432","#0481F3"),
             aesthetics = c("color", "fill")) +
           facet_wrap(
             . ~ Exposure_block,
             nrow = 1) + 
           theme(legend.position = "top")
```






```{r, results='hide', warning=FALSE}
cond_fit <- conditional_effects(
    fit_mix_uniform_bias,
    effects = "VOT_gs:Condition.Exposure",
    conditions = make_conditions(
      d.test_exposure_for_analysis %>% 
        filter(Phase == "test") %>% 
        prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = "difference"), 
      vars = c("Block")),
    method = "posterior_epred",
    ndraws = 500,
    re_formula = NA)

p.fit <- cond_fit[[1]] %>%
  mutate(Condition.Exposure = case_when(Condition.Exposure == "Shift0" ~ "+0ms",
                                        Condition.Exposure == "Shift10" ~ "+10ms",
                                        Condition.Exposure == "Shift40" ~ "+40ms"),
         Test_block = factor(case_when(Block == 1 ~ "Test 1",
                                Block == 3 ~ "Test 2",
                                Block == 5 ~ "Test 3",
                                Block == 7 ~ "Test 4",
                                Block == 8 ~ "Test 5",
                                Block == 9 ~ "Test 6"))) %>% 
           ggplot(aes(x = descale(VOT_gs, VOT.mean_testblock1, VOT.sd_test), 
                      y = estimate__, 
                      group = Condition.Exposure)) +
           geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = Condition.Exposure), alpha = .1) +
           geom_line(aes(color = Condition.Exposure), 
                     size = 1) +
           geom_rug(data = d.test_exposure_for_analysis %>%
                      ungroup() %>% 
                      distinct(Item.VOT),
                    aes(x = Item.VOT),
                    alpha = 0.5,
                    colour = "grey",
                    inherit.aes = F) +
           stat_summary(
             data = d.test_exposure_for_analysis %>%
               filter(Phase == "test") %>%
               mutate(Condition.Exposure =
                        case_when(Condition.Exposure == "Shift0" ~ "+0ms",
                                  Condition.Exposure == "Shift10" ~ "+10ms",
                                  Condition.Exposure == "Shift40" ~ "+40ms"),
                      Test_block = factor(case_when(Block == 1 ~ "Test 1",
                                Block == 3 ~ "Test 2",
                                Block == 5 ~ "Test 3",
                                Block == 7 ~ "Test 4",
                                Block == 8 ~ "Test 5",
                                Block == 9 ~ "Test 6"))) %>%
               group_by(Condition.Exposure, Test_block),
             fun.data = mean_cl_boot,
             mapping = aes(x = Item.VOT,
                           y = Response.Voiceless,
               colour = Condition.Exposure),
             geom = "pointrange",
             size = 0.2,
             position = position_dodge2(width = 2),
             inherit.aes = F) +
           scale_x_continuous("VOT (msec)", limits = c(-5, 75), breaks = c(-5, 5, 15, 25, 35,45, 55, 70)) +
           scale_y_continuous("Proportion \"t\"-responses") +
           scale_color_manual(
             "Condition",
             labels = c("+0ms", "+10ms", "+40ms"),
             values = c("#cc0000", "#12D432","#0481F3"),
             aesthetics = c("color", "fill")) +
           facet_wrap(
             . ~ Test_block,
             nrow = 2) + 
           theme(legend.position = "top")
```



```{r fitted-categorisation-function-condition-block, fig.width=6, fig.height=4.5}
p.fit 
```



```{r}
# nested models for extracting the 'intercepts' and 'slopes' for each Block and Condition
fit_mix_nested <- brm(
  bf(
    Response.Voiceless ~ 1,
    mu1 ~ 0 + offset(0),
    mu2 ~  0 + I(paste(Condition.Exposure, Block, sep = "x")) / VOT_gs + 
      (0 + Block / VOT_gs | ParticipantID) + 
      (0 + I(paste(Condition.Exposure, Block, sep = "x")) / VOT_gs | Item.MinimalPair),
    theta1 ~ 1),
  data = d.test_exposure_for_analysis %>% 
    filter(Phase == "test") %>% 
    prepVars(levels.Condition = levels_Condition.Exposure),
  cores = 4,
  chains = chains,
  init = 0,
  iter = 4000, # iterations to run
  warmup = 2000, # samples used to fit
  family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
  control = list(adapt_delta = .99),
  file = "../models/Exp-AE-DLVOT-labelled-lapsing-GLMM-nested-no-RTexcl.rds")

# summary = F below gives all 8000 posterior samples
 temp <- 
 fixef(fit_mix_nested, summary = F, pars = gsub("^b_(mu2_.*)$", "\\1", variables(fit_mix_nested)))

# temp %>%
#   as_tibble() %>%
#   rename_with(~ paste0(.x, ":Intercept"), -ends_with("VOT_gs")) %>%
#   mutate(draw = rownames(temp)) %>%
#   relocate(draw, everything()) %>%
#   pivot_longer(
#     cols = -draw, 
#     names_pattern = "Shift([0-9]+x[0-9]+):(.*)",
#     names_to = c("ConditionBlock", "Parameter")) %>%
#   separate(
#     col = ConditionBlock,
#     sep = "x",
#     into = c("Condition", "Block")) %>%
#   pivot_wider(
#     values_from = value,
#     names_from = Parameter) %>%
#   mutate(PSE = descale(-Intercept / VOT_gs, VOT.mean_testblock1, VOT.sd_test)) %>%
#   # Get HDCI or SE
#   group_by(Condition, Block) %>% 
#   summarise(lower = quantile(PSE, probs = .025),
#             median = quantile(PSE, probs = .5),
#             upper = quantile(PSE, probs = .975))


# tidy output of nested model and separate terms into intercepts and slopes
Intercepts_slopes <- tidy(fit_mix_nested, effects = "fixed") %>% 
  filter(term != "theta1_(Intercept)") %>% 
  mutate(term = gsub("mu2_IpasteCondition.ExposureBlocksepEQxShift(\\d{1,2})x(\\d{1}.*$)", "Shift\\1.\\2", term),
         parameter = ifelse(str_detect(term, "VOT_gs"), "slope", "Intercept")) %>% 
  separate(col = term, into = c("Condition.Exposure", "Block"), sep = "\\.") %>% 
  mutate(Block = ifelse(str_detect(Block, "VOT"), str_replace(Block, "(\\d{1}):VOT_gs", "\\1"), Block)) 
```




```{r, warning=FALSE}
# alternative way to get posterior draws using gather_draws
d.PSE <- fit_mix_nested %>% 
  gather_draws(`b_mu2_IpasteCondition.ExposureBlocksepEQ.*`, regex = TRUE, ndraws = 8000) %>% 
  mutate(.variable = gsub("b_mu2_IpasteCondition.ExposureBlocksepEQxShift(\\d{1,2})x(\\d{1}.*$)", "Shift\\1.\\2", .variable),
         term = ifelse(str_detect(.variable, "VOT_gs"), "slope", "Intercept")) %>% 
  separate(col = .variable, into = c("Condition.Exposure", "Block"), sep = "\\.") %>% 
  mutate(Block = ifelse(str_detect(Block, "VOT"), str_replace(Block, "(\\d{1}):VOT_gs", "\\1"), Block)) %>% 
  pivot_wider(names_from = term, values_from = ".value") %>% 
  relocate(c(Condition.Exposure, Block, Intercept, slope, .chain, .iteration, .draw)) %>% 
  mutate(PSE = descale(-Intercept/slope, VOT.mean_testblock1, VOT.sd_test)) %>% 
  group_by(Condition.Exposure, Block) %>% 
  mutate(Block = factor(case_when(Block == 1 ~ "1",
                                Block == 3 ~ "2",
                                Block == 5 ~ "3",
                                Block == 7 ~ "4",
                                Block == 8 ~ "5",
                                Block == 9 ~ "6"))) %>% 
  summarise(lower = quantile(PSE, probs = .025),
            mean = mean(PSE),
            upper = quantile(PSE, probs = .975))

p.PSE <- d.PSE %>% 
  ggplot(aes(x = Block, y = median, colour = Condition.Exposure, group = Condition.Exposure)) +
  geom_point(position = position_dodge(.3), size = 2) +
  geom_linerange(aes(ymin = lower, ymax = upper), linewidth = 1, position = position_dodge(.3), alpha = .5) +
  stat_summary(geom = "line", position = position_dodge(.3)) +
  geom_hline(yintercept = 27.1, linetype = 2, linewidth = 0.8, colour = "#cc0000", alpha = 0.8) +
  geom_hline(yintercept = 27.1 + 10, linetype = 2, linewidth = .8, colour = "#12D432", alpha = 0.5) +
  geom_hline(yintercept = 27.1 + 40, linetype = 2, linewidth = .8, colour = "#0481F3", alpha = 0.5) +
  scale_colour_manual("Condition",
    labels = c("+0ms", "+10ms", "+40ms"),
    values = c("#cc0000", "#12D432","#0481F3"),
    aesthetics = "color") +
  scale_y_continuous("Median PSE (ms)", limits = c(24.5, 67.5), breaks = seq(25, 65.5, 5)) +
  scale_x_discrete("Test block") +
  theme(legend.position = "top")

fit_mix_nested %>% 
  gather_draws(`b_mu2_IpasteCondition.ExposureBlocksepEQ.*`, regex = TRUE, ndraws = 8000) %>% 
  mutate(.variable = gsub("b_mu2_IpasteCondition.ExposureBlocksepEQxShift(\\d{1,2})x(\\d{1}.*$)", "Shift\\1.\\2", .variable),
         term = ifelse(str_detect(.variable, "VOT_gs"), "slope", "Intercept")) %>% 
  separate(col = .variable, into = c("Condition.Exposure", "Block"), sep = "\\.") %>% 
  mutate(Block = ifelse(str_detect(Block, "VOT"), str_replace(Block, "(\\d{1}):VOT_gs", "\\1"), Block)) %>% 
  pivot_wider(names_from = term, values_from = ".value") %>% 
  relocate(c(Condition.Exposure, Block, Intercept, slope, .chain, .iteration, .draw)) %>% 
  mutate(PSE = descale(-Intercept/slope, VOT.mean_testblock1, VOT.sd_test))%>% 
  group_by(Block) %>% 
  mutate(Block = factor(case_when(Block == 1 ~ "1",
                                Block == 3 ~ "2",
                                Block == 5 ~ "3",
                                Block == 7 ~ "4",
                                Block == 8 ~ "5",
                                Block == 9 ~ "6"))) %>% 
  summarise(lower = quantile(PSE, probs = .025),
            median = quantile(PSE, probs = .5),
            upper = quantile(PSE, probs = .975))
```



```{r}
d.params <- temp %>%
  as_tibble() %>%
  rename_with(~ paste0(.x, ":Intercept"), -ends_with("VOT_gs")) %>%
  mutate(draw = rownames(temp)) %>%
  relocate(draw, everything()) %>%
  pivot_longer(
    cols = -draw, 
    names_pattern = "Shift([0-9]+x[0-9]+):(.*)",
    names_to = c("ConditionBlock", "Parameter")) %>%
  separate(
    col = ConditionBlock,
    sep = "x",
    into = c("Condition", "Block")) %>%
  pivot_wider(
    values_from = value,
    names_from = Parameter) %>%
  # Get HDCI or SE
  group_by(Condition, Block) %>% 
  mutate(Block = factor(case_when(Block == 1 ~ "1",
                                Block == 3 ~ "2",
                                Block == 5 ~ "3",
                                Block == 7 ~ "4",
                                Block == 8 ~ "5",
                                Block == 9 ~ "6"))) %>% 
  summarise(Intercept.lower = quantile(Intercept, probs = .025),
            Intercept.mean = mean(Intercept),
            Intercept.upper = quantile(Intercept, probs = .975),
            VOT_gs.lower = quantile(VOT_gs, probs = .025),
            VOT_gs.mean = mean(VOT_gs),
            VOT_gs.upper = quantile(VOT_gs, probs = .975))

p.intercepts <- d.params %>% 
  ggplot(aes(x = Block, y = Intercept.mean, colour = Condition, group = Condition)) +
  geom_point(aes(colour = Condition), 
             position = position_dodge(.3), size = 2.5) +
  geom_linerange(aes(ymin = Intercept.lower, ymax = Intercept.upper), linewidth = 1.2, position = position_dodge(.3), alpha = .5) +
  stat_summary(geom = "line", position = position_dodge(.3)) +
  scale_colour_manual("Condition",
    labels = c("+0ms", "+10ms", "+40ms"),
    values = c("#cc0000", "#12D432","#0481F3"),
    aesthetics = "color") + 
  scale_y_continuous("Intercept") +
  theme(legend.position = "top",
        axis.title.x = element_blank(),
        axis.ticks = element_blank(),
        axis.text.x = element_blank())

p.slopes <- d.params %>% 
  ggplot(aes(x = Block, y = VOT_gs.mean, colour = Condition, group = Condition)) +
  geom_point(position = position_dodge(.3), size = 2.5) +
  geom_linerange(aes(ymin = VOT_gs.lower, ymax = VOT_gs.upper), 
                 linewidth = 1.2, position = position_dodge(.3), alpha = .5) +
  stat_summary(geom = "line", position = position_dodge(.3)) +
  scale_colour_manual("Condition",
    labels = c("+0ms", "+10ms", "+40ms"),
    values = c("#cc0000", "#12D432","#0481F3"),
    aesthetics = "color") +
  scale_y_continuous("Slope") +
  xlab("Test block") +
  theme(legend.position = "top") 
```




```{r, fig.width=6.5, fig.height=4.5}
p.params <- ((p.intercepts / p.slopes) | (p.PSE)) + 
  plot_layout(ncol = 2, guides = "collect") &
  theme(legend.position = "none", axis.text = element_text(size = 8))

ggsave("p.params_exp2.png", p.params, width = 14, height = 8, units = "cm", path = "~/Desktop/")
```


```{r compare-density-database-with-exposure-means, fig.width=6.5, fig.height=4.5}
d.chodroff_wilson.selected %>% 
  ggplot(aes(x = VOT_centered, y = f0_Mel_centered, colour = category, group = category)) +
  geom_density2d() +
  scale_colour_manual(values = c("/d/" = "#000000", "/t/" = "#a6a6a6")) +
  scale_y_continuous("F0_Mel", limits = c(160, 320), breaks = seq(0, 320, 25)) +
  scale_x_continuous("VOT (ms)", limits = c(-2, 95), breaks = seq(0, 95, 10)) +
  theme(legend.position = "top",
        axis.text = element_text(size = 10)) +
  guides(colour = guide_legend("Category")) +
  new_scale_color() +
  geom_point(
    data = d.test_exposure_for_analysis %>% 
      filter(Phase == "exposure") %>% 
      group_by(Condition.Exposure) %>%
      mutate(
        category = factor(ifelse(Item.ExpectedResponse.Voicing == "voiced", "/d/", "/t/")),
        Item.VOT_centered = Item.VOT + (chodroff.mean_VOT - VOT.mean_exp2),
        Item.Mel_F0_5ms_centered = Item.Mel_F0_5ms + (chodroff.mean_f0_Mel - f0.mean_exp2)) %>% 
      group_by(Condition.Exposure, category) %>% 
      summarise(across(c(Item.VOT_centered, Item.Mel_F0_5ms_centered), mean)),
    mapping = aes(x = Item.VOT_centered, y = Item.Mel_F0_5ms_centered, colour = Condition.Exposure, shape = category),
    size = 2,
    alpha = 0.8,
  inherit.aes = F) +
  scale_colour_manual("Condition",
             labels = c("+0ms", "+10ms", "+40ms"),
             values = c("#cc0000", "#12D432","#0481F3")) +
  guides(colour = "none",
         shape = guide_legend("Category")) +
  theme(legend.justification = "right")

#ggsave("density_plot.png", last_plot(), width = 11, height = 8.3, units = "cm", path = "~/Desktop/")
```









```{r make-dataframe-for-logistic-regression-on-predicted-probs-by-IOs}
# get the actual means and variances of the exposure stimuli during the experiment
d.summarystats_exposure <- d.test_exposure_for_analysis %>% 
  filter(Phase == "exposure") %>% 
  mutate(Category = ifelse(Item.ExpectedResponse.Voicing == "voiced", "/d/", "/t/")) %>% 
  group_by(Condition.Exposure, Category) %>% 
  # get all exposure rows from one participant per condition
  slice_head(n = 144) %>% 
  summarise(mean = mean(Item.VOT, na.rm = T),
            var = var(Item.VOT, na.rm = T))

exposure_shift0_mean_d <- (d.summarystats_exposure %>% pull(mean))[1]
exposure_shift0_mean_t <- (d.summarystats_exposure %>% pull(mean))[2]
exposure_shift10_mean_d <- (d.summarystats_exposure %>% pull(mean))[3]
exposure_shift10_mean_t <- (d.summarystats_exposure %>% pull(mean))[4]
exposure_shift40_mean_d <- (d.summarystats_exposure %>% pull(mean))[5]
exposure_shift40_mean_t <- (d.summarystats_exposure %>% pull(mean))[6]

exposure_var_d <- (d.summarystats_exposure %>% pull(var))[1]
exposure_var_t <- (d.summarystats_exposure %>% pull(var))[2] 

x <- d.test_exposure_for_analysis %>% 
  filter(Phase == "test") %>% 
  distinct(Item.VOT) %>%
  pull()

conditions <- tibble(
  condition = c("shift0", "shift10", "shift40")) 
  
ios <- tibble(
  category = factor(c("/d/", "/t/")),
  Sigma = list(matrix(sqrt(exposure_var_d)), matrix(sqrt(exposure_var_t))),
  prior = c(.5, .5),
  lapse_rate = c(0, 0),
  lapse_bias = c(.5, .5),
  Sigma_noise = list(matrix(80), matrix(80))
  )

io.conditions <- crossing(conditions, ios) %>% 
  cbind(tibble(mu = list(c(VOT = exposure_shift0_mean_d), c(VOT = exposure_shift0_mean_t), c(VOT = exposure_shift10_mean_d), c(VOT = exposure_shift10_mean_t), c(VOT = exposure_shift40_mean_d), c(VOT = exposure_shift40_mean_t)))) %>% 
  relocate(c(condition, category, mu)) %>% 
  nest(io = -c(condition)) %>% 
  crossing(x) %>% 
  mutate(x = map(x, ~ c(.x))) %>% 
  nest(x = x)

d.io.categorisation <- io.conditions %>% 
  mutate(categorisation = 
           map2(x, io,
          ~ get_categorization_from_MVG_ideal_observer(x = .x$x, model = .y, decision_rule = "proportional") %>% 
            mutate(VOT = map(x, ~ .x[1]) %>% unlist()))) %>%
  unnest(cols = categorisation, names_repair = "unique") %>% 
  select(c(condition, io, category, response, VOT)) %>% 
  pivot_wider(names_from = category, values_from = response, names_prefix = "response_") %>% 
  mutate(n_d = round(`response_/d/` * 10^9),
         n_t = 10^9 - n_d)

d.io.categorisation %>%
  group_by(condition) %>% 
  nest() %>% 
  mutate(model_unscaled = map(data, ~ glm(cbind(n_t, n_d) ~ 1 + VOT, family = binomial, data = .x)),
         intercept_unscaled = map_dbl(model_unscaled, ~ tidy(.x)[1,2] %>% pull()),
         slope_unscaled = map_dbl(model_unscaled, ~ tidy(.x)[2,2] %>% pull()), 
         model_scaled = map(data, ~ glm(cbind(n_t, n_d) ~ 1 + I((VOT - VOT.mean_testblock1)/ (2 * VOT.sd_test)), family = binomial, data = .x)),
         intercept_scaled = map_dbl(model_scaled, ~ tidy(.x)[1,2] %>% pull()),
         slope_scaled = map_dbl(model_scaled, ~ tidy(.x)[2,2] %>% pull()),
           PSE = -intercept_unscaled/slope_unscaled)
```




\newpage

<!-- This is a markdown comment that will NOT show when you knit the document.  -->

All data and code for this article can be downloaded from[https://osf.io/q7gjp/](OSF). This article is written in R markdown, allowing readers to replicate our analyses with the press of a button using freely available software [R, @R; @RStudio], while changing any of the parameters of our models. Readers can revisit any of the assumptions we make---for example, by substituting alternative models of linguistic representations. The supplementary information (SI, \@ref(sec:SI-software)) lists the software/libraries required to compile this document. Beyond our immediate goals here, we hope that this can be helpful to researchers who are interested in developing more informative experimental designs, and to facilitate the interpretation of existing results [see also @tan2021]. 