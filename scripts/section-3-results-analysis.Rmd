```{r load-libraries}
require(tidyverse)
require(magrittr)

require(brms)
require(MVBeliefUpdatr)
require(phonR)
require(rsample)

source("functions.R")
```

## Results

```{r model-fit-test-blocks, include=FALSE}
# Storing some information about the data set submitted for analysis
# (to facilitate unscaling predictions back into the original scales for plotting)
d.mean_sd_scaling <-
  d_for_analysis %>%
  group_by(Phase) %>%
  filter(Item.Labeled == FALSE) %>%
  summarise(across(Item.VOT, list(mean = mean, sd = sd)))

VOT.mean_exposure <- (d.mean_sd_scaling %>% pull(Item.VOT_mean))[1]
VOT.sd_exposure <- (d.mean_sd_scaling %>% pull(Item.VOT_sd))[1]
VOT.mean_test <- (d.mean_sd_scaling %>% pull(Item.VOT_mean))[2]
VOT.sd_test <- (d.mean_sd_scaling %>% pull(Item.VOT_sd))[2]

levels_Condition.Exposure = c("Shift0", "Shift10", "Shift40")
contrast_type <- "difference"

# Simplifying model with uniform bias
fit_mix_test <-
  brm(
    bf(
      Response.Voiceless ~ 1,
      mu1 ~ 0 + offset(0),
      mu2 ~ 1 + VOT_gs * Condition.Exposure * Block +
        (1 + VOT_gs * Block | ParticipantID) +
        (1 + VOT_gs * Condition.Exposure * Block | Item.MinimalPair),
      theta1 ~ 1),
    data = d_for_analysis %>%
      filter(Phase == "test") %>%
      prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = contrast_type),
    cores = chains,
    chains = chains,
    init = 0,
    iter = 4000,
    warmup = 2000,
    family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
    control = list(adapt_delta = .99),
    file = "../models/Exp-AE-DLVOT-labelled-lapsing-GLMM-difference-no-RTexcl.rds")

# fit difference coded model on exposure block
fit_mix_exposure <-
  update(
    fit_mix_test,
    newdata = d_for_analysis %>%
      filter(Phase == "exposure" & Item.Labeled == FALSE) %>%
      prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = contrast_type),
    file = "../models/Exp-AE-DLVOT-lapsing-differencecoded-exposureblocks.rds")

# fit test block with sampled priors

```

We analyzed participants' categorisation responses during exposure and test blocks in two separate Bayesian mixed-effects psychometric models, using brms [@R-brms_a] in R [@R; @RStudio, for details, see SI, \@ref(sec:analysis-approach)]. Psychometric models account for attentional lapses while estimating participants' categorisation functions. Failing to account for attentional lapses---while commonplace in research on speech perception [but see @clayards2008; @kleinschmidt-jaeger2016]---can lead to biased estimates of categorization boundaries [@prins2012; @wichmann2001]. For the present experiment, however, lapse rates were negligible (`r make_CI(fit_mix_test, "theta1_Intercept")`), and all results replicate in simple mixed-effects logistic regressions [@jaeger2008]. 

Each psychometric model regressed participants' categorisation responses against the full factorial interaction of VOT, exposure condition, and block, while including the maximal random effect structure (see SI, \@ref(sec:analysis-approach). Figure \@ref(fig:plot-fit-slope-PSE) summarizes the results that we describe in more detail next. Panels A and B show participantsâ€™ categorisation responses during exposure and test blocks, along with the categorisation function estimated from those responses via the mixed-effects psychometric models. These panels facilitate comparison between exposure conditions within each block. Panels C and D show the slope and point of subject equality (PSE)---i.e., the point at which participants are equally likely to respond "d" and "t"---of the categorisation function across blocks and conditions. These panels facilitate comparison across blocks within each exposure condition. Here we focus on the test blocks, which were identical within and across exposure conditions. Analyses of the exposure blocks are reported in the SI (\@ref(sec:exposure-analyses)), and replicate all effects found in the test blocks. 

We begin by presenting the overall effects, averaging across all test blocks. This part of our analysis matches previous work, which has focused on the overall effect of exposure across the entire experiment ['batch tests', e.g., @clayards2008; @kleinschmidt2016; @nixon2016; @theodore-monto2019] and/or during a single post-exposure test block [e.g., @kleinschmidt2020]. Then we turn to the goals of this study---to characterize the incremental changes in participants' categorisation responses as a function of exposure and, in particular, to test 1) whether we replicate the sublinear effects of exposure observed in previous work under the ecologically more valid stimuli and distributions employed in the present work, and 2) whether we can begin to distinguish between the predictions of the model learning and selection hypotheses. 

```{r fit-nested-models-for-intercepts-slopes-plot, message=FALSE}
# Refit the same model, formulated as nesting intercepts and slopes within each unique combination of
# exposure condition and block. This makes it easier to extract the intercept, slope, and PSE for the
# large result figure (Panels C and D).
fit_mix_test_nested <-
  brm(
    bf(
      Response.Voiceless ~ 1,
      mu1 ~ 0 + offset(0),
      mu2 ~  0 + I(paste(Condition.Exposure, Block, sep = "x")) / VOT_gs +
        (0 + Block / VOT_gs | ParticipantID) +
        (0 + I(paste(Condition.Exposure, Block, sep = "x")) / VOT_gs | Item.MinimalPair),
      theta1 ~ 1),
    data = d_for_analysis %>%
      filter(Phase == "test") %>%
      prepVars(levels.Condition = levels_Condition.Exposure, constrast_type = "difference"),
    cores = chains,
    chains = chains,
    init = 0,
    iter = 4000, # iterations to run
    warmup = 2000, # samples used to fit
    family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
    control = list(adapt_delta = .99),
    file = "../models/Exp-AE-DLVOT-lapsing-nested-test.rds")

fit_mix_exposure_nested <-
  update(
    fit_mix_test_nested,
    newdata = d_for_analysis %>%
      filter(Phase == "exposure") %>%
      prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = "difference"),
    file = "../models/Exp-AE-DLVOT-lapsing-nested-exposure.rds")

# Extract intercepts and slopes from test and exposure model
get_intercepts_and_slopes <-
  . %>%
  gather_draws(`b_mu2_IpasteCondition.ExposureBlocksepEQ.*`, regex = TRUE, ndraws = 8000) %>%
  mutate(.variable = gsub("b_mu2_IpasteCondition.ExposureBlocksepEQxShift(\\d{1,2})x(\\d{1}.*$)", "Shift\\1.\\2", .variable),
         term = ifelse(str_detect(.variable, "VOT_gs"), "slope", "Intercept")) %>%
  separate(col = .variable, into = c("Condition.Exposure", "Block"), sep = "\\.") %>%
  mutate(Block = ifelse(str_detect(Block, "VOT"), str_replace(Block, "(\\d{1}):VOT_gs", "\\1"), Block)) %>%
  pivot_wider(names_from = term, values_from = ".value") %>%
  relocate(c(Condition.Exposure, Block, Intercept, slope, .chain, .iteration, .draw))

d.estimates <-
  full_join(
    fit_mix_test_nested %>% get_intercepts_and_slopes(),
    fit_mix_exposure_nested %>% get_intercepts_and_slopes()) %>%
  mutate(
    PSE = ifelse(
      Block %in% c(2, 4, 6),
      descale(-Intercept/slope, VOT.mean_exposure, VOT.sd_exposure),
      descale(-Intercept/slope, VOT.mean_test, VOT.sd_test))) %>%
  group_by(Condition.Exposure, Block) %>%
  summarise(
    across(
      c(Intercept, slope, PSE),
      list(lower = ~ quantile(.x, probs = .025), mean = mean, upper = ~ quantile(.x, probs = .975))))
```

```{r predictions-exposure-conditions-by-IOs, warning=FALSE}
x <-
  d_for_analysis %>%
  filter(Phase == "test") %>%
  distinct(Item.VOT) %>%
  pull()

# Make ideal observer based on exposure conditions
io <- 
  d_for_analysis %>%
  filter(Phase == "exposure") %>%
  mutate(category = ifelse(Item.ExpectedResponse.Voicing == "voiced", "/d/", "/t/")) %>%
  rename(VOT = Item.VOT, f0 = Item.F0) %>%
  make_MVG_ideal_observer_from_data(
    group = "Condition.Exposure", 
    cues = c("VOT"), 
    Sigma_noise = matrix(80, dimnames = list("VOT", "VOT"))) %>%
  nest(io = -c(Condition.Exposure)) 

# Estimate the intercept, slope, and PSE that these ideal observers would have 
# were they analyzed the same way the human data is analyzed.
d.io.categorisation <-
  io %>%
  # Cross in test tokens
  crossing(x) %>%
  mutate(x = map(x, ~ c(.x))) %>%
  nest(x = x) %>%
  # Get categorisation proportions (turned into counts below)
  mutate(
    categorisation =
      map2(x, io,
           ~ get_categorization_from_MVG_ideal_observer(
             x = .x$x, model = .y, decision_rule = "proportional") %>%
             mutate(VOT = map(x, ~ .x[1]) %>% unlist()))) %>%
  unnest(cols = categorisation, names_repair = "unique") %>%
  # Prepare data frame for logistic regression 
  select(Condition.Exposure, io, category, response, VOT) %>%
  pivot_wider(names_from = category, values_from = response, names_prefix = "response_") %>%
  mutate(n_d = round(`response_/d/` * 10^9), n_t = 10^9 - n_d) %>%
  group_by(Condition.Exposure) %>%
  nest() %>%
  mutate(
    model_unscaled = map(data, ~ glm(cbind(n_t, n_d) ~ 1 + VOT, family = binomial, data = .x)),
    intercept_unscaled = map_dbl(model_unscaled, ~ tidy(.x)[1, 2] %>% pull()),
    slope_unscaled = map_dbl(model_unscaled, ~ tidy(.x)[2, 2] %>% pull()),
    model_scaled = map(data, ~ glm(cbind(n_t, n_d) ~ 1 + I((VOT - VOT.mean_test)/ (2 * VOT.sd_test)), family = binomial, data = .x)),
    intercept_scaled = map_dbl(model_scaled, ~ tidy(.x)[1, 2] %>% pull()),
    slope_scaled = map_dbl(model_scaled, ~ tidy(.x)[2, 2] %>% pull()),
    PSE = -intercept_unscaled/slope_unscaled)
```

```{r prepare-plot-intercepts-slopes}
p.across_blocks <-
  d.estimates %>%
  ggplot(aes(
    x = Block, y = Intercept_mean, 
    ymin = Intercept_lower, ymax = Intercept_upper,
    colour = Condition.Exposure, group = Condition.Exposure)) +
  geom_rect(
    data = tibble(
      xmin = c(seq(0.55, 6.55, 2), seq(7.55, 8.55, 1)), 
      xmax = c(seq(1.45, 7.45, 2), seq(8.45, 9.45, 1))),
    aes(xmin = xmin, xmax = xmax),
    ymin = -Inf, ymax = Inf, fill = "grey", alpha = .1, inherit.aes = F) +
  geom_point(position = position_dodge(.3), size = 1) +
  geom_linerange(linewidth = .6, position = position_dodge(.3), alpha = .5) +
  stat_summary(geom = "line", position = position_dodge(.3)) +
  scale_x_discrete("Block", labels = c("1" = "Test 1", "2" = "Exposure 1", "3" = "Test 2", "4" = "Exposure 2", "5" = "Test 3", "6" = "Exposure 3", "7" = "Test 4", "8" = "Test 5", "9" = "Test 6")) +
  scale_colour_manual("Condition",
    labels = c("baseline", "+10ms", "+40ms"),
    values = colours.condition,
    aesthetics = "color") +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 22.5, hjust = 1))

p.intercept_1to7 <-
  p.across_blocks +  
  scale_y_continuous("intercept") +
  geom_hline(
    data = d.io.categorisation,
    aes(yintercept = intercept_scaled, color = Condition.Exposure),
    linetype = 2, linewidth = .8, alpha = 0.5)

p.slope_1to7 <-
  p.across_blocks +  
  scale_y_continuous("slope") +
  aes(y = slope_mean, ymin = slope_lower, ymax = slope_upper) +
  geom_hline(
    data = d.io.categorisation,
    aes(yintercept = slope_scaled, color = Condition.Exposure),
    linetype = 2, linewidth = .8, alpha = 0.5) 

p.PSE_1to7 <- 
  p.across_blocks +  
  scale_y_continuous("PSE") +
  aes(y = PSE_mean, ymin = PSE_lower, ymax = PSE_upper) +
  geom_hline(
    data = d.io.categorisation,
    aes(yintercept = PSE, color = Condition.Exposure),
    linetype = 2, linewidth = .8, alpha = 0.5) +
  annotate("label", x = 5.2, y = 64, label = "true shift = +21ms \n (max prop. of shift = 38%)", size = 2, colour = "blue") +
  annotate("label", x = 7.3, y = 32, label = "true shift = -10ms \n (max prop. of shift = 40%)", size = 2, colour = "dark green") +
  annotate("label", x = 3.3, y = 30, label = "true shift = -18ms \n (max prop. of shift = 22%)", size = 2, colour = "red") 

p.params_1to7 <- (p.slope_1to7 | p.PSE_1to7) +
  plot_layout(guides = "collect") &
  theme(legend.position = "none", axis.text = element_text(size = 8))
```

```{r plot-test-exposure-fit, fig.width=11, fig.height=3, message=FALSE}
get_conditional_effects <- function(model, data, phase) {
  conditional_effects(
    x = model,
    effects = "VOT_gs:Condition.Exposure",
    conditions = make_conditions(
      data %>%
        filter(Phase == .env$phase & Item.Labeled == FALSE) %>%
        prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = "difference"),
      vars = c("Block")),
    method = "posterior_epred",
    ndraws = 500,
    re_formula = NA)
}

cond_fit_test_exposure <-
  tibble(
    full_join(
      get_conditional_effects(fit_mix_exposure, d_for_analysis, "exposure") %>%
        .[[1]] %>%
        mutate(Item.VOT = descale(VOT_gs, VOT.mean_exposure, VOT.sd_exposure)),
      get_conditional_effects(fit_mix_test, d_for_analysis, "test") %>%
        .[[1]] %>%
        mutate(Item.VOT = descale(VOT_gs, VOT.mean_test, VOT.sd_test)))) %>%
  arrange(as.numeric(as.character(Block))) %>%
  mutate(
    Phase = ifelse(Block %in% c(1, 3, 5, 7, 8, 9), "test", "exposure"),
    Condition.Exposure = case_when(
    Condition.Exposure == "Shift0" ~ "baseline",
    Condition.Exposure == "Shift10" ~ "+10ms",
    Condition.Exposure == "Shift40" ~ "+40ms"), 
    Condition.Exposure = fct_relevel(
          Condition.Exposure, c("baseline", "+10ms", "+40ms")),
    Block = factor(case_when(
      Block == 1 ~ "Test 1",
      Block == 3 ~ "Test 2",
      Block == 5 ~ "Test 3",
      Block == 7 ~ "Test 4",
      Block == 8 ~ "Test 5",
      Block == 9 ~ "Test 6",
      Block == 2 ~ "Exposure 1",
      Block == 4 ~ "Exposure 2",
      Block == 6 ~ "Exposure 3")),
    Block = fct_relevel(Block, c("Test 1", "Exposure 1", "Test 2", "Exposure 2", "Test 3", "Exposure 3",  "Test 4", "Test 5", "Test 6")))

label_colour <- tibble(
  Block = c("Test 1", "Exposure 1", "Test 2", "Exposure 2", "Test 3", "Exposure 3", "Test 4"),
  Block.colour = c("grey", "black", "grey", "black", "grey", "black", "grey")) %>%
  mutate(Block = factor(Block, levels = Block, ordered = T))

p.fit_1to7 <- cond_fit_test_exposure %>%
  filter(Block %in% c("Test 1", "Exposure 1", "Test 2", "Exposure 2", "Test 3", "Exposure 3", "Test 4")) %>%
  ggplot() +
  geom_rect(
    data = label_colour,
    aes(xmin = -Inf, xmax = Inf,
        ymin = 1.05, ymax = 1.3,
        fill = Block.colour), show.legend = F) +
  scale_fill_manual(values = c("grey" = "grey", "black" = "white")) +
  new_scale_fill() +
  geom_ribbon(aes(
    x = Item.VOT,
    y = estimate__,
    group = Condition.Exposure,
    ymin = lower__, ymax = upper__, fill = Condition.Exposure), alpha = .1) +
  geom_line(aes(
    x = Item.VOT,
    y = estimate__,
    group = Condition.Exposure,
    color = Condition.Exposure),
    linewidth = .7,
    alpha = 0.6) +
  geom_rug(data = d_for_analysis %>%
             group_by(Phase, Block) %>%
             filter(Block %in% c(1:7)) %>%
             mutate(
               Block = factor(case_when(
                 Block == 1 ~ "Test 1",
                 Block == 3 ~ "Test 2",
                 Block == 5 ~ "Test 3",
                 Block == 7 ~ "Test 4",
                 Block == 2 ~ "Exposure 1",
                 Block == 4 ~ "Exposure 2",
                 Block == 6 ~ "Exposure 3")),
               Block = fct_relevel(Block, c("Test 1", "Exposure 1", "Test 2", "Exposure 2", "Test 3", "Exposure 3",  "Test 4"))) %>%
             distinct(Item.VOT),
           aes(x = Item.VOT),
           alpha = 0.5,
           colour = "grey",
           inherit.aes = F) +
  stat_summary(
    data = d_for_analysis %>%
      filter(Block %in% c(1:7), Item.Labeled == FALSE) %>%
      mutate(
        Condition.Exposure = factor(case_when(
          Condition.Exposure == "Shift0" ~ "baseline",
          Condition.Exposure == "Shift10" ~ "+10ms",
          Condition.Exposure == "Shift40" ~ "+40ms")),
        Condition.Exposure = fct_relevel(
          Condition.Exposure, c("baseline", "+10ms", "+40ms")),
        Block = factor(case_when(
          Block == 1 ~ "Test 1",
          Block == 2 ~ "Exposure 1",
          Block == 3 ~ "Test 2",
          Block == 4 ~ "Exposure 2",
          Block == 5 ~ "Test 3",
          Block == 6 ~ "Exposure 3",
          Block == 7 ~ "Test 4"))) %>%
      group_by(Condition.Exposure, Block),
    fun.data = mean_cl_boot,
    mapping = aes(x = Item.VOT,
                  y = Response.Voiceless,
                  colour = Condition.Exposure),
    geom = "pointrange",
    size = 0.1,
    alpha = 0.7,
    position = position_dodge2(width = 2),
    inherit.aes = F) +
  scale_x_continuous("VOT (msec)") +
  scale_y_continuous("Proportion \"t\"-responses") +
  scale_color_manual(
    "Condition",
    labels = c("baseline", "+10ms", "+40ms"),
    values = colours.condition,
    aesthetics = c("color", "fill")) +
  coord_cartesian(clip="off", ylim=c(0, 1)) +
  facet_grid(~ Block, scales = "free_x", space = "free_x") +
  theme(legend.position = "top",
        legend.justification = "right",
        strip.background = element_rect(fill = NA),
        strip.text.x.top = element_text(colour = "black"))

p.fit_7to9 <- cond_fit_test_exposure %>%
  filter(Block %in% c("Test 4", "Test 5", "Test 6")) %>%
  ggplot() +
  geom_ribbon(aes(
    x = Item.VOT,
    y = estimate__,
    group = Condition.Exposure,
    ymin = lower__, ymax = upper__, fill = Condition.Exposure), alpha = .1) +
  geom_line(aes(
    x = Item.VOT,
    y = estimate__,
    group = Condition.Exposure,
    color = Condition.Exposure),
    linewidth = .7,
    alpha = 0.6) +
geom_rug(data = d_for_analysis %>%
             group_by(Phase, Block) %>%
             filter(Block %in% c(7:9)) %>%
             mutate(
               Block = factor(case_when(
                 Block == 7 ~ "Test 4",
                 Block == 8 ~ "Test 5",
                 Block == 9 ~ "Test 6")),
               Block = fct_relevel(Block, c("Test 4", "Test 5", "Test 6"))) %>%
             distinct(Item.VOT),
           aes(x = Item.VOT),
           alpha = 0.5,
           colour = "grey",
           inherit.aes = F) +
  stat_summary(
    data = d_for_analysis %>%
      filter(Block %in% c(7:9), Item.Labeled == FALSE) %>%
      mutate(
        Condition.Exposure = factor(case_when(
          Condition.Exposure == "Shift0" ~ "baseline",
          Condition.Exposure == "Shift10" ~ "+10ms",
          Condition.Exposure == "Shift40" ~ "+40ms")),
        Condition.Exposure = fct_relevel(
          Condition.Exposure, c("baseline", "+10ms", "+40ms")),
        Block = factor(case_when(
          Block == 7 ~ "Test 4",
          Block == 8 ~ "Test 5",
          Block == 9 ~ "Test 6"))) %>%
      group_by(Condition.Exposure, Block),
    fun.data = mean_cl_boot,
    mapping = aes(x = Item.VOT,
                  y = Response.Voiceless,
                  colour = Condition.Exposure),
    geom = "pointrange",
    size = 0.1,
    alpha = 0.7,
    position = position_dodge2(width = 2),
    inherit.aes = F) +
  scale_x_continuous("VOT (msec)") +
  scale_y_continuous("Proportion \"t\"-responses") +
  scale_color_manual(
    "Condition",
    labels = c("baseline", "+10ms", "+40ms"),
    values = colours.condition,
    aesthetics = c("color", "fill")) +
  facet_wrap(. ~ Block, nrow = 1) +
  theme(legend.position = "none",
        legend.justification = "right",
        axis.title.y = element_blank(),
        strip.background = element_rect(fill = "grey"),
        strip.text.x = element_text(colour = "black"))

description <- tibble(
  label = c("Lorem ipsum dolor **sit amet,** consectetur adipiscing elit,
    sed do *eiusmod tempor incididunt* ut labore et dolore magna
    aliqua.", "More description about the PSEs and predicted slopes. A naive Bayesian learner is expected to converged on the dashed lines... etc..."),
  x = c(0.05, .65),
  y = c(.5, .5),
  hjust = c(0, 0),
  vjust = c(1, 1),
  orientation = c("upright", "upright"),
  color = c("black", "blue"),
  fill = c("cornsilk", "white")
)
my_text <- description %>% 
  ggplot() +
  aes(x, y, label = label, colour = color, fill = fill,
      hjust = hjust, vjust = vjust, 
      orientation = orientation) +
  geom_textbox(
    width = unit(7, "cm") 
  ) +
  scale_discrete_identity(aesthetics = c("color", "fill", "orientation")) +
  xlim(0, 1) + ylim(0, 1) +
  theme_void() +
  remove_axes_titles
```

(ref:plot-fit-slope-PSE) Summary of results. **Panel A:** Changes in listeners psychometric categorisation functions as a function of exposure, from Test 1 to Test 4 with all intervening exposure blocks (only unlabelled trials were included in the analysis of exposure blocks since labelled trials provide no information about listeners' categorization function). Point ranges indicate the mean proportion of "t"-responses and their 95% bootstrapped CI. Lines and shaded intervals show the MAP predictions and 95% posterior CIs of a Bayesian mixed-effects psychometric model fit to participants' responses. **Panel B:** Same as Panel A but for the final three test blocks without intervening exposure. Test 4 is shown as part of both Panels A and B. **Panels C \& D:** Changes across blocks in the slope and boundary (point-of-subjective-equality, PSE) of the categorisation functions shown in Panels A-B. Point ranges represent the posterior means and their 95% CI. Dashed reference lines show the intercepts and PSEs that naive (non-rational) learner would be expected to converge against after sufficient exposure (an ideal observer model that knows the exposure distributions).

\begin{landscape}
```{r plot-fit-slope-PSE, fig.width=12.5, fig.height=8, fig.cap="(ref:plot-fit-slope-PSE)"}
p.fit_1to7 + p.fit_7to9 + p.params_1to7 +
  plot_layout(
    design = "
AAAAAAAAA
BBB######
DDDDDDDDD
",
heights = c(1, 1, 2)) +
   plot_annotation(tag_levels = 'A', tag_suffix = ")") & theme(plot.tag = element_text(face = "bold")) 

p.row1 <- p.fit_1to7
p.row2 <- p.fit_7to9 + my_text
p.row3 <- p.params_1to7
```
\end{landscape}

### Does exposure affect participants' categorisations (averaging across all blocks)?
We first used the psychometric mixed-effects model to assess whether the exposure conditions had the expected effects across all test blocks *relative to each other*. Unsurprisingly, participants were more likely to respond "t" the larger the VOT ($`r get_bf(fit_mix_test, "mu2_VOT_gs > 0")`$). Critically, exposure affects participants' categorisation responses in the expected direction. Marginalizing across all blocks, participants in the +40 condition were less likely to respond "t" than participants in the +10 condition ($`r get_bf(fit_mix_test, "mu2_Condition.Exposure_Shift40vs.Shift10 < 0")`$) or the baseline condition ($`r get_bf(fit_mix_test, "mu2_Condition.Exposure_Shift40vs.Shift10 + mu2_Condition.Exposure_Shift10vs.Shift0 < 0")`$). There was also evidence---albeit less decisive---that participants in the +10 condition were less likely to respond "t" than participants in the baseline condition ($`r get_bf(fit_mix_test, "mu2_Condition.Exposure_Shift10vs.Shift0 < 0")`$). That is, the +10 and +40 conditions resulted in categorisation functions that were shifted rightwards compared to the baseline condition, as also visible in Figures \@ref(fig:plot-fit-slope-PSE).

This replicates previous findings that exposure to changed VOT distributions changes listeners' categorization responses [for /b/-/p/: @clayards2008; @kleinschmidt-jaeger2016; @kleinschmidt2020; for /g/-/k/, @theodore-monto2019]. Having established that exposure affected categorization, we turn to the questions of primary interest. Incremental changes in participants' categorisation responses can be assessed from three mutually complementing perspectives. First, we compare how exposure affects listeners' categorisation responses relative to other exposure conditions. This tests how early in the experiment differences between exposure conditions began to emerge. Second, we compare how exposure affects listeners' categorisation responses within each condition relative to listeners' responses prior to any exposure. This assesses how the exposure conditions relate to participants' prior expectations. Most importantly, however, it tests the subtly different predictions of the model learning and selection hypotheses---whether changes in listeners' categorisation responses are strongly constrained. Third and finally, we compare changes in listeners' responses to those expected from an ideal observer that has fully learned the exposure distributions. This tests whether the sublinear effects observed in @kleinschmidt-jaeger2016 replicate in our repeated exposure-test paradigm with the improvements the present study makes to ecological validity.

### Comparing across exposure conditions: How quickly does exposure begin to affect participants' responses? 
Figure \@ref(fig:plot-fit-slope-PSE)A suggests that differences between exposure conditions emerged early in the experiment: already in Test 2, listener's categorisation functions seem to be shifted rightwards (larger PSEs) in the +40 condition compared to the +10 condition, and in the +10 condition compared to the baseline condition. This is confirmed by the Bayesian hypothesis tests summarized in Table \@ref(tab:hypothesis-table-simple-effects). Prior to any exposure, during Test 1, participants' responses did not differ across exposure condition (all BFs > XXX). <!-- TO DO: fit model with save_priors =T and change hypothesis tests for block one to = 0, not < 0: fitting--> After exposure to only 24 /d/ and 24 /t/ stimuli, during Test 2, participants' responses differed between exposure conditions (BFs > 17.35). The difference between the +40 condition and the +10 or baseline condition kept increasing with exposure up to Test 4. Additional hypothesis tests in Table \@ref(tab:hypothesis-table-interactions) show that the change from Test 1 to 2 was largest (BF = 27.8), followed by the change from Test 2 to 3 (BF = 19.2), with only minimal changes from Test 3 to 4 (BF = 1.7). Qualitatively paralleling the changes across blocks for the +40 condition, the change in the difference between the +10 and baseline conditions was largest from Test 1 to 2 (BF = 13.5), and then somewhat decreased from Test 2 to Test 4 (BFs < 4). The comparison across exposure conditions thus suggests that changes in listeners' categorisation responses emerged quickly---indeed, they were present already *during* the first exposure block (see SI, \@ref(sec:exposure-analyses))---but then leveled off. The comparison across exposure conditions also yields one result that is, at first blush, surprising: while the difference between the +10 and the baseline condition emerged already after the first exposure block, this difference *de*creased, rather than increased, with additional exposure from Test 2 to 3 (see second row of Table \@ref(tab:hypothesis-table-interactions)). We return to this effect below.

Tables \@ref(tab:hypothesis-table-simple-effects) and \@ref(tab:hypothesis-table-interactions) also reveal the consequences of repeated testing. The difference between exposure conditions decreased from Test 4 to 6 (BFs > 4.3; see also Figure \@ref(fig:plot-fit-slope-PSE)B & D). On the final test block, the +10 condition did not differ any longer from the baseline condition. Only the differences between the +40 condition relative to the +10 and baseline conditions persisted, albeit substantially reduced compared to Test 4. This pattern of results replicates previous findings that repeated testing over uniform test continua can undo the effects of exposure [@cummings2023; @liu-jaeger2018; @liu-jaeger2019], and extends them from perceptual recalibration paradigms to distributional learning paradigms [see also @kleinschmidt2020]. One important methodological consequence of these findings is that longer test phases do not necessarily increase the statistical power to detect effects of adaptation [unless analyses take the effects of repeated testing into account, as in the approach developed in @liu-jaeger2018]. Analyses that average across all test tokens---as remains the norm---are bound to systematically underestimate the adaptivity of human speech perception.

```{r fit-nested-blocks-simple-effects, results='hide'}
# nested model to get simple effects of Condition embedded in block
fit_mix_test_nested_block <- brm(
   bf(
     Response.Voiceless ~ 1,
     mu1 ~ 0 + offset(0),
     mu2 ~ 0 + Block / (Condition.Exposure * VOT_gs) +
       (0 + Block / VOT_gs | ParticipantID) +
       (0 + Block / (Condition.Exposure * VOT_gs) | Item.MinimalPair),
     theta1 ~ 1),
   data = d_for_analysis %>%
     filter(Phase == "test") %>%
     prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = "difference"),
   cores = 4,
   chains = chains,
   init = 0,
   iter = 4000, # if 1000 warmup then iter can be lowered to 2000
   warmup = 2000, # 1000 warmup will exceed max tree depth
   family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
   control = list(adapt_delta = .99),
   file ="../models/Exp-AE-DLVOT-nested-block-condVOT.rds")

fit_mix_test_nested_condition <- brm(
   bf(
     Response.Voiceless ~ 1,
     mu1 ~ 0 + offset(0),
     mu2 ~ 0 + Condition.Exposure / (Block * VOT_gs) +
       (0 + Block * VOT_gs | ParticipantID) +
       (0 + Condition.Exposure / (Block * VOT_gs) | Item.MinimalPair),
     theta1 ~ 1),
   data = d_for_analysis %>%
     filter(Phase == "test") %>%
     prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = "difference"),
   cores = 4,
   chains = chains,
   init = 0,
   iter = 4000, 
   warmup = 2000, 
   family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
   control = list(adapt_delta = .995),
   file ="../models/Exp-AE-DLVOT-nested-condition.rds")

# get tidy df of nested test simple effects within block --no divergence in model found
simple_effects_condition <- tidy(fit_mix_test_nested_block, effects = "fixed") %>%
  filter(term != "theta1_(Intercept)")

simple_effects_block <- tidy(fit_mix_test_nested_condition, effects = "fixed") %>%
  filter(term != "theta1_(Intercept)")
```

```{r hypothesis-table-simple-effects, results='asis'}
# hypotheses to answer questions "when did change first emerge?" 
hyp_contrasts_nested_block <-
  c(
    "mu2_Block1:Condition.Exposure_Shift10vs.Shift0 < 0",
    "mu2_Block1:Condition.Exposure_Shift40vs.Shift10 < 0",
    "mu2_Block1:Condition.Exposure_Shift40vs.Shift10 + mu2_Block1:Condition.Exposure_Shift10vs.Shift0 < 0",
    "mu2_Block3:Condition.Exposure_Shift10vs.Shift0 < 0",
    "mu2_Block3:Condition.Exposure_Shift40vs.Shift10 < 0",
    "mu2_Block3:Condition.Exposure_Shift40vs.Shift10 + mu2_Block3:Condition.Exposure_Shift10vs.Shift0 < 0",
    "mu2_Block5:Condition.Exposure_Shift10vs.Shift0 < 0",
    "mu2_Block5:Condition.Exposure_Shift40vs.Shift10 < 0",
    "mu2_Block5:Condition.Exposure_Shift40vs.Shift10 + mu2_Block5:Condition.Exposure_Shift10vs.Shift0 < 0",
    "mu2_Block7:Condition.Exposure_Shift10vs.Shift0 < 0",
    "mu2_Block7:Condition.Exposure_Shift40vs.Shift10 < 0",
    "mu2_Block7:Condition.Exposure_Shift40vs.Shift10 + mu2_Block7:Condition.Exposure_Shift10vs.Shift0 < 0",
    "mu2_Block8:Condition.Exposure_Shift10vs.Shift0 < 0",
    "mu2_Block8:Condition.Exposure_Shift40vs.Shift10 < 0",
    "mu2_Block8:Condition.Exposure_Shift40vs.Shift10 + mu2_Block7:Condition.Exposure_Shift10vs.Shift0 < 0",
    "mu2_Block9:Condition.Exposure_Shift10vs.Shift0 < 0",
    "mu2_Block9:Condition.Exposure_Shift40vs.Shift10 < 0",
    "mu2_Block9:Condition.Exposure_Shift40vs.Shift10 + mu2_Block7:Condition.Exposure_Shift10vs.Shift0 < 0")

hyp_contrasts_nested_block <- hypothesis(fit_mix_test_nested_block, hyp_contrasts_nested_block, robust = T)
hyp_contrasts_nested_block <- hyp_contrasts_nested_block$hypothesis %>% select(-Star)

# translate hypotheses into intelligible statements
hyp_contrasts_nested_block_readable <- tibble(Hypothesis = rep(c("+10 vs. baseline", "+40 vs. +10", "+40 vs. baseline"), 6))

table.simple_effects <- 
  make_hyp_table(hyp_contrasts_nested_block_readable, hyp_contrasts_nested_block, caption = "When did exposure begin to affect participants' categorization responses? When, if ever, were these changes undone with repeated testing? This table summarizes the simple effects of the exposure conditions for each test block.") %>% 
  pack_rows("Test block 1 (pre-exposure)", 1, 3) %>%
  pack_rows("Test block 2", 4, 6) %>% 
  pack_rows("Test block 3", 7, 9) %>% 
  pack_rows("Test block 4", 10, 12) %>% 
  pack_rows("Test block 5 (no additional exposure)", 13, 15) %>% 
  pack_rows("Test block 6 (no additional exposure)", 16, 18)
table.simple_effects
```

```{r hypothesis-table-interactions, results='asis'}
# hypotheses to answer question, "was the change incremental between blocks?"
hyp_interactions <- c(
  "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test2vs.Test1 < 0",
  "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test3vs.Test2 < 0",
  "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test4vs.Test3 < 0",
  "(mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test4vs.Test3 + mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test3vs.Test2 + mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test2vs.Test1) < 0",
  
  "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test5vs.Test4 > 0",
  "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test6vs.Test5 > 0",
  "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test5vs.Test4 + mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test6vs.Test5 > 0",
  
  "mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test2vs.Test1 < 0",
  "mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test3vs.Test2 < 0",
  "mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test4vs.Test3 < 0",
  "(mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test4vs.Test3 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test3vs.Test2 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test2vs.Test1) < 0",
  
  "mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test5vs.Test4 > 0",
  "mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test6vs.Test5 > 0",
  "mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test5vs.Test4 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test6vs.Test5 > 0",
  
  "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test2vs.Test1 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test2vs.Test1 < 0",
  "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test3vs.Test2 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test3vs.Test2 < 0",
  "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test4vs.Test3 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test4vs.Test3 < 0",
  "(mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test4vs.Test3 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test4vs.Test3 + 
    mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test3vs.Test2 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test3vs.Test2 + 
    mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test2vs.Test1 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test2vs.Test1) < 0",
  
  "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test5vs.Test4 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test5vs.Test4 > 0",
  "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test6vs.Test5 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test6vs.Test5 > 0",
  "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test5vs.Test4 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test5vs.Test4 + 
   mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test6vs.Test5 + mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test6vs.Test5 > 0")

hyp_interactions <- hypothesis(fit_mix_test, hyp_interactions, robust = T)
hyp_interactions <- hyp_interactions$hypothesis %>% select(-Star)

# translate the hypotheses above into intelligible statements
hyp_interactions_readable <- 
  tibble(Hypothesis_readable = rep(c(
  # Comparing differences in +10 vs. baseline between blocks
  "Block 1 to 2: increased $\\Delta_{PSE}$",
  "Block 2 to 3: increased $\\Delta_{PSE}$",
  "Block 3 to 4: increased $\\Delta_{PSE}$",
  "{\\em Block 1 to 4: increased $\\Delta_{PSE}$}",
  "Block 4 to 5: decreased $\\Delta_{PSE}$",
  "Block 5 to 6: decreased $\\Delta_{PSE}$",
  "{\\em Block 4 to 6: decreased $\\Delta_{PSE}$}"), 3))

table.interactions <- 
  make_hyp_table(
    hyp_interactions_readable,
    hyp_interactions,
    caption = "Was there incremental change from test block 1 to 4? Did these changes dissipate with repeated testing from block 4 to 6? This table summarizes the interactions between exposure condition and block, whether the differences between exposure conditions changed from test block to test block.") %>% 
  pack_rows("Difference in +10 vs. baseline", 1, 7) %>%
  pack_rows("Difference in +40 vs. +10", 8, 14) %>%
  pack_rows("Difference in +40 vs. baseline", 15, 21) 

table.interactions
```

### Comparing within exposure conditions: How quickly does exposure begin to affect participants' responses? 
Next, we compared how exposure affects listeners' categorisation reponses within each condition relative to listeners' responses prior to any exposure. These changes are summarised for the slope and PSE in Figure \@ref(fig:plot-fit-slope-PSE)C & D, respectively. This visualization makes apparent two aspects of participants' behavior that were not readily apparent in the statistical comparisons we have summarized so far. First, while the PSEs for the +40 and +10 conditions were shifted rightwards compared to the baseline condition, both the +10 and the baseline condition actually shift leftwards relative to their pre-exposure starting point in Test 1. This is confirmed by Bayesian hypothesis tests summarized in Table \@ref(tab:hypothesis-table-simple-block-effects). 

(ref:exposure-means-database-density) Placement of exposure stimuli relative to an estimate of typical phonetic distributions for XXX word-initial /d/ and /t/ productions in L1-US English [based on 92 talkers in @chodroff-wilson2017]. The outermost contour of each category shows the 95% density quantile. Points show the category means of the exposure condition.

```{r getting-means-at-exposure-by-condition}
# calculate the various mean VOTs exposed to for each condition, including the labelled trials, with and without accounting for the test trials
cond_means_test_exposure <- d_for_analysis %>%
  group_by(Condition.Exposure) %>%
  summarise(across(c(Item.VOT, Item.Mel_F0_5ms), mean, .names = "{.col}_mean_test_exposure"))

cond_means_exposure <- d_for_analysis %>%
  filter(Phase == "exposure") %>%
  group_by(Condition.Exposure) %>%
  summarise(across(c(Item.VOT, Item.Mel_F0_5ms), mean, .names = "{.col}_mean_exposure"))

cond_means <- left_join(cond_means_test_exposure, cond_means_exposure)

d.chodroff_wilson <-
  get_ChodroffWilson_data(
    database_filename = "../data/all_observations_with_non-missing_vot_cog_f0.csv",
    min.n_per_talker_and_stop = 25,
    limits.VOT = c(-Inf, Inf),
    limits.f0 = c(0, 350),
    max.p_for_multimodality = .1) %>%
  filter(poa == "/d/-/t/") %>%
  group_by(Talker, category) %>%
  mutate(n = n()) %>%
  group_by(Talker) %>%
  # subsample n tokens, as determined by category with fewer tokens
  mutate(
    n_min = min(n),
    n_category = n_distinct(category)) %>%
  # select talkers with both /d/ and /t/ observations
  filter(n_category == 2) %>%
  group_by(Talker, category) %>%
  sample_n(size = first(n_min)) %>%
  ungroup() %>% 
  nest(data = everything()) %>% 
  mutate(speech_corrected = map(data, ~ get_speech.corrected.VOT(.x))) %>% 
  select(-data) %>% 
  unnest(speech_corrected) %>% 
  mutate_at(
    c("VOT", "f0", "f0_Mel", "f0_semitones", "VOT.speech_corrected"),
    list("centered" = function(x) apply_ccure(x, data = .))) %>%
  mutate(category = factor(category))

# corpus mean and sd values for VOT and speech
chodroff.mean_VOT <- mean(d.chodroff_wilson$VOT)
chodroff.sd_VOT <- sd(d.chodroff_wilson$VOT)
chodroff.mean_vowel_duration <- mean(d.chodroff_wilson$vowel_duration)
chodroff.sd_vowel_duration <- sd(d.chodroff_wilson$vowel_duration)

# get estimates from speech rate model to predict VOT
intercept.speech_rate <- 
  get_speech_rate_model(d.chodroff_wilson)$estimate[1] 
slope.speech_rate <- 
  get_speech_rate_model(d.chodroff_wilson)$estimate[2]

# center exposure cues to speech corpus means
d_for_analysis %<>% 
  mutate(
    VOT.scaled = (Item.VOT - chodroff.mean_VOT) / chodroff.sd_VOT,
    vowel_duration.scaled = (vowel_duration - chodroff.mean_vowel_duration) / chodroff.sd_vowel_duration,
    VOT.scaled_predict = intercept.speech_rate + (slope.speech_rate * vowel_duration.scaled),
    VOT.scaled_corrected = (VOT.scaled - VOT.scaled_predict) + intercept.speech_rate,
    VOT.speech_corrected = VOT.scaled_corrected * chodroff.sd_vowel_duration + chodroff.mean_vowel_duration) %>% 
  group_by(Condition.Exposure) %>%
  mutate(
    category = factor(ifelse(Item.ExpectedResponse.Voicing == "voiced", "/d/", "/t/")),
    Item.VOT_centered = case_when(
      Condition.Exposure == "Shift0" ~ Item.VOT + (chodroff.mean_VOT - cond_means$Item.VOT_mean_test_exposure[1]),
      Condition.Exposure == "Shift10" ~ Item.VOT + (chodroff.mean_VOT - cond_means$Item.VOT_mean_test_exposure[2]),
      Condition.Exposure == "Shift40" ~ Item.VOT + (chodroff.mean_VOT - cond_means$Item.VOT_mean_test_exposure[3])),
    Item.Mel_F0_5ms_centered = case_when(
      Condition.Exposure == "Shift0" ~ Item.Mel_F0_5ms + (chodroff.mean_f0_Mel - cond_means$Item.Mel_F0_5ms_mean_exposure[1]),
      Condition.Exposure == "Shift10" ~ Item.Mel_F0_5ms + (chodroff.mean_f0_Mel - cond_means$Item.Mel_F0_5ms_mean_exposure[2]),
      Condition.Exposure == "Shift40" ~ Item.Mel_F0_5ms + (chodroff.mean_f0_Mel - cond_means$Item.Mel_F0_5ms_mean_exposure[3]))) 

# specify quantiles for density plots
quantile_levels <- c(.05, .25, .5, .75, .95)
d_breaks <- density_quantiles(x = d.chodroff_wilson %>% filter(category == "/d/") %>% pull(VOT_centered),
                               y = d.chodroff_wilson %>% filter(category == "/d/") %>% pull(f0_Mel_centered),
                               quantiles = quantile_levels)
t_breaks <- density_quantiles(x = d.chodroff_wilson %>% filter(category == "/t/") %>% pull(VOT_centered),
                               y = d.chodroff_wilson %>% filter(category == "/t/") %>% pull(f0_Mel_centered),
                               quantiles = quantile_levels)

# matching breaks in each category to corresponding quantile
d_quantile <- quantile_levels
t_quantile <- quantile_levels
names(d_quantile) <- d_breaks
names(t_quantile) <- t_breaks
quantile_breaks <- tibble(quantile_levels, d_breaks, t_breaks)

p.density <- 
  d.chodroff_wilson %>%
  ggplot(aes(x = VOT_centered, y = f0_Mel_centered, linetype = category, group = category)) +
  geom_density2d(
    data = . %>% filter(category == "/d/"),
    aes(colour = d_quantile[as.character(after_stat(level))]),
    contour_var = "density", 
    breaks = d_breaks) +
  geom_density2d(
    data = . %>% filter(category == "/t/"),
    aes(colour = t_quantile[as.character(after_stat(level))]),
    contour_var = "density", 
    breaks = t_breaks) +
  scale_y_continuous("F0 (Mel)", limits = c(118, 360)) +
  scale_x_continuous("VOT (ms)", limits = c(-12, 125), breaks = scales::breaks_width(25)) +
  scale_colour_gradient("Quantiles", 
                        high = "#e6e6e6", 
                        low = "#000000", 
                        guide = "colourbar", 
                        breaks = quantile_levels, 
                        labels = scales::percent(quantile_levels)) +
  theme(legend.position = "top",
        legend.text = element_text(size = 7)) +
  #plot centered means
  new_scale_color() +
  geom_point(
    data = d_for_analysis %>%
      filter(Phase == "exposure") %>%
      group_by(Condition.Exposure, category) %>%
      summarise(across(c(Item.VOT_centered, Item.Mel_F0_5ms_centered), mean)),
    mapping = aes(x = Item.VOT_centered, y = Item.Mel_F0_5ms_centered, colour = Condition.Exposure, shape = category),
    size = 2,
    alpha = 0.8,
  inherit.aes = F,
  show.legend = T) +
  scale_colour_manual("Condition",
             labels = c("baseline", "+10ms", "+40ms"),
             values = c("#cc0000", "#12D432","#0481F3")) +
  guides(colour = "none",
         linetype = guide_legend(title = "Category"),
         shape = guide_legend(title = "Category"))
```

```{r exposure-means-database-density, fig.width=base.width*2.5+1, fig.height=base.height*2.5, warning=FALSE, fig.cap="(ref:exposure-means-database-density)"}
shift10_cov_d <- 
  (d_for_analysis %>% 
  filter(Condition.Exposure == "Shift10") %>% 
  group_by(category) %>%
  nest(data = -c(category)) %>%
  mutate(covariance = map_dbl(data, ~ cov(.x$Item.VOT_centered, .x$Item.Mel_F0_5ms_centered))) %>%
  pull(covariance))[1]
  
shift10_cov_t <- 
  (d_for_analysis %>% 
  filter(Condition.Exposure == "Shift10") %>% 
  group_by(category) %>%
  nest(data = -c(category)) %>%
  mutate(covariance = map_dbl(data, ~ cov(.x$Item.VOT_centered, .x$Item.Mel_F0_5ms_centered))) %>%
  pull(covariance))[2]
  
cues <- c("VOT", "f0_Mel")

shift10_ellipse <- 
  d_for_analysis %>% 
  filter(Phase == "exposure",
         Condition.Exposure == "Shift10") %>% 
  group_by(category) %>% 
  summarise(across(c(Item.VOT_centered, Item.Mel_F0_5ms_centered), list(mean = mean, var = var), .names = "{.col}.{.fn}")) %>% 
  mutate(cov = ifelse(category == "/d/", shift10_cov_d, shift10_cov_t), 
         mu = map2(Item.VOT_centered.mean, Item.Mel_F0_5ms_centered.mean, ~ c("VOT" = .x, "f0_Mel" = .y)), 
         Sigma = pmap(list(
           Item.VOT_centered.var, Item.Mel_F0_5ms_centered.var, cov), ~ matrix(c(..1, ..3, ..3, ..2), 2, 2, dimnames = list(cues, cues)))) %>%
  select(c(category, mu, Sigma)) %>% 
  crossing(level = .95) %>%
  group_by(category) %>%
  mutate(ellipse = c(1:1),
         ellipse_points = pmap(list(mu, Sigma, level), ~ get_bivariate_normal_ellipse(mu = ..1, Sigma = ..2, level = ..3))) %>%
  group_by(ellipse) %>%
  mutate(path = pmap(list(category, level, ellipse_points),
                     ~ geom_path(data = ..3, mapping = aes(x = ..3[[1]], y = ..3[[2]], linetype = ..1, colour = ..2))))

shift10_95ellipse <- 
  shift10_ellipse %>% 
  group_by(category) %>% 
  unnest(ellipse_points)

p.shift10_ellipse <- p.density +
  geom_path(
    data = shift10_95ellipse,
    aes(x = VOT, y = F0, linetype = category),
    colour = "#85e085",
    show.legend = F,
    inherit.aes = F) +
  scale_y_continuous("F0 (Mel)", limits = c(220, 250))

p.density +
  plot_layout(ncol = 1, guides = "collect") &
  theme(legend.position = "right")
```

To understand this pattern, it is helpful to relate our exposure conditions to the distribution of VOT in listeners' prior experience. Figure \@ref(fig:exposure-means-database-density) shows the mean and covariance of our exposure conditions relative to the distribution of VOT by talkers of L1-US English [based on @chodroff-wilson2017]. This comparison offers an explanation as to why the baseline condition (and to some extent the +10 condition) shift leftwards with increasing exposure, whereas the +40 condition shifts rightwards: relative to listeners' prior experience our baseline condition actually presented lower-than-expected category means; of our three exposure conditions, only the +40 condition presented larger-than-expected category means. That is, once we take into account how our exposure conditions relate to listeners' prior experience, both the direction of changes from Test 1 to 4 *within* each exposure condition, and the direction of differences *between* exposure conditions receive an explanation.

```{r hypothesis-table-simple-block-effects, results='asis'}
caption = "In what direction did exposure shift participants' responses compared from block to block? This table summarizes the simple effect of block for each exposure condition."
```

Second, the reason for the slight decrease in the difference between the +10 and baseline conditions observed in Tables \@ref(tab:hypothesis-table-simple-condition-effects) and \@ref(tab:hypothesis-table-interactions) (visible in Figure \@ref(fig:plot-fit-slope-PSE)D as the decreasing difference between the green and red line) is *not* due to a reversal of the effects in the +10 condition. Rather, both conditions are changing in the same direction but the baseline condition stops changing after Test 2, which reduces the difference between the +10 and baseline conditions (see Table \@ref(tab:hypothesis-table-simple-block-effects)). The comparison across blocks thus suggests a rather uniform picture across all exposure conditions: participants' responses initially changed rapidly with exposure; with increasing exposure, these changes did not only slow down but seem to hit a hard constraint. Participants in the leftwards-shifted baseline condition did not exhibit any further changes in their categorisation responses beyond Test 2. Similarly, participants in the rightwards-shifted +40 condition did not exhibit any further changes in their categorisation responses beyond Test 3. Only participants in the leftward-shifted +10 condition still exhibit changes across blocks even form Test 3 to 4. But, perhaps tellingly, those participants also never reached the degree of shift that was evident in the baseline condition.  

### Constraints on cumulative changes
Finally, Figures \@ref(fig:plot-fit-slope-PSE)C & D also compare participants' responses against those of an ideal observer that has fully learned the exposure distributions.





