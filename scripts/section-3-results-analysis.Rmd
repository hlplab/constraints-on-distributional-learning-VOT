```{r}
require(tidyverse)
require(magrittr)

require(brms)
require(MVBeliefUpdatr)
require(phonR)
require(rsample)

source("functions.R")
```


```{r}
# load formatted exposure and test data from experiment 2
d.exposure_test <- read_csv("../data/experiment2_raw_formatted.csv", show_col_types = F)

# load f0-5ms-into-vowel measurements of stimuli
d.f0.5ms <- 
  read_csv("../data/AEDLVOT_stimuli_f0_5ms.csv", show_col_types = F) %>% 
  select(filename, VOT, f0_5ms_into_vowel) %>% 
  rename(Item.VOT = VOT,
         Item.F0_5ms = f0_5ms_into_vowel,
         Item.Filename = filename) %>% 
  mutate(Item.Filename = paste0(Item.Filename, ".wav"))

# add f0-5ms data
d.exposure_test %<>% 
ungroup() %>%
  left_join(d.f0.5ms, by = c("Item.Filename", "Item.VOT")) %>% 
              mutate(Item.Mel_F0_5ms = normMel(Item.F0_5ms)) 

# mark catch trials rows and mark those to be excluded
d.exposure_test %<>% 
  mutate(
    Is.CatchTrial = ifelse(Item.ExpectedResponse %in% c("flare", "rare", "share"), TRUE, FALSE),
    CatchTrial.Correct = ifelse(Is.CatchTrial == TRUE, 
                    ifelse(Item.ExpectedResponse == Response, TRUE, FALSE), NA),
    Answer.sex.Correct = ifelse(sex == "woman", TRUE, FALSE)) %>% 
  group_by(ParticipantID) %>% 
  mutate(Exclude_participant.due_to_catch_trials = ifelse(sum(CatchTrial.Correct, na.rm = TRUE) < 17, TRUE, FALSE)) %>%
  ungroup()

# mark labelled trials
d.exposure_test %<>% 
  mutate(Response.Correct = ifelse(Item.ExpectedResponse == Response, TRUE, FALSE),
         LabeledTrial.Correct = ifelse(Item.Labeled == TRUE, ifelse(Response.Correct == TRUE, TRUE, FALSE), NA)) %>% 
  group_by(ParticipantID) %>% 
  mutate(Exclude_participant.due_to_labeled_trials = ifelse(sum(LabeledTrial.Correct, na.rm = T) < 68, TRUE, FALSE))
```



```{r set-exclusion-due-to-categorisation-slope, warning=FALSE}
# get data for exclusion due to categorisation slope of first 36 trials. 
d.VOT_exclusion <- d.exposure_test %>% 
  filter(Block == 1 | (Block == 2 & Trial %in% c(13:36))) %>% 
  drop_na(c(ParticipantID, Response.Voicing, Item.VOT)) %>% 
  mutate(Response.ProportionVoiceless = ifelse(Response.Voicing == "voiceless", 1, 0)) %>%
  select(c(Experiment, ParticipantID, Condition.Exposure, Response.Voicing, Response.ProportionVoiceless, Item.VOT))

# set the VOT criteria 
empirical_means <- c(17, 62)
VOT_for_targeted_proportion_t <- empirical_means + c(-20, 20)
targeted_proportion_t <- c(.15, .80) 


# Fit logistic regression by participant to get model predictions (REPLACE WITH LAPSE ESTIMATED NON-LINEAR FIT)
d.VOT_exclusion %<>%
  group_by(ParticipantID, Experiment, Condition.Exposure) %>%
  nest() %>%
  mutate(
    CategorizationModel =
      map(data, ~ glm(Response.ProportionVoiceless ~ 1 + Item.VOT, data = .x, family = binomial))) %>% 
  # type = "response" in predict() gives the probability
  summarise(Model.predicted.Reponse = 
              map(CategorizationModel, ~ predict(object = .x, 
                                                 newdata = tibble(Item.VOT = VOT_for_targeted_proportion_t), 
                                                 type = "response"))) %>% 
  mutate(Exclude_participant.due_to_VOT_slope = 
           map(Model.predicted.Reponse, ~ ifelse(.x[1] > targeted_proportion_t[1] || .x[2] < targeted_proportion_t[2], TRUE, FALSE)),
         Exclude_participant.due_to_lower_VOT = map(Model.predicted.Reponse, ~ ifelse(.x[1] > targeted_proportion_t[1], TRUE, FALSE)),
         Exclude_participant.due_to_higher_VOT = map(Model.predicted.Reponse, ~ ifelse(.x[2] < targeted_proportion_t[2], TRUE, FALSE))) %>% 
  select(ParticipantID, Experiment, Condition.Exposure, Exclude_participant.due_to_VOT_slope, Exclude_participant.due_to_lower_VOT, Exclude_participant.due_to_higher_VOT) %>% 
  mutate(across(c(Exclude_participant.due_to_VOT_slope, 
                  Exclude_participant.due_to_lower_VOT, 
                  Exclude_participant.due_to_higher_VOT), .fns = unlist)) %>% 
  ungroup()

# counting TRUEs
n_excluded_VOT_slope <- d.VOT_exclusion %>% 
  group_by(Exclude_participant.due_to_VOT_slope, Condition.Exposure) %>% 
  summarise(n())
  
d.exposure_test %<>% left_join(d.VOT_exclusion)
```



```{r set-RT-exclusion-criteria, message=FALSE}
# calculate RT exclusion AFTER removing excluded participants due to other criteria
# d.test_exposure_for_analysis <- d.exposure_test %>%
#   filter(
#     Is.CatchTrial == FALSE &
#     Exclude_participant.due_to_catch_trials == FALSE &
#     Exclude_participant.due_to_labeled_trials == FALSE &
#     Exclude_participant.due_to_VOT_slope == FALSE) %>% 
#   group_by(ParticipantID) %>%
#   mutate(
#     Response.log_RT = log10(ifelse(Response.RT <= 0, NA_real_, Response.RT)),
#     Response.log_RT.scaled = scale(Response.log_RT), # deducts each value with subject's own mean, divide by own SD
#     Response.log_RT.mean = mean(Response.log_RT, na.rm = T)) %>% 
#   ungroup() %>% 
#   mutate(Exclude_participant.due_to_RT = ifelse(abs(scale(Response.log_RT.mean)) > 3, TRUE, FALSE)) %>% 
#   filter(Exclude_participant.due_to_RT == FALSE) %>% 
#   mutate(Exclude_trial.due_to_RT = ifelse(abs(Response.log_RT.scaled) > 3, TRUE, FALSE))

# get number of participants excluded due to RT
# excl.RT.participant <- d.test_exposure_for_analysis %>% 
#   filter(Exclude_participant.due_to_RT == TRUE) %>% 
#   tally()

# get number of trials excluded due to RT
# excl.RT.trial <- d.test_exposure_for_analysis %>%  
#   filter(Exclude_trial.due_to_RT == TRUE) 

# proportion of trials excluded due to RT
# proportion.trials.excluded <- nrow(excl.RT.trial)/nrow(d.test_exposure_for_analysis)

# get number of participants excluded due to catch trial
excl.catch <- d.exposure_test %>% 
  filter(Exclude_participant.due_to_catch_trials == TRUE) %>% 
  group_by(ParticipantID) %>% 
  summarise() %>% 
  tally() 

# get number of participants excluded due to labelled trials
excl.labeled <- d.exposure_test %>% 
  filter(Exclude_participant.due_to_labeled_trials == TRUE) %>% 
  group_by(ParticipantID) %>% 
  summarise() %>% 
  tally() 

# count number of exclusions due to VOT slope
excl.VOT <- d.exposure_test %>% 
  filter(Exclude_participant.due_to_VOT_slope == TRUE) %>% 
  group_by(ParticipantID) %>% 
  summarise() %>% 
  tally()

# make dataframe for analysis after exclusions
d.test_exposure_for_analysis <- d.exposure_test %>%
  filter(
    Is.CatchTrial == FALSE &
    Exclude_participant.due_to_catch_trials == FALSE &
    Exclude_participant.due_to_labeled_trials == FALSE &
    Exclude_participant.due_to_VOT_slope == FALSE)
```

### Exclusions
We excluded from analysis participants who committed more than 3 errors out of the 18 catch trials (<84% accuracy, N = 1), participants who committed more than 4 errors out of the 72 labelled trials (<94% accuracy, N = 0), participants with an average reaction time (RT) more than three standard deviations from the mean of the by-participant means (N = 0), and participants who reported not to have used headphones (N = 0) or not to be native (L1) speakers of US English (N = 0). 

In addition, participants' categorization during the early phase of the experiment were scrutinised for their slope orientation and their proportion of "t"-responses at the least ambiguous locations of the VOT continuum. The early phase of the experiment was defined as the first 36 trials and the least ambiguous locations were defined as -20ms below the empirical mean of the /d/ category and +20ms above the empirical mean of the /t/ category. These means were obtained from the production data estimates by @Kurumada_Xie_Jaeger_2022.


### Analysis approach

##Results
## Regression analysis
The regression analysis addresses two main questions: 
Do participants shift their categorisation behaviour in an incremental fashion, i.e. do they exhibit categorisation behaviour that draws closer to the ideal categorisation function with each successive exposure block?
Are the differences in shifts between the conditions proportional to the magnitude of the shifts between exposure distributions i.e. is the PSE of the +40ms condition 3 times that of the +10ms condition?

We fit a Bayesian mixed-effects psychometric model with lapse and perceptual components. Continuous predictors were standardised to twice the standard deviation and priors and sampling parameters were identical to those specified in experiment 1. 

To analyse the incremental effects of exposure condition on the proportion of /t/ responses at test, the perceptual model contained exposure condition (backward difference coded, comparing the +10ms against the +0ms shift condition, and the +40ms against the +10ms shift condition), test block (backward difference coded from the first to the sixth test block), VOT (scaled to twice the), and their full factorial interaction. For the perceptual model, "t"-responses were regressed on the three-way interaction of VOT, condition, and block. Random effects were modelled with varying intercepts and slopes by participant and varying intercepts and slopes by minimal pair item. The lapsing model which estimates participant bias on trials with attention lapses was fitted without an intercept but with an offset [how does one describe this? what does offset(0) represent]. Finally, a population-level intercept was fitted to estimate the lapse rate. Random effects for the lapsing model and lapse rates were not fitted to limit the number of parameters and to ensure model convergence.

### Expectations
Given previous findings of @kleinschmidt2016you we expected participants in the various exposure conditions to shift their average categorization functions towards the direction of the ideal categorization function implied by their respective exposure distributions. We expected the differences between the groups to be most pronounced after the final exposure block as they would have had the complete exposure to all the tokens that make up the exposure distributions. This follows from predictions of incremental Bayesian belief-updating -- that listeners would integrate their prior expectations with the current input to infer the present talker's cue-to-category-mapping (the posterior distribution). 
Also based on previous findings, we expected the +40ms group to not fully  converge on the ideal categorization function as it was previously found that the further an exposure talker's cue distributions deviated from a *typical* talker's, the further the distance of categorization function from the ideal boundary. We therefore expected to see differences in categorizations between the +10ms and +40ms conditions such that listeners in the +40ms condition would shift more than those in the +10ms condition but to have an average categorization function located to the left of the ideal function. [@kleinschmidt2016you].

## Behavioral results


### Analysis approach


```{r load-br-model-block1}
# make Block 1 subset
d.block1 <- d.test_exposure_for_analysis %>% 
  filter(Block == 1) 

# set the mean and SD values for scaling/unscaling purposes. 
d.mean_sd <- d.test_exposure_for_analysis %>% 
  filter(Phase == "test") %>% 
  ungroup() %>% 
  summarise(across(c(Item.VOT, Item.Mel_F0_5ms), list(mean = mean, sd = sd), .names = "{.col}.{.fn}"))

VOT.mean_test <- d.mean_sd %>% pull(Item.VOT.mean)
VOT.sd_test <- d.mean_sd %>% pull(Item.VOT.sd)
f0.mean_test <- d.mean_sd %>% pull(Item.Mel_F0_5ms.mean)
f0.sd_test <- d.mean_sd %>% pull(Item.Mel_F0_5ms.sd)

d.block1 %<>% 
  mutate(
    Response.Voiceless = ifelse(Response.Voicing == "voiceless", 1, 0),
    VOT_gs = (Item.VOT - VOT.mean_test)/ (2 * VOT.sd_test),
    F0_gs = (Item.Mel_F0_5ms - f0.mean_test) /(2 * f0.sd_test))

# load the full experiment fit to obtain lapse rate
fit_mix_uniform_bias <- readRDS("../models/Exp-AE-DLVOT-labelled-lapsing-GLMM-difference-no-RTexcl.rds")
lapse_exp2 <- as.numeric(summary(fit_mix_uniform_bias)$fixed["theta1_Intercept", 1])

# run brms model of data for block 1 using lapse rate from full model (section X.X) 
fit_mix_block1 <- brm(
  bf(
    Response.Voiceless ~ 1,
    mu1 ~ 0 + offset(0),
    mu2 ~ 1 + VOT_gs + (1 + VOT_gs | ParticipantID),
    theta1 ~ 0 + offset(lapse) + (1 | ParticipantID)),
  data = d.block1 %>% 
    mutate(lapse = lapse_exp2),
  cores = 4,
  iter = 3000, # iterations to run
  warmup = 1500, # samples used to fit
  chains = chains,
  family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
  control = list(adapt_delta = .999),
  file = "../models/Exp-AE-DLVOT-Block1-lapse-no-RTexcl.rds")
```






```{r}
# get PSE of Block 1 from model summary
PSE.fit_mix_block1 <- descale(-(as.numeric(summary(fit_mix_block1)$fixed["mu2_Intercept", 1])) / as.numeric(summary(fit_mix_block1)$fixed["mu2_VOT_gs", 1]), VOT.mean_test, VOT.sd_test)

# get posterior samples of intercept and slope, and median qi of the PSE 
post_sample_block1 <- fit_mix_block1 %>% 
  spread_draws(b_mu2_Intercept, b_mu2_VOT_gs) %>% 
  mutate(PSE = descale(-(b_mu2_Intercept/b_mu2_VOT_gs),VOT.mean_test, VOT.sd_test)) %>% 
  median_qi(PSE)

#plot the fitted psychometric function for Block 1
psychometric_fit_block1 <- conditional_effects(
    fit_mix_block1, 
    effects = "VOT_gs",
    method = "posterior_epred",
    plot = F)[[1]]

# make base plot
p.fit_block1 <- psychometric_fit_block1 %>% 
  ggplot(aes(x = descale(VOT_gs, VOT.mean_test, VOT.sd_test), 
             y = estimate__)) +
  scale_x_continuous("VOT (ms)", limits = c(-5, 70)) +
  scale_y_continuous("Fitted proportion of 't' responses") +
  geom_ribbon(aes(ymin = lower__, ymax = upper__), alpha = .1) +
  geom_line(linewidth = 1.5, 
            colour = "#333333",
            alpha = .8) +
   geom_errorbarh(
    data = post_sample_block1 %>% 
      mutate(y = .01),
    mapping = aes(xmin = .lower, xmax = .upper, y = y), 
    color = "#333333",
    height = 0,
    alpha = .5,
    size = 1, 
    inherit.aes = F) +
  geom_label(
    data = post_sample_block1 %>% 
      median_qi(PSE) %>% 
      mutate(y = 0.01),
    mapping = aes(x = PSE, y = y, label = round(PSE)),
    color = "#333333", 
    size = 1.8,
    label.padding = unit(0.18, "lines"),
    alpha = .5) +
  annotate(
    geom = "text",
    x = 55,
    y = 0.02, 
    label = paste(round(post_sample_block1[[2]]), "ms", "-", round(post_sample_block1[[3]]), "ms"),
    size = 3.5,
    colour = "darkgray") +
   geom_rug(
    data = d.block1 %>% 
      reframe(Item.VOT) %>% 
      distinct(Item.VOT),
    mapping = aes(x = Item.VOT),
    alpha = .6,
    inherit.aes = F)
```


```{r prepare-production-database}
# prepare production corpus from Chodroff & Wilson
d.chodroff_wilson <-
  get_ChodroffWilson_data(
    database_filename = "../data/all_observations_with_non-missing_vot_cog_f0.csv",
    min.n_per_talker_and_stop = 25,
    limits.VOT = c(-Inf, Inf),
    limits.f0 = c(0, 350),
    max.p_for_multimodality = .1
  ) %>%
  mutate_at(
    c("VOT", "f0_Mel"),
    list("centered" = function(x) apply_ccure(x, data = .)))

d.chodroff_wilson.selected <-
  d.chodroff_wilson %>%
  filter(poa == "/d/-/t/") %>%
  group_by(Talker, category) %>%
  mutate(n = n()) %>%
  group_by(Talker) %>%
  # subsample n tokens, as determined by category with fewer tokens
  mutate(
    n_min = min(n),
    n_category = n_distinct(category)) %>%
  # select talkers with both /d/ and /t/ observations
  filter(n_category == 2) %>%
  group_by(Talker, category) %>%
  sample_n(size = first(n_min)) %>%
  ungroup() %>%
  mutate_at(
      c("VOT", "f0", "f0_Mel", "f0_semitones"),
      list("centered" = function(x) apply_ccure(x, data = .))) %>% 
  mutate(category = factor(category))

d.chodroff_wilson.selected %>% 
  group_by(Talker, gender, category ) %>% 
  summarise(
    mean_VOT = mean(VOT_centered),
    variance = var(VOT_centered),
    SD = sqrt(variance)) %>% 
  ggplot(aes(x = mean_VOT, y = variance, colour = category)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~x, alpha = .4) +
  ggpubr::stat_cor(aes(label = after_stat(rr.label))) 
```



```{r IO-categorization-VOT-f0-centered-input-block1, message=FALSE}
# prepare data for IO that centers perceptual input relative to database mean before categorization
chodroff.means <- d.chodroff_wilson.selected %>% 
  group_by(Talker) %>% 
  summarise(across(c(VOT, f0_Mel), mean)) %>% 
  ungroup() %>% 
  summarise(across(c(VOT, f0_Mel), mean)) 

chodroff.mean_VOT <- chodroff.means %>% pull(VOT)
chodroff.mean_f0 <- chodroff.means %>% pull(f0_Mel)
# 
# # get means and SDs from entire experiment for centering purposes
# d.mean_sd <- d.test_exposure_for_analysis %>% 
#   ungroup() %>% 
#   summarise(across(c(Item.VOT, Item.Mel_F0_5ms), list(mean = mean, sd = sd), .names = "{.col}.{.fn}"))
# 
# VOT.mean_test <- d.mean_sd %>% pull(Item.VOT.mean)
# VOT.sd_test <- d.mean_sd %>% pull(Item.VOT.sd)
# f0.mean_exp2 <- d.mean_sd %>% pull(Item.Mel_F0_5ms.mean)
# f0.sd_exp2 <- d.mean_sd %>% pull(Item.Mel_F0_5ms.sd)
```





```{r, message=FALSE}
# prepare data for IO that centers perceptual input relative to database mean before categorization
chodroff.means <- d.chodroff_wilson.selected %>% 
  group_by(Talker) %>% 
  summarise(across(c(VOT, f0_Mel), mean)) %>% 
  ungroup() %>% 
  summarise(across(c(VOT, f0_Mel), mean)) 

# get means of cues from chodroff database
chodroff.mean_VOT <- chodroff.means %>% pull(VOT)
chodroff.mean_f0 <- chodroff.means %>% pull(f0_Mel)

# center exposure data relative to database mean
psychometric_fit_block1_centered <- psychometric_fit_block1 %>% 
  mutate(Item.VOT = descale(VOT_gs, VOT.mean_test, VOT.sd_test),
         Item.VOT = Item.VOT + (chodroff.mean_VOT - VOT.mean_test),
         VOT_gs = (Item.VOT - VOT.mean_test)/(2 * VOT.sd_test))


# get expected values of the centered EXPOSURE VOT under the linear model
if (file.exists("../models/centered_exposure_block1_exp2.rds")) {
  epred_centered_block1 <- read_rds("../models/epred_centered_exposure_block1_exp2.rds")
} else {
  epred_centered_block1 <- epred_draws(
    object = fit_mix_block1,
    newdata = psychometric_fit_block1_centered,
    re_formula = NA,
    ndraws = 2000)
  write_rds(epred_centered_block1, file = "../models/epred_centered_exposure_block1_exp2.rds")
}
```



## Regression analysis
The regression analysis addresses two main questions: 
Do participants shift their categorisation behaviour in an incremental fashion, such that the categorisation function draws closer to the ideal categorisation function with each successive exposure block?
Are the differences in shifts between the conditions proportional to the magnitude of the shifts between exposure distributions i.e. is the PSE of the +40ms condition 3 times that of the +10ms condition?

### Expectations
Given previous findings of @kleinschmidt2016you we expected participants in the various exposure conditions to shift their average categorization functions towards the direction of the ideal categorization function implied by their respective exposure distributions. We expected the differences between the groups to be most pronounced after the final exposure block as they would have had the complete exposure to all the tokens that make up the exposure distributions. This follows from predictions of incremental Bayesian belief-updating -- that listeners would integrate their prior expectations with the current input to infer the present talker's cue-to-category-mapping (the posterior distribution). 
Also based on previous findings, we expected the +40ms group to not fully  converge on the ideal categorization function as it was previously found that the further an exposure talker's cue distributions deviated from a *typical* talker's, the further the distance of categorization function from the ideal boundary. We therefore expected to see differences in categorizations between the +10ms and +40ms conditions such that listeners in the +40ms condition would shift more than those in the +10ms condition but to have an average categorization function located to the left of the ideal function. [@kleinschmidt2016you].


```{r model-test-blocks, warning=FALSE}
d.test_exposure_for_analysis %<>% 
  mutate(Response.Voiceless = ifelse(Response.Voicing == "voiceless", 1, 0))
levels_Condition.Exposure = c("Shift0", "Shift10", "Shift40")
contrast_type <- "difference"

my_priors <- c(
  prior(student_t(3, 0, 2.5), class = "b", dpar = "mu2"),
  prior(student_t(3, 0, 2.5), class = "b", dpar = "theta1"),
  prior(cauchy(0, 2.5), class = "sd"),
  prior(lkj(1), class = "cor"))

# simplifying model with uniform bias
fit_mix_uniform_bias <- brm(
  bf(
    Response.Voiceless ~ 1,
    mu1 ~ 0 + offset(0),
    mu2 ~ 1 + VOT_gs * Condition.Exposure * Block + (1 + VOT_gs * Block | ParticipantID) + (1 + VOT_gs * Condition.Exposure * Block | Item.MinimalPair),
    theta1 ~ 1),
  data = d.test_exposure_for_analysis %>% 
    filter(Phase == "test") %>% 
    prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = contrast_type),
  cores = 4,
  chains = chains,
  init = 0,
  iter = 4000, # iterations to run
  warmup = 2000, # samples used to fit
  family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
  control = list(adapt_delta = .99),
  file = "../models/Exp-AE-DLVOT-labelled-lapsing-GLMM-difference-no-RTexcl.rds")

fixed_eff_exp2 <- tidy(fit_mix_uniform_bias, effects = "fixed") %>% 
  select(-c(effect, component))

# load helmert contrast-coded model
fit_mix_helmert <- read_rds("../models/Exp-AE-DLVOT-labelled-lapsing-GLMM-helmert-no-RTexcl.rds")

fixed_eff_exp2_helmert <- tidy(fit_mix_helmert, effects = "fixed") %>% 
  select(-c(effect, component))

#fixed_eff_exp2
#fixed_eff_exp2_helmert

kable(fixed_eff_exp2, booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "repeat_header", "scale_down"), position = "center") 
```

We fit two Bayesian mixed-effects psychometric models to participants' categorization responses on critical trials for test and exposure blocks [e.g., @prins2011]. We are primarily interested in the changes in categorization behaviour between test blocks which are presumed to be a consequence of the input from preceding exposure blocks however we fit a regression model for exposure in order to visualise participant behaviour during exposure as well. Our analysis is therefore focused on the estimates fitted to test blocks.

The psychometric model is essentially an extension of mixed-effects logistic regression that also takes into account attentional lapses. Ignoring attentional lapses--while commonplace in research on speech perception [incl. our own work, but see @clayards2008; @kleinschmidt2016you]---can lead to biased estimates of categorization boundaries [e.g., @wichmann2001psychometric]. The mixed-effects psychometric model describes the probability of "t"-responses as a weighted mixture of a lapsing-model and a perceptual model. The lapsing model is a mixed-effects logistic regression [@jaeger2008categorical] that predicts participant responses that are made independent of the stimulus---for example, responses that result from attentional lapses. These responses are independent of the stimulus, and depend only on participants' response bias. The perceptual model is a mixed-effects logistic regression that predicts all other responses, and captures stimulus-dependent aspects of participants' responses. The relative weight of the two models is determined by the lapse rate, which is described by a third mixed-effects logistic regression. 

We fit the model using the package \texttt{brms} [@R-brms_a] in R [@R; @RStudio]. Following previous work from our lab [@horberg2021rational; @xie2021cross], we used weakly regularizing priors to facilitate model convergence. For fixed effect parameters, we standardized continuous predictors (VOT) by dividing through twice their standard deviation [@gelman2008scaling], and used Student priors centered around zero with a scale of 2.5 units [following @gelman2008weakly] and 3 degrees of freedom. For random effect standard deviations, we used a Cauchy prior with location 0 and scale 2, and for random effect correlations, we used an uninformative LKJ-Correlation prior with its only parameter set to 1, describing a uniform prior over correlation matrices [@Lewandowski2009]. Four chains with 2000 warm-up samples and 2000 posterior samples each were fit. No divergent transitions after warm-up were observed, and all $\hat{R}$ were close to 1.

To analyse the incremental effects of exposure condition on the proportion of "t"-responses at test, the perceptual model contained exposure condition (backward difference coded, comparing the +10ms against the +0ms shift condition, and the +40ms against the +10ms shift condition), test block (backward difference coded from the first to last test block), VOT (Gelman scaled), and their full factorial interaction. For the perceptual model, "t"-responses were regressed on the three-way interaction of VOT, condition, and block. Random effects were modelled with varying intercepts and slopes by participant and varying intercepts and slopes by minimal pair item. We assumed uniform bias [*check that model which fits bias estimate converges, if so use that model] and fitted a population-level intercept for the lapse rate. Random effects for the lapsing model and lapse rates were not fitted to limit the number of parameters and to encourage model convergence.



Fig. XX summarizes participants’ fitted categorization functions across the different test blocks. A first point to note is the average categorization functions of the respective conditions before exposure to the talker. As depicted in the first panel, the average categorization functions converge on the same boundary or PSE (45ms, 95% QI = 36ms -- 55ms) which suggests that the three exposure groups largely had similar expectations about the cue distribution corresponding to /d/ and /t/ for this type of talker. What it also shows is that in setting our baseline condition we may have underestimated the boundary for our test stimuli by approximately 20ms which implies that the true shifts of our conditions correspond to -20ms, -10ms and +20ms (for +0, +10, and +40) respectively. The misalignment of the expected categorisation function between norming and the present experiment could be due to differences in both the length of and the continua deployed in the experiments. 

There was a main effect of VOT $\hat{\beta} =$ `r get_CI(fit_mix_uniform_bias, "mu2_VOT_gs", "mu2_VOT_gs > 0")`; participants were more likely to respond "t" as VOT increased. Condition had a main effect on responses such that with larger shifts, participants on average responded with fewer "t"s.  Additionally, the difference in average "t" responses between the +40ms and +10ms conditions ($\hat{\beta} =$ `r get_CI(fit_mix_uniform_bias, "mu2_Condition.Exposure_Shift40vs.Shift10", "mu2_Condition.Exposure_Shift40vs.Shift10 < 0")` reduction in log-odds) was *larger* than the difference between the +10 and +0 conditions ($\hat{\beta} =$ `r get_CI(fit_mix_uniform_bias, "mu2_Condition.Exposure_Shift10vs.Shift0", "mu2_Condition.Exposure_Shift10vs.Shift0 < 0")` reduction in log-odds). 
Qualitatively, the results indicate listeners adjust their expectations to align with the statistics of the exposure talker, consonant with previous findings of studies employing this paradigm (e.g., @clayards2008; @kleinschmidt2016you; @theodore2019distributional). 

While there was weak evidence for a main effect of block its interaction with condition revealed how participants in the respective exposure groups responded as they progressively received more informative input. Most of the change took place after the first exposure block. Participants in the +10ms condition responded with fewer "ts" compared to participants in the +0ms condition in test block 2 relative to that in test block 1 ($\hat{\beta} =$ `r get_CI(fit_mix_uniform_bias, "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test2vs.Test1", "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test2vs.Test1 < 0")`). The difference between the  +40ms and +10ms condition in test block 2 relative to that in block 1 was more pronounced, reflecting the wider separation between the two exposure conditions in block 2 ($\hat{\beta} =$ `r get_CI(fit_mix_uniform_bias, "mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test2vs.Test1", "mu2_Condition.Exposure_Shift40vs.Shift10:Block_Test2vs.Test1 < 0")`). 

In test block 3, the difference in average log-odds between conditions +0ms and +10ms, relative to test block 2 was *positive* such that the difference between the two conditions in test block 3 was smaller than the corresponding difference in block 2 ($\hat{\beta} =$ `r get_CI(fit_mix_uniform_bias, "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test3vs.Test2", "mu2_Condition.Exposure_Shift10vs.Shift0:Block_Test3vs.Test2 >0")`). In test blocks 4 and 5, the  average log-odds difference between +0ms and +10ms increased marginally when compared to the preceding block, respectively (as indicated by the negative signs of the estimates; see table xx) while in test block 6 the difference between the two exposure conditions narrowed substantially. Looking at the block-by-block differences between the +40ms and +10ms conditions, these continued to widen in test blocks 3 and block 4 relative to their respective preceding blocks, albeit by progressively smaller increments. This widening trend would then reverse in test blocks 5 and 6. In all, the respective conditions achieved their maximal shifts by block 3 and began to display a reversal of the exposure effects by the end of block 4. This "unlearning" of the exposure distribution, observed in the final 3 test blocks was expected given previous findings that distributional learning effects can begin to dissipate with prolonged testing with tokens from a uniform distribution. 

An examination of the block-by-block changes in the intercepts and slopes of the respective conditions, confirmed that the changes in categorization behaviour were driven predominantly by changes in the intercept (fig xx). the slopes of all 3 conditions in test block 4, which immediately follows the final exposure block, and where participants would have had full exposure to their respective distributions, did not differ substantially from each other nor from their estimated starting point in test block 1. Conversely, the intercepts at these points in the experiment were more distinct from each other and from where they were estimated to be at test block 1. 

In summary, the analysis shows that the groups diverged in their categorisation behaviour very early on in the experiment -- only after 24 exposures to each category. This suggests a readiness to adapt to a new talker by integrating current input with prior expectations. This prompt shift was however tempered by participants reaching the limits of their adaptation almost as quickly; the +40ms condition for example achieved more than 95% of its maximal shift in the experiment in test block 2. Only a marginal change in categorization behaviour was observed after the second exposure block while the third exposure block barely resulted in further shifts. 

 **Glaringly, all three conditions undershot the ideal categorization boundaries implied by their respective exposure distributions: 14.5ms in the +0ms, 7.2ms in the +10ms, and 14.5ms in the +40ms conditions. 

  **Like this study's predecessor, we also find that participants had a greater propensity to shift their categorisations rightwards towards higher VOT values rather than leftwards towards lower VOT values as the +40ms group showed the widest deviation from the baseline.

Under the Bayesian ideal adapter framework quick adaptation is characterised as listeners having weak beliefs in their prior cue means and variances. Listeners' strength in prior beliefs influences the speed of adaptation, and this is what we observed. On the other hand, weak prior beliefs also predict that it would take few trials for listeners to converge on the implied categorisation boundary. But this is not what we observed in our data. 



```{r model-exposure-blocks}
# get VOT mean and sd across exposure blocks and CONDITIONS for scaling purposes
exposure_block_stats <- d.test_exposure_for_analysis %>% 
  ungroup() %>% 
    filter(Phase == "exposure" & Item.Labeled == FALSE) %>% 
  summarise(VOT.mean_exposure = mean(Item.VOT),
            VOT.sd_exposure = sd(Item.VOT))

VOT.mean_exposure <- exposure_block_stats[[1]]
VOT.sd_exposure <- exposure_block_stats[[2]]

# set priors for psychometric model
my_priors <- c(
  prior(student_t(3, 0, 2.5), class = "b", dpar = "mu2"), # prior 
  prior(student_t(3, 0, 2.5), class = "b", dpar = "theta1"), 
  prior(cauchy(0, 2.5), class = "sd"),
  prior(lkj(1), class = "cor")
)

# fit difference coded model on exposure block
fit_mix_exposure <- brm(
  bf(
    Response.Voiceless ~ 1,
    mu1 ~ 0 + offset(0),
    mu2 ~ 1 + VOT_gs * Condition.Exposure * Block + (1 + VOT_gs * Block | ParticipantID) + (1 + VOT_gs * Condition.Exposure * Block | Item.MinimalPair),
    theta1 ~ 1),
  data = d.test_exposure_for_analysis %>% 
    filter(Phase == "exposure" & Item.Labeled == FALSE) %>% 
    prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = contrast_type),
  cores = 4,
  chains = chains,
  init = 0,
  iter = 4000, # iterations to run
  warmup = 2000, # samples used to fit
  family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
  control = list(adapt_delta = .99),
  file = "../models/Exp-AE-DLVOT-lapsing-GLMM-differencecoded-exposureblocks.rds")

tidy(fit_mix_exposure, effects = "fixed") %>% 
  select(-c(effect, component))
```


```{r plot-exposure-fit, fig.width=6, fig.height=2}
cond_fit_exposure <- conditional_effects(
    fit_mix_exposure,
    effects = "VOT_gs:Condition.Exposure",
    conditions = make_conditions(
      d.test_exposure_for_analysis %>% 
        filter(Phase == "exposure" & Item.Labeled == FALSE) %>% 
        prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = "difference"), 
      vars = c("Block")),
    method = "posterior_epred",
    ndraws = 500,
    re_formula = NA)
```



```{r, results='hide', warning=FALSE}
cond_fit_test <- conditional_effects(
    fit_mix_uniform_bias,
    effects = "VOT_gs:Condition.Exposure",
    conditions = make_conditions(
      d.test_exposure_for_analysis %>% 
        filter(Phase == "test") %>% 
        prepVars(levels.Condition = levels_Condition.Exposure, contrast_type = "difference"), 
      vars = c("Block")),
    method = "posterior_epred",
    ndraws = 500,
    re_formula = NA)
```





```{r, fig.width=6, fig.height=4.3}
#combine test and exposure fit
cond_fit_exposure[[1]] %<>% 
  mutate(Item.VOT = descale(VOT_gs, VOT.mean_exposure, VOT.sd_exposure))

cond_fit_test[[1]] %<>% 
  mutate(Item.VOT = descale(VOT_gs, VOT.mean_test, VOT.sd_test))

cond_fit_test_exposure <- tibble(full_join(cond_fit_exposure[[1]], cond_fit_test[[1]])) %>% 
  arrange(as.numeric(as.character(Block))) %>% 
  mutate(
    Condition.Exposure = case_when(
    Condition.Exposure == "Shift0" ~ "+0ms",
    Condition.Exposure == "Shift10" ~ "+10ms",
    Condition.Exposure == "Shift40" ~ "+40ms"),
    Block = factor(case_when(
      Block == 1 ~ "Test block 1",
      Block == 3 ~ "Test block 2",
      Block == 5 ~ "Test block 3",
      Block == 7 ~ "Test block 4",
      Block == 8 ~ "Test block 5",
      Block == 9 ~ "Test block 6",
      Block == 2 ~ "Exposure block 1",
      Block == 4 ~ "Exposure block 2",
      Block == 6 ~ "Exposure block 3")), 
    Block = fct_relevel(Block, c("Test block 1", "Exposure block 1", "Test block 2", "Exposure block 2", "Test block 3", "Exposure block 3",  "Test block 4", "Test block 5", "Test block 6"))) 

cond_fit_test_exposure %>% 
  ggplot(aes(
    x = Item.VOT, 
    y = estimate__, 
    group = Condition.Exposure)) +
  geom_ribbon(aes(
    ymin = lower__, ymax = upper__, fill = Condition.Exposure), alpha = .1) +
  geom_line(aes(
    color = Condition.Exposure), 
    size = 1,
    alpha = 0.6) +
  geom_rug(data = d.test_exposure_for_analysis %>%
             ungroup() %>% 
             distinct(Item.VOT),
           aes(x = Item.VOT),
           alpha = 0.5,
           colour = "grey",
           inherit.aes = F) +
  stat_summary(
    data = d.test_exposure_for_analysis %>%
      filter(Item.Labeled == FALSE) %>%
      mutate(
        Condition.Exposure = case_when(
          Condition.Exposure == "Shift0" ~ "+0ms",
          Condition.Exposure == "Shift10" ~ "+10ms",
          Condition.Exposure == "Shift40" ~ "+40ms"),
        Block = factor(case_when(
          Block == 1 ~ "Test block 1",
          Block == 3 ~ "Test block 2",
          Block == 5 ~ "Test block 3",
          Block == 7 ~ "Test block 4",
          Block == 8 ~ "Test block 5",
          Block == 9 ~ "Test block 6",
          Block == 2 ~ "Exposure block 1",
          Block == 4 ~ "Exposure block 2",
          Block == 6 ~ "Exposure block 3"))) %>%
      group_by(Condition.Exposure, Block),
    fun.data = mean_cl_boot,
    mapping = aes(x = Item.VOT,
                  y = Response.Voiceless,
                  colour = Condition.Exposure),
    geom = "pointrange",
    size = 0.2,
    alpha = 0.7,
    position = position_dodge2(width = 2),
    inherit.aes = F) +
           scale_x_continuous("VOT (msec)") +
           scale_y_continuous("Proportion \"t\"-responses") +
           scale_color_manual(
             "Condition",
             labels = c("+0ms", "+10ms", "+40ms"),
             values = c("#cc0000", "#12D432","#0481F3"),
             aesthetics = c("color", "fill")) +
           facet_wrap(
           . ~ Block,
            nrow = 3) + 
           theme(legend.position = "top")
```


```{r}
# nested models for extracting the 'intercepts' and 'slopes' for each Block and Condition
fit_mix_test_nested <- brm(
  bf(
    Response.Voiceless ~ 1,
    mu1 ~ 0 + offset(0),
    mu2 ~  0 + I(paste(Condition.Exposure, Block, sep = "x")) / VOT_gs + 
      (0 + Block / VOT_gs | ParticipantID) + 
      (0 + I(paste(Condition.Exposure, Block, sep = "x")) / VOT_gs | Item.MinimalPair),
    theta1 ~ 1),
  data = d.test_exposure_for_analysis %>% 
    filter(Phase == "test") %>% 
    prepVars(levels.Condition = levels_Condition.Exposure),
  cores = 4,
  chains = chains,
  init = 0,
  iter = 4000, # iterations to run
  warmup = 2000, # samples used to fit
  family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
  control = list(adapt_delta = .99),
  file = "../models/Exp-AE-DLVOT-labelled-lapsing-GLMM-nested-no-RTexcl.rds")

fit_mix_exposure_nested <- brm(
  bf(
    Response.Voiceless ~ 1,
    mu1 ~ 0 + offset(0),
    mu2 ~  0 + I(paste(Condition.Exposure, Block, sep = "x")) / VOT_gs + 
      (0 + Block / VOT_gs | ParticipantID) + 
      (0 + I(paste(Condition.Exposure, Block, sep = "x")) / VOT_gs | Item.MinimalPair),
    theta1 ~ 1),
  data = d.test_exposure_for_analysis %>% 
    filter(Phase == "test") %>% 
    prepVars(levels.Condition = levels_Condition.Exposure),
  cores = 4,
  chains = chains,
  init = 0,
  iter = 4000, # iterations to run
  warmup = 2000, # samples used to fit
  family = mixture(bernoulli("logit"), bernoulli("logit"), order = F),
  control = list(adapt_delta = .99),
  file = "../models/Exp-AE-DLVOT-lapsing-nested-exposureblock.rds")

# summary = F below gives all 8000 posterior samples
 temp <- 
 fixef(fit_mix_test_nested, summary = F, pars = gsub("^b_(mu2_.*)$", "\\1", variables(fit_mix_test_nested)))

# temp %>%
#   as_tibble() %>%
#   rename_with(~ paste0(.x, ":Intercept"), -ends_with("VOT_gs")) %>%
#   mutate(draw = rownames(temp)) %>%
#   relocate(draw, everything()) %>%
#   pivot_longer(
#     cols = -draw, 
#     names_pattern = "Shift([0-9]+x[0-9]+):(.*)",
#     names_to = c("ConditionBlock", "Parameter")) %>%
#   separate(
#     col = ConditionBlock,
#     sep = "x",
#     into = c("Condition", "Block")) %>%
#   pivot_wider(
#     values_from = value,
#     names_from = Parameter) %>%
#   mutate(PSE = descale(-Intercept / VOT_gs, VOT.mean_test, VOT.sd_test)) %>%
#   # Get HDCI or SE
#   group_by(Condition, Block) %>% 
#   summarise(lower = quantile(PSE, probs = .025),
#             median = quantile(PSE, probs = .5),
#             upper = quantile(PSE, probs = .975))


# tidy output of nested model and separate terms into intercepts and slopes
Intercepts_slopes_test <- tidy(fit_mix_test_nested, effects = "fixed") %>% 
  filter(term != "theta1_(Intercept)") %>% 
  mutate(term = gsub("mu2_IpasteCondition.ExposureBlocksepEQxShift(\\d{1,2})x(\\d{1}.*$)", "Shift\\1.\\2", term),
         parameter = ifelse(str_detect(term, "VOT_gs"), "slope", "Intercept")) %>% 
  separate(col = term, into = c("Condition.Exposure", "Block"), sep = "\\.") %>% 
  mutate(Block = ifelse(str_detect(Block, "VOT"), str_replace(Block, "(\\d{1}):VOT_gs", "\\1"), Block)) 

Intercepts_slopes_exposure <- tidy(fit_mix_exposure_nested, effects = "fixed") %>% 
  filter(term != "theta1_(Intercept)") %>% 
  mutate(term = gsub("mu2_IpasteCondition.ExposureBlocksepEQxShift(\\d{1,2})x(\\d{1}.*$)", "Shift\\1.\\2", term),
         parameter = ifelse(str_detect(term, "VOT_gs"), "slope", "Intercept")) %>% 
  separate(col = term, into = c("Condition.Exposure", "Block"), sep = "\\.") %>% 
  mutate(Block = ifelse(str_detect(Block, "VOT"), str_replace(Block, "(\\d{1}):VOT_gs", "\\1"), Block)) 

Intercepts_slopes <- full_join(Intercepts_slopes_test, Intercepts_slopes_exposure)
```
```{r make-dataframe-for-logistic-regression-on-predicted-probs-by-IOs}
# get the actual means and variances of the exposure stimuli by category
d.summarystats_exposure <- d.test_exposure_for_analysis %>% 
  filter(Phase == "exposure") %>% 
  mutate(Category = ifelse(Item.ExpectedResponse.Voicing == "voiced", "/d/", "/t/")) %>% 
  group_by(Condition.Exposure, Category) %>% 
  # get all exposure rows from one participant per condition
  slice_head(n = 144) %>% 
  summarise(mean = mean(Item.VOT, na.rm = T),
            var = var(Item.VOT, na.rm = T))

exposure_shift0_mean_d <- (d.summarystats_exposure %>% pull(mean))[1]
exposure_shift0_mean_t <- (d.summarystats_exposure %>% pull(mean))[2]
exposure_shift10_mean_d <- (d.summarystats_exposure %>% pull(mean))[3]
exposure_shift10_mean_t <- (d.summarystats_exposure %>% pull(mean))[4]
exposure_shift40_mean_d <- (d.summarystats_exposure %>% pull(mean))[5]
exposure_shift40_mean_t <- (d.summarystats_exposure %>% pull(mean))[6]

exposure_var_d <- (d.summarystats_exposure %>% pull(var))[1]
exposure_var_t <- (d.summarystats_exposure %>% pull(var))[2] 

x <- d.test_exposure_for_analysis %>% 
  filter(Phase == "test") %>% 
  distinct(Item.VOT) %>%
  pull()

conditions <- tibble(
  condition = c("shift0", "shift10", "shift40")) 
  
ios <- tibble(
  category = factor(c("/d/", "/t/")),
  Sigma = list(matrix(sqrt(exposure_var_d)), matrix(sqrt(exposure_var_t))),
  prior = c(.5, .5),
  lapse_rate = c(0, 0),
  lapse_bias = c(.5, .5),
  Sigma_noise = list(matrix(80), matrix(80))
  )

io.conditions <- crossing(conditions, ios) %>% 
  cbind(tibble(mu = list(c(VOT = exposure_shift0_mean_d), c(VOT = exposure_shift0_mean_t), c(VOT = exposure_shift10_mean_d), c(VOT = exposure_shift10_mean_t), c(VOT = exposure_shift40_mean_d), c(VOT = exposure_shift40_mean_t)))) %>% 
  relocate(c(condition, category, mu)) %>% 
  nest(io = -c(condition)) %>% 
  crossing(x) %>% 
  mutate(x = map(x, ~ c(.x))) %>% 
  nest(x = x)

d.io.categorisation <- io.conditions %>% 
  mutate(categorisation = 
           map2(x, io,
          ~ get_categorization_from_MVG_ideal_observer(x = .x$x, model = .y, decision_rule = "proportional") %>% 
            mutate(VOT = map(x, ~ .x[1]) %>% unlist()))) %>%
  unnest(cols = categorisation, names_repair = "unique") %>% 
  select(c(condition, io, category, response, VOT)) %>% 
  pivot_wider(names_from = category, values_from = response, names_prefix = "response_") %>% 
  mutate(n_d = round(`response_/d/` * 10^9),
         n_t = 10^9 - n_d)

d.io.categorisation %<>%
  group_by(condition) %>% 
  nest() %>% 
  mutate(model_unscaled = map(data, ~ glm(cbind(n_t, n_d) ~ 1 + VOT, family = binomial, data = .x)),
         intercept_unscaled = map_dbl(model_unscaled, ~ tidy(.x)[1,2] %>% pull()),
         slope_unscaled = map_dbl(model_unscaled, ~ tidy(.x)[2,2] %>% pull()), 
         model_scaled = map(data, ~ glm(cbind(n_t, n_d) ~ 1 + I((VOT - VOT.mean_test)/ (2 * VOT.sd_test)), family = binomial, data = .x)),
         intercept_scaled = map_dbl(model_scaled, ~ tidy(.x)[1,2] %>% pull()),
         slope_scaled = map_dbl(model_scaled, ~ tidy(.x)[2,2] %>% pull()),
           PSE = -intercept_unscaled/slope_unscaled)
```



```{r, warning=FALSE}
# alternative way to get posterior draws using gather_draws
d.estimates_test <- fit_mix_test_nested %>% 
  gather_draws(`b_mu2_IpasteCondition.ExposureBlocksepEQ.*`, regex = TRUE, ndraws = 8000) %>% 
  mutate(.variable = gsub("b_mu2_IpasteCondition.ExposureBlocksepEQxShift(\\d{1,2})x(\\d{1}.*$)", "Shift\\1.\\2", .variable),
         term = ifelse(str_detect(.variable, "VOT_gs"), "slope", "Intercept")) %>% 
  separate(col = .variable, into = c("Condition.Exposure", "Block"), sep = "\\.") %>% 
  mutate(Block = ifelse(str_detect(Block, "VOT"), str_replace(Block, "(\\d{1}):VOT_gs", "\\1"), Block)) %>% 
  pivot_wider(names_from = term, values_from = ".value") %>% 
  relocate(c(Condition.Exposure, Block, Intercept, slope, .chain, .iteration, .draw))

d.estimates_exposure <- fit_mix_exposure_nested %>% 
  gather_draws(`b_mu2_IpasteCondition.ExposureBlocksepEQ.*`, regex = TRUE, ndraws = 8000) %>% 
  mutate(.variable = gsub("b_mu2_IpasteCondition.ExposureBlocksepEQxShift(\\d{1,2})x(\\d{1}.*$)", "Shift\\1.\\2", .variable),
         term = ifelse(str_detect(.variable, "VOT_gs"), "slope", "Intercept")) %>% 
  separate(col = .variable, into = c("Condition.Exposure", "Block"), sep = "\\.") %>% 
  mutate(Block = ifelse(str_detect(Block, "VOT"), str_replace(Block, "(\\d{1}):VOT_gs", "\\1"), Block)) %>% 
  pivot_wider(names_from = term, values_from = ".value") %>% 
  relocate(c(Condition.Exposure, Block, Intercept, slope, .chain, .iteration, .draw))

d.estimates <- full_join(d.estimates_test, d.estimates_exposure) %>% 
  mutate(PSE = ifelse(Block %in% c(2, 4, 6), descale(-Intercept/slope, VOT.mean_exposure, VOT.sd_exposure), descale(-Intercept/slope, VOT.mean_test, VOT.sd_test))) %>% 
  group_by(Condition.Exposure, Block) %>% 
  summarise(across(c(Intercept, slope, PSE), .fns = list(lower = ~ quantile(.x, probs = .025), mean = mean, upper = ~ quantile(.x, probs = .975))))
```



```{r}
p.intercept <- d.estimates %>% 
  ggplot(aes(x = Block, y = Intercept_mean, colour = Condition.Exposure, group = Condition.Exposure)) +
  geom_point(position = position_dodge(.3), size = 2) +
  geom_linerange(aes(ymin = Intercept_lower, ymax = Intercept_upper), linewidth = 1, position = position_dodge(.3), alpha = .5) +
  stat_summary(geom = "line", position = position_dodge(.3)) + 
  geom_rect(aes(ymin = -16.1, ymax = 5.1, xmin = 0.75, xmax = 1.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
  geom_rect(aes(ymin = -16.1, ymax = 5.1, xmin = 2.75, xmax = 3.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
  geom_rect(aes(ymin = -16.1, ymax = 5.1, xmin = 4.75, xmax = 5.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
   geom_rect(aes(ymin = -16.1, ymax = 5.1, xmin = 6.75, xmax = 7.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
   geom_rect(aes(ymin = -16.1, ymax = 5.1, xmin = 7.75, xmax = 8.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
  geom_rect(aes(ymin = -16.1, ymax = 5.1, xmin = 8.75, xmax = 9.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
  geom_hline(yintercept = d.io.categorisation[[7]][1], linetype = 2, linewidth = 0.8, colour = "#cc0000", alpha = 0.5) +
  geom_hline(yintercept = d.io.categorisation[[7]][2], linetype = 2, linewidth = .8, colour = "#12D432", alpha = 0.5) +
  geom_hline(yintercept = d.io.categorisation[[7]][3], linetype = 2, linewidth = .8, colour = "#0481F3", alpha = 0.5) +
  scale_colour_manual("Condition",
    labels = c("+0ms", "+10ms", "+40ms"),
    values = c("#cc0000", "#12D432","#0481F3"),
    aesthetics = "color") +
  scale_y_continuous("Mean Intercept") +
  scale_x_discrete("Block", labels = c("1" = "Test 1", "2" = "Exposure 1", "3" = "Test 2", "4" = "Exposure 2", "5" = "Test 3", "6" = "Exposure 3", "7" = "Test 4", "8" = "Test 5", "9" = "Test 6")) +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 22.5, hjust = 1))

p.slope <- d.estimates %>% 
  ggplot(aes(x = Block, y = slope_mean, colour = Condition.Exposure, group = Condition.Exposure)) +
geom_rect(aes(ymin = 8.5, ymax = 32, xmin = 0.75, xmax = 1.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
  geom_rect(aes(ymin = 8.5, ymax = 32, xmin = 2.75, xmax = 3.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
  geom_rect(aes(ymin = 8.5, ymax = 32, xmin = 4.75, xmax = 5.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
   geom_rect(aes(ymin = 8.5, ymax = 32, xmin = 6.75, xmax = 7.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
   geom_rect(aes(ymin = 8.5, ymax = 32, xmin = 7.75, xmax = 8.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
  geom_rect(aes(ymin = 8.5, ymax = 32, xmin = 8.75, xmax = 9.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
  geom_point(position = position_dodge(.3), size = 2) +
  geom_linerange(aes(ymin = slope_lower, ymax = slope_upper), linewidth = 1, position = position_dodge(.3), alpha = .5) +
  stat_summary(geom = "line", position = position_dodge(.3)) +
  geom_hline(yintercept = 23, linetype = 2, linewidth = 0.8, colour = "#cc0000", alpha = 0.5) +
  geom_hline(yintercept = 23, linetype = 2, linewidth = .8, colour = "#12D432", alpha = 0.5) +
  geom_hline(yintercept = 23, linetype = 2, linewidth = .8, colour = "#0481F3", alpha = 0.5) +
  scale_colour_manual("Condition",
    labels = c("+0ms", "+10ms", "+40ms"),
    values = c("#cc0000", "#12D432","#0481F3"),
    aesthetics = "color") +
  scale_y_continuous("Mean Slope") +
  scale_x_discrete("Block", labels = c("1" = "Test 1", "2" = "Exposure 1", "3" = "Test 2", "4" = "Exposure 2", "5" = "Test 3", "6" = "Exposure 3", "7" = "Test 4", "8" = "Test 5", "9" = "Test 6")) +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 22.5, hjust = 1))

p.PSE <- d.estimates %>% 
  ggplot(aes(x = Block, y = PSE_mean, colour = Condition.Exposure, group = Condition.Exposure)) +
  geom_rect(aes(ymin = 25.2, ymax = 66.8, xmin = 0.75, xmax = 1.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
  geom_rect(aes(ymin = 25.2, ymax = 67, xmin = 2.75, xmax = 3.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
  geom_rect(aes(ymin = 25.2, ymax = 67, xmin = 4.75, xmax = 5.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
   geom_rect(aes(ymin = 25.2, ymax = 67, xmin = 6.75, xmax = 7.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
   geom_rect(aes(ymin = 25.2, ymax = 67, xmin = 7.75, xmax = 8.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
  geom_rect(aes(ymin = 25.2, ymax = 67, xmin = 8.75, xmax = 9.25), 
            fill = "grey", 
            alpha = .009, 
            inherit.aes = F) +
  geom_point(position = position_dodge(.3), size = 2) +
  geom_linerange(aes(ymin = PSE_lower, ymax = PSE_upper), linewidth = 1, position = position_dodge(.3), alpha = .5) +
  stat_summary(geom = "line", position = position_dodge(.3)) +
  geom_hline(yintercept = d.io.categorisation[[9]][1], linetype = 2, linewidth = 0.8, colour = "#cc0000", alpha = 0.5) +
  geom_hline(yintercept = d.io.categorisation[[9]][2], linetype = 2, linewidth = .8, colour = "#12D432", alpha = 0.5) +
  geom_hline(yintercept = d.io.categorisation[[9]][3], linetype = 2, linewidth = .8, colour = "#0481F3", alpha = 0.5) +
  scale_colour_manual("Condition",
    labels = c("+0ms", "+10ms", "+40ms"),
    values = c("#cc0000", "#12D432","#0481F3"),
    aesthetics = "color") +
  scale_y_continuous("Mean Intercept") +
  scale_x_discrete("Block", labels = c("1" = "Test 1", "2" = "Exposure 1", "3" = "Test 2", "4" = "Exposure 2", "5" = "Test 3", "6" = "Exposure 3", "7" = "Test 4", "8" = "Test 5", "9" = "Test 6")) +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 22.5, hjust = 1))
```


```{r, fig.width=3.5, fig.height=6.5, warning=FALSE}
p.params <- ((p.intercept + remove_x_guides) / (p.slope + remove_x_guides) / p.PSE) + 
  plot_layout( guides = "collect") &
  theme(legend.position = "none", axis.text = element_text(size = 8))
p.params
#ggsave("p.params_exp2.png", p.params, width = 14, height = 8, units = "cm", path = "~/Desktop/")
```


```{r}
# calculate the various mean VOTs exposed to for each condition, including the labelled trials, with and without accounting for the test trials
cond_means_test_exposure <- d.test_exposure_for_analysis %>% 
  group_by(Condition.Exposure) %>% 
  summarise(across(c(Item.VOT, Item.Mel_F0_5ms), mean, .names = "{.col}_mean_test_exposure"))
  
cond_means_exposure <- d.test_exposure_for_analysis %>% 
  filter(Phase == "exposure") %>% 
  group_by(Condition.Exposure) %>% 
  summarise(across(c(Item.VOT, Item.Mel_F0_5ms), mean, .names = "{.col}_mean_exposure"))

cond_means <- left_join(cond_means_test_exposure, cond_means_exposure)
```


```{r compare-density-database-with-exposure-means, fig.width=6.5, fig.height=4.5}
# ensuring that a particular proportion of points are included within each contour line
# adjusted from https://stackoverflow.com/questions/75598144/interpretation-of-2d-density-estimate-charts
# we can get the 2d density with MASS::kde2d, then convert to a raster using terra. We can then order the points according to the density in the associated 2d density grid and find the density at which a quantile is passed with approx
quantile_levels <- c(0, .05, .25, .5, .75, .95, .99)

density_quantiles <- function(x, y, quantiles) {
  require(terra)
  dens <- MASS::kde2d(x, y, n = 500)
  df   <- cbind(expand.grid(x = dens$x, y = dens$y), z = c(dens$z))
  r    <- terra::rast(df)
  ind  <- sapply(seq_along(x), function(i) cellFromXY(r, cbind(x[i], y[i])))
  ind  <- ind[order(-r[ind][[1]])]
  vals <- r[ind][[1]]
  ret  <- approx(seq_along(ind)/length(ind), vals, xout = quantiles)$y
  replace(ret, is.na(ret), max(r[]))
}

p.density <- 
  d.chodroff_wilson.selected %>% 
  ggplot(aes(x = VOT_centered, y = f0_Mel_centered, linetype = category, group = category)) +
  geom_density2d(
    data = . %>% filter(category == "/d/"),
    contour_var = "density", aes(alpha = after_stat(level)), 
    colour = "black",
    breaks = density_quantiles(x = d.chodroff_wilson.selected %>% filter(category == "/d/") %>% pull(VOT_centered), 
                               y = d.chodroff_wilson.selected %>% filter(category == "/d/") %>% pull(f0_Mel_centered),
                               quantiles = quantile_levels[-1])) +
  geom_density2d(
    data = . %>% filter(category == "/t/"),
    contour_var = "density", aes(alpha = after_stat(level)), 
    colour = "black",
    breaks = density_quantiles(x = d.chodroff_wilson.selected %>% filter(category == "/t/") %>% pull(VOT_centered), 
                               y = d.chodroff_wilson.selected %>% filter(category == "/t/") %>% pull(f0_Mel_centered),
                               quantiles = quantile_levels[-1])) +
  scale_y_continuous("F0 (Mel)", limits = c(118, 360)) + 
  scale_x_continuous("VOT (ms)", limits = c(-12, 125), breaks = scales::breaks_width(25)) +
  scale_alpha_continuous(breaks = quantile_levels, range = c(.1, 1), labels = scales::percent(quantile_levels)) +
  theme(legend.position = "top") +
  #plot the uncentred means
  geom_point(
    data = d.test_exposure_for_analysis %>% 
      filter(Phase == "exposure") %>% 
      group_by(Condition.Exposure) %>%
      mutate(
        category = factor(ifelse(Item.ExpectedResponse.Voicing == "voiced", "/d/", "/t/"))) %>% 
      group_by(Condition.Exposure, category) %>% 
      summarise(across(c(Item.VOT, Item.Mel_F0_5ms), mean)),
    mapping = aes(x = Item.VOT, y = Item.Mel_F0_5ms, colour = Condition.Exposure, shape = category),
    size = 2,
    shape = c(1, 2, 1, 2, 1, 2),
    alpha = 0.8,
  inherit.aes = F) +
  #plot centred means
  geom_point(
    data = d.test_exposure_for_analysis %>% 
      filter(Phase == "exposure") %>% 
      group_by(Condition.Exposure) %>%
      mutate(
        category = factor(ifelse(Item.ExpectedResponse.Voicing == "voiced", "/d/", "/t/")),
        Item.VOT_centered = case_when(
          Condition.Exposure == "Shift0" ~ Item.VOT + (chodroff.mean_VOT - cond_means$Item.VOT_mean_test_exposure[1]),
          Condition.Exposure == "Shift10" ~ Item.VOT + (chodroff.mean_VOT - cond_means$Item.VOT_mean_test_exposure[2]),
          Condition.Exposure == "Shift40" ~ Item.VOT + (chodroff.mean_VOT - cond_means$Item.VOT_mean_test_exposure[3])),
        Item.Mel_F0_5ms_centered = case_when(
          Condition.Exposure == "Shift0" ~ Item.Mel_F0_5ms + (chodroff.mean_f0_Mel - cond_means$Item.Mel_F0_5ms_mean_exposure[1]),
          Condition.Exposure == "Shift10" ~ Item.Mel_F0_5ms + (chodroff.mean_f0_Mel - cond_means$Item.Mel_F0_5ms_mean_exposure[2]),
          Condition.Exposure == "Shift40" ~ Item.Mel_F0_5ms + (chodroff.mean_f0_Mel - cond_means$Item.Mel_F0_5ms_mean_exposure[3]))) %>% 
      group_by(Condition.Exposure, category) %>% 
      summarise(across(c(Item.VOT_centered, Item.Mel_F0_5ms_centered), mean)),
    mapping = aes(x = Item.VOT_centered, y = Item.Mel_F0_5ms_centered, colour = Condition.Exposure, shape = category),
    size = 2,
    alpha = 0.8,
  inherit.aes = F,
  show.legend = T) +
  scale_colour_manual("Condition",
             labels = c("+0ms", "+10ms", "+40ms"),
             values = c("#cc0000", "#12D432","#0481F3")) +
  guides(colour = "none",
         linetype = guide_legend(title = "Category"),
         shape = guide_legend(title = "Category")) + 
 theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) + 
  remove_axes_titles 
```

```{r, warning=FALSE}
cov_d <- (d.chodroff_wilson.selected %>% 
  group_by(category) %>% 
  nest(data = -c(category)) %>% 
  mutate(covariance = map_dbl(data, ~ cov(.x$VOT_centered, .x$f0_Mel_centered))) %>% 
  pull(covariance))[1]

cov_t <- (d.chodroff_wilson.selected %>% 
  group_by(category) %>% 
  nest(data = -c(category)) %>% 
  mutate(covariance = map_dbl(data, ~ cov(.x$VOT_centered, .x$f0_Mel_centered))) %>% 
  pull(covariance))[2]

cat_d <- d.chodroff_wilson.selected %>% 
  filter(category == "/d/")

cues <- c("VOT", "f0_Mel")

d.category_ellipse <- d.chodroff_wilson.selected %>% 
  group_by(category) %>% 
  summarise(across(c(VOT_centered, f0_Mel_centered), list(mean = mean, var = var), .names = "{.col}.{.fn}")) %>% 
  mutate(cov = ifelse(category == "/d/", cov_d, cov_t),
         mu = map2(VOT_centered.mean, f0_Mel_centered.mean, ~ c("VOT" = .x, "f0_Mel" = .y)),
         Sigma = pmap(list(VOT_centered.var, f0_Mel_centered.var, cov), ~ matrix(c(..1, ..3, ..3, ..2), 2, 2, dimnames = list(cues, cues)))) %>% 
  select(c(category, mu, Sigma)) %>% 
  crossing(level = quantile_levels) %>% 
  group_by(category) %>%
  mutate(ellipse = c(1:length(quantile_levels)),
         ellipse_points = pmap(list(mu, Sigma, level), ~ get_bivariate_normal_ellipse(mu = ..1, Sigma = ..2, level = ..3))) %>% 
  group_by(ellipse) %>% 
  mutate(path = pmap(list(category, level, ellipse_points),
                     ~ geom_path(data = ..3, mapping = aes(x = ..3[[1]], y = ..3[[2]], linetype = ..1, colour = ..2))))

p.ellipse <- d.category_ellipse %>% 
  ggplot() +
  d.category_ellipse$path +
  scale_y_continuous("F0 (Mel)", limits = c(118, 360)) +
  scale_x_continuous("VOT (ms)", limits = c(-12, 125), breaks = scales::breaks_width(25)) +
  scale_color_gradient("Interval", low = "#000000",
  high = "#D0D0D0") +
  # scale_linetype_manual("Category", values = c(1, 2)) + 
  # theme(legend.position = "right") +
  new_scale_color() +
  #plot the uncentred means
  geom_point(
    data = d.test_exposure_for_analysis %>% 
      filter(Phase == "exposure") %>% 
      group_by(Condition.Exposure) %>%
      mutate(
        category = factor(ifelse(Item.ExpectedResponse.Voicing == "voiced", "/d/", "/t/"))) %>% 
      group_by(Condition.Exposure, category) %>% 
      summarise(across(c(Item.VOT, Item.Mel_F0_5ms), mean)),
    mapping = aes(x = Item.VOT, y = Item.Mel_F0_5ms, colour = Condition.Exposure, shape = category),
    size = 2,
    shape = c(1, 2, 1, 2, 1, 2),
    alpha = 0.8,
  inherit.aes = F,
  show.legend = F) +
  scale_colour_manual("Condition",
             labels = c("+0ms", "+10ms", "+40ms"),
             values = c("#cc0000", "#12D432","#0481F3")) +
  #plot the centered means
  geom_point(
    data = d.test_exposure_for_analysis %>% 
      filter(Phase == "exposure") %>% 
      group_by(Condition.Exposure) %>%
      mutate(
        category = factor(ifelse(Item.ExpectedResponse.Voicing == "voiced", "/d/", "/t/")),
        Item.VOT_centered = case_when(
          Condition.Exposure == "Shift0" ~ Item.VOT + (chodroff.mean_VOT - cond_means$Item.VOT_mean_test_exposure[1]),
          Condition.Exposure == "Shift10" ~ Item.VOT + (chodroff.mean_VOT - cond_means$Item.VOT_mean_test_exposure[2]),
          Condition.Exposure == "Shift40" ~ Item.VOT + (chodroff.mean_VOT - cond_means$Item.VOT_mean_test_exposure[3])),
        Item.Mel_F0_5ms_centered = case_when(
          Condition.Exposure == "Shift0" ~ Item.Mel_F0_5ms + (chodroff.mean_f0_Mel - cond_means$Item.Mel_F0_5ms_mean_test_exposure[1]),
          Condition.Exposure == "Shift10" ~ Item.Mel_F0_5ms + (chodroff.mean_f0_Mel - cond_means$Item.Mel_F0_5ms_mean_test_exposure[2]),
          Condition.Exposure == "Shift40" ~ Item.Mel_F0_5ms + (chodroff.mean_f0_Mel - cond_means$Item.Mel_F0_5ms_mean_test_exposure[3]))) %>% 
      group_by(Condition.Exposure, category) %>% 
      summarise(across(c(Item.VOT_centered, Item.Mel_F0_5ms_centered), mean)),
    mapping = aes(x = Item.VOT_centered, y = Item.Mel_F0_5ms_centered, colour = Condition.Exposure, shape = category),
    size = 2,
    alpha = 0.8,
  inherit.aes = F,
  show.legend = F) +
  guides(linetype = "none")
  # scale_colour_manual("Condition",
  #            labels = c("+0ms", "+10ms", "+40ms"),
  #            values = c("#cc0000", "#12D432","#0481F3")) +
```


```{r}
(p.density / p.ellipse) +
  plot_layout(ncol = 1, guides = "collect") &
  theme(legend.position = "right")
```











\newpage

<!-- This is a markdown comment that will NOT show when you knit the document.  -->

All data and code for this article can be downloaded from[https://osf.io/q7gjp/](OSF). This article is written in R markdown, allowing readers to replicate our analyses with the press of a button using freely available software [R, @R; @RStudio], while changing any of the parameters of our models. Readers can revisit any of the assumptions we make---for example, by substituting alternative models of linguistic representations. The supplementary information (SI, \@ref(sec:SI-software)) lists the software/libraries required to compile this document. Beyond our immediate goals here, we hope that this can be helpful to researchers who are interested in developing more informative experimental designs, and to facilitate the interpretation of existing results [see also @tan2021]. 