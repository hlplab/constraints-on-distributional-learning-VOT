---
title: "cut out stuff"
author: "T. Florian Jaeger"
date: "2023-05-31"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
colours.voicing <- c("#7EC8E3", "#990033")
colours.sex <- c("#c1502e", "#2F9FC2")


    Condition.Exposure = case_when(
    Condition.Exposure == "Shift0" ~ "baseline",
    Condition.Exposure == "Shift10" ~ "+10ms",
    Condition.Exposure == "Shift40" ~ "+40ms"), 
    Condition.Exposure = fct_relevel(
          Condition.Exposure, c("baseline", "+10ms", "+40ms")),


############################################################################
# function to plot talker productions in experiment 1 (section 2.3)
############################################################################

plot_talker_UVGs <- function (data_production, data_perception, noise = FALSE) {
  plot <- data_production %>%
    mutate(x = list(VOT = seq(-100, 130, .5)),
           x = map(x, ~ as_tibble(.x) %>% rename("VOT (ms)" = value))) %>%
    unnest(io) %>%
    mutate(
      gaussian = pmap(
        list(x, gender, category, mu, Sigma, Sigma_noise),
        ~ geom_function(
          data = ..1,
          aes(x = `VOT (ms)`,
              linetype = ..3, colour = ..2),
          fun = function(x) dnorm(x, mean = ..4[[1]][[1]], sd = if (noise == T) sqrt(..5[[1]][[1]]) + sqrt(..6[[1]][[1]]) else sqrt(..5[[1]][[1]])), alpha = .2)))

  plot %>%
    ggplot() +
    plot$gaussian +
    scale_colour_manual("Talker sex", values = colours.sex, labels = c("Female", "Male")) +
    scale_linetype_discrete("Category") +
    scale_y_continuous("Density") +
    geom_rug(
      data = data_perception %>%
        ungroup() %>%
        distinct(Item.VOT),
      mapping = aes(x = Item.VOT),
      colour = "black",
      alpha = .6,
      inherit.aes = F) +
    guides(colour = "none")
}



plot_talker_MVGs <- function(
  data_production,
  prod_means = c(chodroff.mean_VOT, chodroff.mean_f0_Mel),
  cues,
  data_perception = d.test.excluded,
  percept_means = c(VOT.mean_exp1, f0.mean_exp1),
  centered = F
) {
  plot <- data_production %>%
    unnest(io) %>%
    select(-c(x, PSE, categorization, line)) %>%
    mutate(ellipse_points = pmap(
      list(mu, Sigma, Sigma_noise),
      ~ get_bivariate_normal_ellipse(..1, Sigma = ..2 + ..3))) %>%
    group_by(Talker) %>%
    mutate(ellipse = pmap(
      list(gender, category, ellipse_points),
      ~ geom_path(data = ..3, mapping = aes(x = ..3[[1]], y = ..3[[2]], colour = ..1, linetype = ..2), alpha = .1)))

  plot %>%
    ggplot() +
    plot$ellipse +
    scale_x_continuous("VOT (ms)", breaks = seq(-100, 150, 50)) +
    scale_y_continuous("F0 (Mel)") +
    scale_colour_manual("Talker sex", values = colours.sex, labels = c("Female", "Male")) +
    scale_linetype_discrete("Category") +
    geom_point(
      data = if (centered == T) data_perception %>%
        ungroup() %>%
        distinct(Item.VOT, Item.Mel_f0_5ms) %>%
        mutate(Item.VOT = Item.VOT + (prod_means[1] - percept_means[1]),
               Item.Mel_f0_5ms = Item.Mel_f0_5ms + (prod_means[2] - percept_means[2])) else
                 data_perception %>%
        ungroup() %>%
        distinct(Item.VOT, Item.Mel_f0_5ms),
      aes(x = Item.VOT, y = Item.Mel_f0_5ms),
      shape = 4,
      size = .8,
      alpha = .2,
      inherit.aes = F) +
    geom_abline(intercept = if (centered == T) normMel(245.46968) + (prod_means[2] - percept_means[2]) else normMel(245.46968),
               slope = 0.03827,
               linetype = 2,
               alpha = .3) +
    guides(colour = "none", category = "none")
}
```

END OF INTRO: 
The code for the experiment is available as part of the OSF repository for this article. A live version is available at (https://www.hlp.rochester.edu/FILLIN-FULL-URL). 
+ ALL OTHER OSF STATEMENTS.


Prior to creating the three exposure conditions for the experiment, we conducted a norming experiment (N = XXX participants) to assess US-L1 listeners' perception of our stimuli and to determine a baseline categorisation boundary for this talker. While it is normal and acceptable practice to set the baseline by taking population estimates of mean values from past studies on stops, we reasoned that such estimates were highly variable and therefore aimed to obtained a more accurate estimation of how L1-US English listeners perceived the speech of our talker. To anticipate the outcome, we eventually discovered that the classification boundary from norming underestimated the boundary fitted to our participants' classification in the initial test block. This placed our baseline and baseline +10ms shift exposure conditions slightly leftwards of participants' initial perceptual boundary. This finding, however does not impinge on the conclusions drawn from this study [<!--CALL IT baseline, +10 AND +40-->]

The other purpose of the norming experiment was to detect possible anomalous features present in our stimuli (for e.g. if it would elicit unusual categorisation behaviour or whether certain minimal-pairs had an exaggerated effect on categorisation). For the norming experiment the VOT continua employed 24 VOT steps ranging from -100ms VOT to +130ms (-100, -50, -10, 5  `r paste0(seq(15, 90, 5), collapse = ", ")`, `r paste0(seq(100, 130, 10), collapse = ", ")`). VOT tokens in the lower and upper ends were distributed over larger increments because stimuli in those ranges were expected to elicit floor and ceiling effects, respectively. We found VOT to have the expected effect on the proportion of "t"-responses, i.e. higher VOTs elicited greater "t"-responses and that the word-pairs did not differ substantially from each other. The results and analysis of the norming experiment are reported in full in section \@ref(sec:XX).  




To construct the baseline exposure distribution we first computed the point of subjective equality (PSE) from the perceptual component of the fitted psychometric function of listener responses in the norming experiment. The PSE corresponds to the VOT duration that was perceived as most ambiguous across all participants during norming (i.e. the stimulus that on average, elicited equal chance of being categorised as /d/ or /t/) thus marking the categorical boundary. From a distributional perspective the PSE is where the likelihoods of both categories intersect and have equal probability density (we assumed Gaussian distributions and equal prior probability for each category). To limit the infinite combinations of category likelihoods that could intersect at this value, we set the variances of the /d/ (80ms) and /t/ (270ms <!--/t/ variance lowered from original 398ms estimate because of dip-tip pair variance limitations--> categories based on parameter estimates (@Kurumada_Xie_Jaeger_2022) obtained from the production database of word-initial stops in @chodroff2017structure. To each variance value we added 80ms following (@kronrod2016unified) to account for variability due to perceptual noise since these likelihoods were estimated from perceptual data. We took an additional degree of freedom of setting the *distance between the means* of the categories at 46ms; this too was based on the mean  for /d/ and /t/ estimated from the production database. The means of both categories were then obtained through a grid-search process to find the likelihood distributions that crossed at 25ms VOT (see XX of SI for further detail on this procedure).


The distributional make up was determined through a process of sampling tokens from a discretised normal distribution with values rounded to the nearest multiple of 5 integer (available through the `extraDistr` package in R). 


In addition, participants' categorization during the early phase of the experiment were scrutinised for their slope orientation and their proportion of "t"-responses at the least ambiguous locations of the VOT continuum. The early phase of the experiment was defined as the first 36 trials and the least ambiguous locations were defined as -20ms below the empirical mean of the /d/ category and +20ms above the empirical mean of the /t/ category. These means were obtained from the production data estimates by @Kurumada_Xie_Jaeger_2022.
