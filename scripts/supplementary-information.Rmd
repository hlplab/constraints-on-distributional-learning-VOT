<!-- Do NOT knit this document. It is part of a larger document. Instead knit the main document (my-apa-formatted-article) 
     If you want to separate the SI from the rest of the paper, we recommend you do so AFTER knitting them into a single PDF. 
     This will make sure that all references to sections, figures, tables, etc. are working as intended. You can easily separate 
     the PDF into two parts, using e.g., Acrobat PDF viewer. //-->
     
# Supplementary information {-}
\setcounter{section}{0}

Both the main text and these supplementary information (SI) are derived from the same R markdown document available via [OSF](). It is best viewed using Acrobat Reader. Some links and animations might not work in other PDF viewers. 

# Required software {#sec:SI-software}
The document was compiled using \texttt{knitr} [@xie2021] in RStudio with R:

```{r} 
version
```

You will also need to download the IPA font [SIL Doulos](https://software.sil.org/doulos/download/) and a Latex environment like (e.g., [MacTex](https://tug.org/mactex/mactex-download.html) or the R library \texttt{tinytex}). 

We used the following R packages to create this document: `r cite_r("latex-stuff/r-references.bib", withhold = T, pkgs = c("MVBeliefUpdatr"))`. If opened in RStudio, the top of the R markdown document should alert you to any libraries you will need to download, if you have not already installed them. The full session information is provided at the end of this document.

# Overview

## Overview of data organisation

# Stimuli generation for perception experiments
## Recording of audio stimuli
## Annotation of audio stimuli
## Synthesis of audio stimuli

# Web-based experiment design procedure
## Making exposure conditions


## Ideal observer training
We train the IOs on cue distributions extracted from an annotated database of XX L1 US-English talkers' productions (@chodroff2017structure) of word initial stops. We apply Bayes' theorem to derive the IOs' posterior probability of categorising the test stimuli as "t". This is defined as the product of the likelihood of the cue under the hypothesis that the talker produced "t", and the prior probability of that cue. By using IOs trained solely on production data to predict categorization behaviour we avoid additional computational degrees of freedom and limit the risk of overfitting the model to the data thus reducing bias. 

We filtered the database to /d/s and /t/s which gave 92 talkers (4x male and 4x female), each with a minimum of 25 tokens. We then fit ideal observers to each talker under different hypotheses of distributional learning [and evaluated their respective goodness-of-fit to the human data]. In total we fit x IOs to represent the different hypotheses about listeners' implicit knowledge -- models grouped by sex, grouped by sex and   Predictions of the IO were obtained using talker-normalized category statistics for /d/ and /t/ from [@Kurumada_Xie_Jaeger_2022] based on data from [@chodroff2017], perceptual noise estimates for VOT from [@kronrod2016unified], and a lapse rate identical to the psychometric model estimate. 

# Session Info

```{r session_info, echo=FALSE, results='markup'}
devtools::session_info()
```

