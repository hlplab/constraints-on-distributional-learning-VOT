<!-- Do NOT knit this document. It is part of a larger document. Instead knit the main document (my-apa-formatted-article) 
     If you want to separate the SI from the rest of the paper, we recommend you do so AFTER knitting them into a single PDF. 
     This will make sure that all references to sections, figures, tables, etc. are working as intended. You can easily separate 
     the PDF into two parts, using e.g., Acrobat PDF viewer. //-->
     
# Supplementary information {-}
\setcounter{section}{0}

Both the main text and these supplementary information (SI) are derived from the same R markdown document available via [OSF](). It is best viewed using Acrobat Reader. Some links and animations might not work in other PDF viewers. 

# Required software {#sec:SI-software}
The document was compiled using \texttt{knitr} [@xie2021] in RStudio with R:

```{r} 
version
```

You will also need to download the IPA font [SIL Doulos](https://software.sil.org/doulos/download/) and a Latex environment like (e.g., [MacTex](https://tug.org/mactex/mactex-download.html) or the R library \texttt{tinytex}). 

We used the following R packages to create this document: `r cite_r("latex-stuff/r-references.bib", withhold = T, pkgs = c("MVBeliefUpdatr"))`. If opened in RStudio, the top of the R markdown document should alert you to any libraries you will need to download, if you have not already installed them. The full session information is provided at the end of this document.

# Overview

## Overview of data organisation

# Stimuli generation for perception experiments
## Recording of audio stimuli
## Annotation of audio stimuli
## Synthesis of audio stimuli
- acoustic plots

# Web-based experiment design procedure
## Experiment 1
### Making exposure conditions
### Exclusions analysis
### Regression analysis - model selection

```{r comparing-regression-models, fig.height=3, fig.width=5.5, fig.cap="Expected effect of VOT interacting with trial on categorisation from model: 1 + (sVOT + sFO) * sTrial shown as red dashed line with pink shaded CI. Grey line and shaded area represents effects of VOT interacting with trial from model: 1 + sVOT * sTrial"}
# run an alternative model with f0 as a predictor
# get f0 mean and sd for scaling
f0.mean_exp1 <- mean(d.test.excluded$Item.Mel_f0_5ms)
f0.sd_exp1 <- sd(d.test.excluded$Item.Mel_f0_5ms)
d.test.excluded %<>% 
  mutate(sF0 = (Item.Mel_f0_5ms - f0.mean_exp1)/(2 * f0.sd_exp1))

# specify new model formula (priors will be same as previous model without f0)
fit_mix_f0 <- brm(
  bf(
    Response.Voicing == "voiceless" ~ 1,
    mu1 ~ 1 + (1 | g | ParticipantID),
    mu2 ~ 1 + (sVOT + sF0) * sTrial + (1 + (sVOT + sF0) * sTrial | g | ParticipantID) + (1 + (sVOT + sF0) * sTrial | h | Item.MinimalPair),
    theta1 ~ 1 + (1 | g | ParticipantID)),
  data = d.test.excluded,
  cores = 4,
  iter = 4000,
  warmup = 2000,
  family = mixture(bernoulli("logit"), bernoulli("logit")),
  control = list(adapt_delta = .99),
  file = "../models/Exp-NORM-lapsing-Trial-F0.rds")

if (file.exists("../models/conditional_effects_fit_mix_f0.csv")){
  fit_mix_f0_data <- read_rds("../models/conditional_effects_fit_mix_f0.csv")
} else {
  int_conditions <- list(sTrial = sort(unique((d.test.excluded$Trial - Trial.mean)) / (2 * Trial.sd)))
  
  fit_mix_f0_data <- conditional_effects(
    fit_mix_f0, 
    effects = "sVOT:sTrial", 
    int_conditions = int_conditions,
    ndraws = 1000,
    plot = F)[[1]] # by default this does not include any group level effects
  
  write_rds(fit_mix_f0_data, "../models/conditional_effects_fit_mix_f0.rds")
}



# plotting conditional effects of VOT from the 2 models side-by-side
psychometric_fit_exp1 %>% 
  group_by(sVOT) %>% 
  summarise(estimate__ = mean(estimate__),
            lower__ = mean(lower__),
            upper__ = mean(upper__)) %>% 
     ggplot(aes(x = descale(sVOT, VOT.mean_exp1, VOT.sd_exp1), 
             y = estimate__, linetype = "solid")) + 
    geom_ribbon(
    data = fit_mix_f0_data, 
    mapping = aes(
      x = descale(sVOT, VOT.mean_exp1, VOT.sd_exp1),
      ymin = lower__, 
      ymax = upper__),
    fill = "red",
    alpha = 0.05,
    inherit.aes = F) +
  geom_ribbon(aes(ymin = lower__, ymax = upper__),
              fill = "#333333",
              alpha = .1) +
  geom_line(linewidth = 1.5, 
            colour = "#333333",
            alpha = .2) +
    geom_line(
      data = fit_mix_f0_data, 
      mapping = aes(x = descale(sVOT, VOT.mean_exp1, VOT.sd_exp1), 
             y = estimate__, linetype = 2), 
      colour = "red",
    linetype = 2,
      alpha = .5,
      linewidth = 1.5,
      inherit.aes = F) + 
  scale_x_continuous("VOT (ms)", limits = c(-100, 130)) +
  scale_y_continuous("Fitted proportion of 't' responses") +
  scale_linetype_manual("Model", values = c("solid" = 1, "dashed" = 2), labels = c("1 + sVOT  * sTrial", "fit with F0"))

```



## Experiment 2
### Making exposure conditions
### Exclusions analysis
- reaction time plots
- catch trial performance plots
### Regression analysis - model selection

```{r catch-trial-performance, fig.height=4, fig.width=6}
d.exposure_test %>% 
  group_by(ParticipantID) %>% 
  summarise(No.CatchTrial.Correct = sum(CatchTrial.Correct, na.rm = T)) %>%
  ggplot(aes(x = No.CatchTrial.Correct)) +
  geom_bar(width = .6) +
  scale_x_continuous("Number of correct catch trials", breaks = seq(0, 18, 1)) +
  scale_y_continuous("Number of participants") 
```


-labelled trial performance plots
```{r labeled-trial-performance-group, fig.width=6, fig.height=4, message=F}
p.labelled <- d.exposure_test %>% 
  filter(Phase == "exposure") %>% 
  group_by(ParticipantID, Condition.Exposure) %>% 
  summarise(LabeledTrial.Correct = sum(LabeledTrial.Correct, na.rm = TRUE)) %>% 
  group_by(Condition.Exposure, LabeledTrial.Correct) %>% 
  summarise(freq = n()) %>% 
  ggplot(aes(x = LabeledTrial.Correct, y = freq, fill = Condition.Exposure)) +
  geom_bar(stat = "identity", position = position_dodge2(width = .5, preserve = "single"), width = .5) +
  geom_text(aes(label = freq), position = position_dodge(width = .5), vjust = -.5) +
  scale_colour_manual("Exposure condition", 
                      aesthetics = c("colour", "fill"), 
                      breaks = c("Shift0", "Shift10", "Shift40"), 
                      values = c("#cc0000", "#12D432","#0481F3")) +
  scale_x_continuous("Total labelled trials correct") +
  scale_y_continuous("No. of participants", breaks  = seq(0, 115, 5)) +
  theme(legend.position = "none") 
```


```{r labeled-trial-performance, fig.width=6, fig.height=4, message=F}
p.labelled.group <- d.exposure_test %>% 
  filter(Phase == "exposure") %>% 
  group_by(ParticipantID, Condition.Exposure, Block) %>% 
  summarise(LabeledTrial.Correct = sum(LabeledTrial.Correct, na.rm = TRUE)) %>% 
  ggplot(aes(x = LabeledTrial.Correct, fill = Condition.Exposure)) +
  geom_bar(position = position_dodge(width = .5, preserve = "single"), width = .5) +
  scale_colour_manual("Exposure condition", 
                      aesthetics = c("colour", "fill"), 
                      breaks = c("Shift0", "Shift10", "Shift40"), 
                      values = c("#cc0000", "#12D432","#0481F3")) +
  scale_x_continuous("Total labelled trials correct") +
  theme(legend.position = "top") +
  facet_grid(Condition.Exposure ~ Block) 

p.labelled + p.labelled.group + plot_layout(guides = "collect") & theme(legend.position = "top")
```


```{r, message=FALSE, fig.width=6, fig.height=5}
d.exposure_test %>% 
  filter(Is.CatchTrial == FALSE & Phase == "exposure") %>% 
  mutate(Item.Labeled = factor(ifelse(Item.Labeled == TRUE, "labeled", "unlabeled"))) %>% 
  summarise(Condition.Exposure, Block, Item.Labeled, Response.Correct) %>% 
  ggplot(aes(x = Response.Correct, fill = Item.Labeled)) +
  geom_bar(position = position_dodge2(width = .5, preserve = "single"), width = .5) +
  scale_x_discrete("Response", labels = c("incorrect", "correct")) +
  scale_colour_manual("Labelling", aesthetics = c("colour", "fill"), breaks = c("labeled", "unlabeled"), values = c("#f6546a", "#00ced1")) +
  theme(legend.position = "top") +
  facet_grid(Condition.Exposure ~ Block) 
```


```{r fig,width=8, fig.height=5, fig.width=6}
d.exposure_test %>%
  group_by(ParticipantID, Condition.Exposure, Block) %>%
  filter(Is.CatchTrial == FALSE) %>%
  mutate(Response.log_RT = log10(Response.RT)) %>%
  summarise_at("Response.log_RT", .funs = list("mean" = mean, "sd" = sd)) %>%
  ggplot(aes(x = mean, y = sd, label = ParticipantID)) +
  geom_text(aes(colour = Condition.Exposure), alpha = .5) +
  geom_rug(aes(colour = Condition.Exposure), alpha = .5) +
  scale_x_continuous("mean log-RT (log10 of msec)") +
  scale_y_continuous("SD of log-RT") +
  scale_color_manual("Exposure condition", 
                      aesthetics = c("colour", "fill"), 
                      breaks = c("Shift0", "Shift10", "Shift40"), 
                      values = c("#cc0000", "#12D432","#0481F3")) +
  theme(legend.position = "top") +
  facet_wrap( ~ Block )
```




```{r, fig.width=8, fig.height=3}
d.exposure_test %>% 
  group_by(Trial, Condition.Exposure, Block) %>%
  mutate(Response.log_RT = log10(Response.RT)) %>%
  summarise_at("Response.log_RT", .funs = list("mean" = mean, "sd" = sd)) %>% 
  ggplot(aes(x = Trial, y = mean)) +
  geom_ribbon(aes(ymin = mean - 2*sd, ymax = mean + 2*sd), colour = "lightgrey", alpha = .1) +
  geom_line(aes(group = Condition.Exposure, color = Condition.Exposure), size = 1) +
  scale_x_continuous("Trial", breaks = c(12, 24, 36, 48)) +
  scale_y_continuous("mean log-RT (log10 of msec)") +
  coord_trans(y = "log10") +
      scale_color_manual("Exposure condition", 
                      aesthetics = c("colour", "fill"), 
                      breaks = c("Shift0", "Shift10", "Shift40"), 
                      values = c("#cc0000", "#12D432","#0481F3")) +
  facet_grid(Condition.Exposure~ Block, scales = "free_x", space = "free_x") +
  theme(legend.position = "top")
```


## Ideal observer training
We train the IOs on cue distributions extracted from an annotated database of XX L1 US-English talkers' productions (@chodroff2017structure) of word initial stops. We apply Bayes' theorem to derive the IOs' posterior probability of categorising the test stimuli as "t". This is defined as the product of the likelihood of the cue under the hypothesis that the talker produced "t", and the prior probability of that cue. By using IOs trained solely on production data to predict categorization behaviour we avoid additional computational degrees of freedom and limit the risk of overfitting the model to the data thus reducing bias. 

We filtered the database to /d/s and /t/s which gave 92 talkers (4x male and 4x female), each with a minimum of 25 tokens. We then fit ideal observers to each talker under different hypotheses of distributional learning [and evaluated their respective goodness-of-fit to the human data]. In total we fit x IOs to represent the different hypotheses about listeners' implicit knowledge -- models grouped by sex, grouped by sex and   Predictions of the IO were obtained using talker-normalized category statistics for /d/ and /t/ from [@Kurumada_Xie_Jaeger_2022] based on data from [@chodroff2017], perceptual noise estimates for VOT from [@kronrod2016unified], and a lapse rate identical to the psychometric model estimate. 

# Session Info

```{r session_info, echo=FALSE, results='markup'}
devtools::session_info()
```

