```{r, stand-alone-preamble}
require(tidyverse)
require(magrittr)

require(brms)
require(tidybayes)
require(MVBeliefUpdatr)
require(phonR)
require(cowplot)

source("functions.R")
```




## Methods 
### Participants
Participants were recruited over the Prolific platform and experiment data (but not participant profile data) were collected, stored, and via proliferate (@schuster). They were paid $8.00 each (for a targeted remuneration of \$9.60/hour). The experiment was visible to participants following a selection of Prolific's available pre-screening criteria. Participants had to (1) have US nationality, (2) report to only know English, and (3) had not previously participated in any experiment from our lab on Prolific.

126 L1 US English listeners (male = 60, female = 59, NA = 3; mean age = 38 years; SD age = 12 years) completed the experiment. Due to data transfer errors 4 participants' data were not stored and therefore not included in this analysis. To be eligible, participants had to confirm that they (1) spent at least the first 10 years of their life in the US speaking only English, (2) were in a quiet place and free from distractions, and (3) wore in-ear or over-the-ears headphones that cost at least \$15. 

### Materials 

We recorded multiple tokens of four minimal word pairs ("dill"/"till", "dim"/"tim", "din"/"tin", and "dip"/"tip") from a 23-year-old, female L1 US English talker from New Hampshire, judged to have a "general American" accent. These recordings were used to create four natural-sounding minimal pair VOT continua (dill-till, dip-tip, din-tin, and dip-tip) using a Praat script [@winn2020manipulation]. In addition to the critical minimal pair continua we also recorded three words that did not did not contain any stop consonant sounds ("flare", "share", and "rare"). These word recordings were used as catch trials. Stimulus intensity was set to 70 dB sound pressure level for all recordings. The full procedure is described in the supplementary information (SI, \@ref(sec:SI-XXX)). 

We also set the F0 at vowel onset to follow the speaker's natural correlation which was estimated through a linear regression analysis of all the recorded speech tokens. We did this so that we could determine the approximate corresponding f0 values at each VOT value along the continua as predicted by this talker's VOT. The duration of the vowel was set to follow the natural trade-off relation with VOT reported in @allen1999effects. This approach resulted in continuum steps that sound highly natural [unlike the robotic-sounding stimuli employed in @clayards2008perception; @kleinschmidt2016you]. All stimuli are available as part of the OSF repository for this article.

Prior to creating the three exposure conditions of the experiment, we ran a norming experiment to test US-L1 listeners' perception of our stimuli and to determine a baseline categorisation boundary for this talker. The norming experiment also served as a measure to detect possible anomalous features present in our stimuli (for e.g. if it would elicit unusual categorisation behaviour or whether certain minimal-pairs had an exaggerated effect on categorisation). For the norming experiment the VOT continua employed 24 VOT steps ranging from -100ms VOT to +130ms (-100, -50, -10, 5  `r paste0(seq(15, 90, 5), collapse = ", ")`, `r paste0(seq(100, 130, 10), collapse = ", ")`). VOT tokens in the lower and upper ends were distributed over larger increments because stimuli in those ranges were expected to elicit floor and ceiling effects, respectively. We found VOT to have the expected effect on the proportion of "t"-responses, i.e. higher VOTs elicited greater "t"-responses and that the word-pairs did not differ substantially from each other. The results and analysis of the norming experiment are reported in full in section \@ref(sec:XX).  


A subset of the materials were used to generate the three exposure conditions; in particular three continua of the minimal pairs, dill-till, din-tin, and dip-tip. The dim-tim continuum was omitted in order to keep the pairs as distinct as possible. 

We employed a multi-block exposure-test design \@ref(fig:exp2-design-figure) which enabled the assessment of listener perception before informative exposure as well as incrementally at intervals  during informative exposure (after every 48 exposure trials). To have a comparable test between blocks and across conditions, test blocks were made up of a uniform distribution of 12 VOT stimuli (-5, 5, 15, 25, 30, 35, 40, 45, 50, 55, 65, 70), identical across test blocks and between conditions. Each of the test tokens were presented once at random. The test blocks were kept short to minimise distortion of the intended distribution to be presented by the end of the exposure phase. After the final exposure block we tripled the number of test blocks to increase the statistical power to detect exposure induced behavioural changes. 

The conditions were created by first generating the baseline distribution (+0ms shift) and then shifting that distribution by +10ms and by +40ms to the right of the VOT continuum to create the remaining two conditions. 

To construct the +0ms shift exposure distribution we first computed the point of subjective equality (PSE) from the perceptual component of the fitted psychometric function of listener responses in the norming experiment. The PSE corresponds to the VOT duration that was perceived as most ambiguous across all participants during norming (i.e. the stimulus that on average, elicited equal chance of being categorised as /d/ or /t/) thus marking the categorical boundary. From a distributional perspective the PSE is where the likelihoods of both categories intersect and have equal probability density (we assumed Gaussian distributions and equal prior probability for each category) [SOMETHING HERE ABOUT GAUSSIANS BEING A CONVENIENT ASSUMPTION?]. To limit the infinite combinations of category likelihoods that could intersect at this value, we set the variances of the /d/ (80ms) and /t/ (270ms (lowered from 398 because of dip-tip pair limitations)) categories based on parameter estimates (@Kurumada_Xie_Jaeger_2022) obtained from the production database of word-initial stops in @chodroff2017structure. To each variance value we added 80ms following (@kronrod2016unified) to account for variability due to perceptual noise since these likelihoods were estimated from perceptual data. We took an additional degree of freedom of setting the *distance between the means* of the categories at 46ms; this too was based on the mean  for /d/ and /t/ estimated from the production database. The means of both categories were then obtained through a grid-search process to find the likelihood distributions that crossed at 25ms VOT (see XX of SI for further detail on this procedure).

The distributional make up was determined through a process of sampling tokens from a discretised normal distribution with values rounded to the nearest multiple of 5 integer (available through the `extraDistr` package in R). 
For each exposure block 8 VOT tokens per minimal word pair were sampled from discrete normal distributions of each category of the +0ms condition, giving 24 /d/ and 24 /t/ items (48 critical trials) per block. Additionally, each exposure block contained 2 instances of 3 catch items, giving 6 catch trials per block. The sampled distributions of VOT tokens were increased by a margin of +10ms and +40 ms to create the remaining two conditions. Three variants of each condition list were created so that exposure blocks followed a latin-square order. 

Lastly, half of the exposure trials were randomly assigned as labelled trials. In labelled trials, participants receive clear information of the word's category as both orthographic options will always begin with the intended sound. For example if a trial was intended to be "dill" then the two image options will either be "dill" and "dip" or "dill" and "din". Test trials were always *unlabelled*. 

```{r exp2-design-distribution, fig.height=3, fig.width=6, warning=FALSE, message=FALSE}
# read in exposure block sampled tokens
d.exposure <- read_csv("../data/exposure_block_tokens.csv", show_col_types = F)

# set variances of categories
var_d <- 80
var_t <- 270

d.means <- 
  crossing(condition = c("+0ms", "+10ms", "+40ms"),
         category = c("/d/", "/t/")) %>% 
  mutate(mean = c(5, 50, 15, 60, 45, 90))

d.exposure %>% 
  na.omit() %>% 
  filter(image_selection == "forward" & list_LSQ_variant == "A") %>% 
  mutate(condition = case_when(condition == "Shift0" ~ "+0ms",
                               condition == "Shift10" ~ "+10ms",
                               condition == "Shift40" ~ "+40ms"),
         labelling = as_factor(labelling)) %>% 
  ggplot() +
  geom_histogram(aes(x = VOT, fill = paste(condition, category, labelling), 
                     color = paste(condition, category, labelling),
                     linetype = labelling), 
                 alpha = .8) +
  scale_colour_manual(
    "Labelling",
    values = c(
    "+0ms /d/ labeled" = "#800000", 
    "+0ms /d/ unlabeled" = "#ff9999",
    "+0ms /t/ labeled" = "#cc0000", 
    "+0ms /t/ unlabeled" = "#ffe6e6",
    "+10ms /d/ labeled" = "#0a751c",
    "+10ms /d/ unlabeled" = "#b9f9c3",
    "+10ms /t/ labeled" = "#12D432",
    "+10ms /t/ unlabeled" = "#e8fdeb",
    "+40ms /d/ labeled" = "#02427e", 
    "+40ms /d/ unlabeled" = "#b4dafe",
    "+40ms /t/ labeled" = "#0481F3", 
    "+40ms /t/ unlabeled" = "#e6f3ff"),
    aesthetics = c("color", "category", "fill"),
    labels = c("/d/ labeled", "/d/ unlabeled", "/t/ labeled", "/t/ unlabeled", "", "", "", "", "", "", "", "")) +
    guides(colour = guide_legend(override.aes = list(
    colour = c("#383838", "#C0C0C0", "#606060", "#F0F0F0", 0, 0, 0, 0, 0, 0, 0, 0),
    fill = c("#383838", "#C0C0C0", "#606060", "#F0F0F0", 0, 0, 0, 0, 0, 0, 0, 0),
    linetype = c(2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0),
    values = c("/d/ labeled", "/d/ unlabeled", "/t/ labeled", "/t/ unlabeled", 0, 0, 0, 0, 0, 0, 0, 0)), nrow = 1)) +
  stat_function(fun = function(x) 72 * 5 * dnorm(x, 5, sqrt(var_d)),
                color = "black", size = .6, alpha = .7, linetype = 2) +
  stat_function(
    fun = function(x) 72 * 5 * dnorm(x, 50, sqrt(var_t)),
    color = "black", size = .6, alpha = .5, linetype = 2) +
  geom_rug(data = tibble(VOT = c(5, 50)), aes(x = VOT), sides = "t") +
  scale_x_continuous("VOT (ms)", breaks = seq(-50, 150, 30)) +
  scale_y_continuous("Count") +
  geom_text(data = d.means,
            aes(x = 103, 
                y = 17,
                label = paste("mean", category, "=", mean)),
            size = 2,
            position = position_dodge2v(height = -8),
            inherit.aes = F) +
  facet_wrap(~ condition, scales = "free_y") +
  guides(linetype = "none") +
  theme(legend.position = "top",
        legend.box.spacing = unit(2, "pt"))
```
```{r}
d.means <- 
  crossing(condition = c("+0ms", "+10ms", "+40ms"),
         category = c("/d/", "/t/")) %>% 
  mutate(mean = c(5, 50, 15, 60, 45, 90))

d.exposure %>% 
  na.omit() %>% 
  filter(image_selection == "forward" & list_LSQ_variant == "A") %>% 
  mutate(condition = case_when(condition == "Shift0" ~ "+0ms",
                               condition == "Shift10" ~ "+10ms",
                               condition == "Shift40" ~ "+40ms"),
         labelling = as_factor(labelling)) %>% 
  ggplot() +
  geom_histogram(aes(x = VOT, fill = paste(condition, category, labelling), 
                     color = paste(condition, category, labelling),
                     linetype = labelling), 
                 alpha = .8) +
  scale_colour_manual(
    "Labelling",
    values = c(
    "+0ms /d/ labeled" = "#800000", 
    "+0ms /d/ unlabeled" = "#ff9999",
    "+0ms /t/ labeled" = "#cc0000", 
    "+0ms /t/ unlabeled" = "#ffe6e6",
    "+10ms /d/ labeled" = "#0a751c",
    "+10ms /d/ unlabeled" = "#b9f9c3",
    "+10ms /t/ labeled" = "#12D432",
    "+10ms /t/ unlabeled" = "#e8fdeb",
    "+40ms /d/ labeled" = "#02427e", 
    "+40ms /d/ unlabeled" = "#b4dafe",
    "+40ms /t/ labeled" = "#0481F3", 
    "+40ms /t/ unlabeled" = "#e6f3ff"),
    aesthetics = c("color", "category", "fill"),
    labels = c("/d/ labeled", "/d/ unlabeled", "/t/ labeled", "/t/ unlabeled", "", "", "", "", "", "", "", "")) +
    guides(colour = guide_legend(override.aes = list(
    colour = c("#383838", "#C0C0C0", "#606060", "#F0F0F0", 0, 0, 0, 0, 0, 0, 0, 0),
    fill = c("#383838", "#C0C0C0", "#606060", "#F0F0F0", 0, 0, 0, 0, 0, 0, 0, 0),
    linetype = c(2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0),
    values = c("/d/ labeled", "/d/ unlabeled", "/t/ labeled", "/t/ unlabeled", 0, 0, 0, 0, 0, 0, 0, 0)), nrow = 1)) +
  stat_function(fun = function(x) 72 * 5 * dnorm(x, 25, sqrt(var_d)),
                color = "black", size = .6, alpha = .7, linetype = 2) +
  stat_function(
    fun = function(x) 72 * 5 * dnorm(x, 70, sqrt(var_t)),
    color = "black", size = .6, alpha = .5, linetype = 2) +
  geom_rug(data = tibble(VOT = c(25, 70)), aes(x = VOT), sides = "t") +
  scale_x_continuous("VOT (ms)", breaks = seq(-50, 150, 30)) +
  scale_y_continuous("Count") +
  geom_text(data = d.means,
            aes(x = 103, 
                y = 17,
                label = paste("mean", category, "=", mean)),
            size = 2,
            position = position_dodge2v(height = -8),
            inherit.aes = F) +
  facet_wrap(~ condition, scales = "free_y") +
  guides(linetype = "none") +
  theme(legend.position = "top")
```




### Procedure
The code for the experiment is available as part of the OSF repository for this article. A live version is available at (https://www.hlp.rochester.edu/FILLIN-FULL-URL). The first page of the experiment informed participants of their rights and the requirements for the experiment: that they had to be native listeners of English, wear headphones for the entire duration of the experiment, and be in a quiet room without distractions. Participants had to pass a headphone test, and were asked to keep the volume unchanged throughout the experiment. Participants could only advance to the start of the experiment by acknowledging each requirement and consenting to the guidelines of the Research Subjects Review Board of the University of Rochester. 

On the next page, participants were informed about the task for the remainder of the experiment. They were informed that they would hear a female talker speak a single word on each trial, and had to select which word they heard. They were also informed that they needed to click a green button that would be displayed during each trial when it "lights up" in order to hear the recording of the speaker saying the word. Participants were instructed to listen carefully and answer as quickly and as accurately as possible. They were also alerted to the fact that the recordings were subtly different and therefore may sound repetitive. This was done to encourage their full attention.

Each trial started with a dark-shaded green fixation dot being displayed. At 500ms from trial onset, two minimal pair words appeared on the screen, as shown in Figure \@ref(fig:exp1-example-trial). At 1000ms from trial onset, the fixation dot would turn bright green and participants had to click on the dot to play the recording. Participants responded by clicking on the word they heard and the next trial would begin. The placement of the word presentations were counter-balanced across participants.

Participants underwent 234 trials which included 6 catch trials in each exposure block (18 in total). Since these recordings were easily distinguishable, they served as a check on participant attention throughout the experiment.  Catch trials were distributed randomly throughout the experiment with the constraint that no more than two catch trials would occur in a row. Participants were given the opportunity to take breaks after every 60 trials during exposure blocks. Participants took an average of 17 minutes (SD = 9) to complete the 234 trials, after which they answered a short survey about the experiment.

```{r example-trial, fig.cap="Example trial display. The words were displayed 500ms after trial onset. The green button would turn bright green signalling participants to click on the dot to play the recording."}
knitr::include_graphics("../figures/exp1_trial_example.png")
```









\newpage








