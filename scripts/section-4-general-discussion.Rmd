<!-- Do NOT knit this document. It is part of a larger document. Instead knit the main document (my-apa-formatted-article) -->

<!-- TO DO: discuss reasons for slope discrepancies? 1) slope changes with perceptual noise. our estimates of noise might be wrong. in particular, we assume the both temporal cues (VOT and vowel duration) are subject to identical and independent noise. 2) our estimates of category variance are based on recordings that contain a variety of phonetic contexts, whereas listeners in our stimuli only experienced one type of context /i/. if listeners normalize cues based on phonetic contexts (as is often assumed) estimates based on unnormalized cues might over-estimate category variance. Both 1) and 2) would explain under-estimation of slopes since more variability -> smaller slope. But  -->

# General discussion
Landmark studies within DL or LGPL/VGPL paradigms have demonstrated that listeners' interpretation of speech changes in response to the phonetic properties of the speech input. These changes have been found to be qualitatively compatible with theories of adaptive speech perception. Few studies, however, have tested predictions concerning the cumulative and incremental process of adaptation and how the input is integrated with listeners' prior expectations. This study brings those predictions into sharper focus with a novel design that probed listeners categorisation behaviour before exposure and in regular intervals during exposure to the input. In addition, we have quantified listeners' incremental change relative to the predicted changes by an idealized listener who has fully learned the exposure distribution to investigate how far listeners are willing to move from their prior beliefs. 

Broadly, we can summarise the behavioural patterns we found in five main points: the first is that listeners changed their categorization behaviour in the direction of the exposure talker's distributional statistics (prediction 2b); Second, listeners changed their categorization in an incremental fashion. Third, adaptive changes were front-loaded, that is, the bulk of the total amount of shift in categorization happened very early and rapidly. Fourth, listeners did not converge fully on the ideal category boundary -- adaptation appears to be constrained. Finally, the degree of constraint depended on where the exposure distribution was placed relative to listeners' prior expectations of the test talker's cue realisations (as indicated by their pre-exposure categorisations). The latter two observations point towards a more complex prior-constrained feature of adaptive speech perception which current speech perception models are unable to account for. [*Current IA models have priors to calibrate pace of adaptation but here are other prior knowledge constraining adaptation that is not parameterised in the model*]

## Adaptation to shifted talker distributions is rapid
Like previous studies on accent adaptation, LGPL, and VGPL we find rapid adaptation to the exposure input. In fewer than 48 trials (taking only the unlabelled trials into account) the three exposure conditions significantly diverged from their identical categorisation functions pre-exposure towards the direction predicted by their respective exposure distributions. As far as DL paradigms are concerned, this is a novel finding because of the convention of assessing listener categorisation only after hundreds of exposure trials [@clayards2008; @kleinschmidt-jaeger2016; @theodore-monto2019]. Unlike in LGPL and VGPL where exposure trials are made up of ambiguous phonetic cues located in a narrow acoustic space and presented in maximally informative contexts, DL exposure trials form full distributions from which listeners need to infer the category membership of each stimulus. The relatively low informativeness of DL engenders the notion that a large number of trials may be required in order for learning to take effect. We did not however find this to be the case. The pace of adaptation (24 labelled trials) we observe in the second test block is comparable to that of LGPL studies which have reported between 4 and 20 labelled exposure trials for detectable differences between groups [@liu-jaeger2018; @cummings-theodore2023; @tzeng2021; @luthra2021]. The effects we report here are however not entirely comparable to LGPL or VGPL studies due to the difference in the scope of behavioural change evaluated post-exposure. Post-exposure categorisation in LGPL paradigms are made along a continuum of steps of ambiguous stimuli selected by the experimenter. LGPL effects thus reflect perceptual changes with respect to stimuli located in a region previously judged to be ambiguous unlike here where we find a wholesale shift along the actual cue continuum. 

<!-- ## Does labelling quicken the pace of adaptation? -->
<!-- We did not design the study with a strong hypothesis about labelling given that previous studies found no effect of labelling on DL [@kleinschmidt2015] while studies in LGPL found that disambiguating labels were critical for phonetic adaptation [@norris2003]. What remains unclear is whether labelling could be effective in the earliest moments of exposure particularly for extremely shifted conditions which would presumably be the most challenging for listeners to adapt to. Because we planned for very short blocks of exposure, including labelled trials hedged our position in the event that labelling facilitates quicker DL. This would not interfere with our main experiment goals nor its ecological validity since real-life encounters would present a listener with both labelled and unlabelled input. Although this study does not provide us with conclusive evidence on the effects of labelling on DL, a future study similar in design to the present one, should test how the presence of labelling or the type of labelling could affect the pace of DL. -->

## Does adaptation proceed in an incremental and cumulative manner?
A more challenging/pertinent question we have sought to investigate is whether adaptive speech perception proceeds in proportion to the amount of recent evidence. To some extent, past studies [@kleinschmidt-jaeger2015; @kleinschmidt-jaeger2011] have shown that to be the case. To reiterate an earlier point however, prior evidence were obtained under paradigms that employ a limited range of stimuli and not with comprehensive phonetic distributions. The pattern of change we found with our exposure stimuli which covers the full extent of a talker's /d/s and /t/s qualitatively supports the prediction of incrementality. However, we also found several complexities in how the different groups responded as they progressively received more input which warrant deeper consideration.  
  
The +40 condition is where we saw the greatest degree of shift in listener categorisations as well as the strongest evidence for incremental adaptation which certain Bayesian models of inference predict [@kleinschmidt-jaeger2015]. Evidence for incremental change was found to a lesser degree in the +10 and baseline conditions---both of which were left-shifted relative to pre-exposure categorization. A striking pattern shared between all conditions was the very rapid change in categorization after the first exposure block followed by diminished incremental changes in subsequent test blocks. Indeed, in all conditions a large proportion of the net total boundary shifts were already present afer the first third of exposure. This pattern of is consistent with models of Bayesian inference and those that emphasize error-based learning [@olejarczuk2018; @harmon2019; @davis-sohoglu2020; for demonstration, see @jaeger2019] where adaptation is observed in behavioural and neural responses as a result of effort to reduce the disparity between the expected stimulus and the heard stimulus. As the experiment progressed this disparity narrowed thus resulting in reduced learning in later test blocks. 

## Adaptation is tethered to the prior
But neither error-based learning nor Bayesian belief-updating models in their current forms, are sufficient to explain the marked slowdown and lack of convergence on the ideal boundary after the final exposure block.  
Under the conceptualisation of ideal adaptor models [@kleinschmidt-jaeger2015; @xie2023] the pace of adaptation or belief-updating is a function of confidence in prior expected values of the means and variances of the phonetic categories. The rapid change seen after the first exposure block indicates listeners have low confidence in their prior beliefs about the distributions and are therefore quick to adjust their categorisations---the shifted boundary should be dominated by the observations from the recent input rather than their prior beliefs. But weak prior beliefs under such a model of adaptation implicates sustained rapid shifts as the listener receives more evidence from the input which is not the result we found. For the +40 condition we even saw a retraction of the estimated boundary in test block 4. It is unclear whether this indicates that listeners had completely stopped adapting or if further shifts would have been observed with more exposure input. 
Adding more exposure trials alone is not likely to have a discernible impact on shifts as lack of convergence on ideal boundaries was also reported in [@kleinschmidt-jaeger2016] which was run with 222 trials. As discussed further in @kleinschmidt2020, all three conditions that were right-shifted from the estimated boundary of a typical talker produced boundaries that fell short of the ideal and the difference between the observed and ideal widened the more extreme the shift. Similarly, conditions which were left-shifted from the prior expected boundary also saw incomplete shifts. When these left-shifted distributions were extreme and included many tokens with negative VOT values the constraint on shifts was even stronger [@kleinschmidt2020 experiment 4]. 
Our results replicate those general findings. Among the left-shifted conditions, the further the exposure distribution from the prior, the lower the proportion of boundary shift. The ideal listener boundaries for the baseline and +40 conditions particularly were almost equidistant from the prior in opposite directions (+21ms vs. -18ms relative to the prior) but boundary changes in the baseline condition vascillated within a very tight range, achieving at most about a fifth of the total distance which was half the proportion achieved by the +40 condition. This asymmetry is best explained when taking into account listener prior beliefs. That listeners in the +40 conditioned moved their boundaries more freely corresponds to the distribution of /t/ tokens in encountered speech. Figure \@ref(fig:exposure-means-database-matrix-plot) shows the widely distributed VOT values for /t/ across two different speech styles indicating that listeners are likely to have encountered a wide range of /t/ tokens in their lifetime. In contrast, the distribution of /d/ tokens is much more narrow in variability. The asymmetry in the distribution of /t/ and /d/ tokens in the input is likely to have resulted in listeners having stronger constraints on movements of the left-shifted conditions since adapting would mean interpreting more /d/s as /t/s under prior expectations that /d/s are much more tightly clustered in the cue space. Furthermore, as the voiced category is shifted further leftwards more negative VOT tokens will be included in exposure. Pre-voicing in L1-US English while quite common, is not a primary cue for identifying the voiced category. While it could reinforce perception of a voiced category research on pre-voicing effects in true-voicing languages suggest it is unlikely to elicit gradient responses in the perception of the voiced category [@vanalphen-mcqueen2006; @vanalphen-smits2004; @clare-schertz2022]. This means that for the voiced category as VOT gets smaller and moves into the negative region there is less information to be gained from attending to the changes. This flip-side to the effect on perception as VOT increases makes sense because there is not a category to the left of the voiced one in a dual-contrast langauge (it's /d/s all the way down). 

Constrained adaptation should not be surprising since the need for perception to strike a balance between stability and flexibility has long been recognised. Constrained adaption is a logical result of a rational perceiver.






 + discuss rapid adaptation. link to findings from LGPL and VGPL [cummings-theodore; lj18,19]
 + discuss fast-then-slow adaptation. link to findings in VGPL [kj11, 12, K20] 
 + discuss other evidence for constraints in DL work [kj16; k20], potentially also limits in vroomen 07, kj12 though these are harder to compare.

 
 + discuss consequences of findings for other accounts (decision-making; normalization)

 
 + could some form of moving window with historical decay explain the findings? On the one hand if the moving window is very small, that would not explain why we do see some *cumulative* changes across blocks (window must be at least 48 + 12 = 60 trials). on the other hand, the qualitative changes in the PSEs and slopes suggest that 12 trials can be enough to change some aspects of the categorisation function. it's thus *possible* that something that ways recent input much more strongly but also considers less recent input beyond 48 trials might explain the overall pattern.
 
<!-- TO DO: take note to make test stimuli relative to exposure stims in your next experiment? -->
 
 + discuss potential that observed adaptation maximizes accuracy under the choice rule. use psychometric function fit during unlabeled exposure trials to calculate *accuracy* (not likelihood) on labeled trials under criterion and under proportional matching decision rules. compare against accuracy if ideal observers categorization functions are used instead.




