<!-- Do NOT knit this document. It is part of a larger document. Instead knit the main document (my-apa-formatted-article) -->

<!-- TO DO: discuss reasons for slope discrepancies? 1) slope changes with perceptual noise. our estimates of noise might be wrong. in particular, we assume the both temporal cues (VOT and vowel duration) are subject to identical and independent noise. 2) our estimates of category variance are based on recordings that contain a variety of phonetic contexts, whereas listeners in our stimuli only experienced one type of context /i/. if listeners normalize cues based on phonetic contexts (as is often assumed) estimates based on unnormalized cues might over-estimate category variance. Both 1) and 2) would explain under-estimation of slopes since more variability -> smaller slope. But  -->

<!-- TO DO: if we integrate model, cite Martin; yarkoni-westfall2017 -->

<!-- discuss: failure of predicting slopes, possible reasons. mostly in SI but should be acknowledge in GD -->

# General discussion
Over the last 20+ years, landmark studies in adaptive speech perception have demonstrated that listeners' interpretation of speech is not static. Instead, it can change with recent exposure, accommodating differences in pronunciation across talkers. Even a single session of exposure can be sufficient to substantially reduce losses in processing speed or accuracy that listeners might initially experience when exposed to unfamiliar speech patterns. Research on accent adaptation [AA, @eisner2013; @schertz2016; @xie2017] and perceptual recalibration [VGPL/LGPL, @eisner-mcqueen2005; @kraljic-samuel2006; @kurumada2018; @norris2003; @reinisch-holt2014; @vroomen2007] has found that this flexibility is achieved through changes in listeners' *categorization functions*---the mapping from acoustic or phonetic cues to the phonological categories that form the input to spoken language understanding. These changes in listeners' categorization functions seem to depend on the statistics of the exposure input in ways qualitatively expected under the hypothesis that adaptive speech perception involves distributional learning [DL, @clayards2008; @idemaru-holt2011; @idemaru-holt2020; @kleinschmidt-jaeger2015; @kleinschmidt2020; @mcmurray-jongman2011; @nixon2016; @theodore-monto2019].

Despite these advances, little is known about the incremental unfolding of adaptive speech perception. Recent reviews have identified this as an area in need of further investigation [@xie2023; @OTHERS], arguing that a better understanding of incremental adaptation will facilitate stronger tests of existing theories. In particular, it is unclear how listeners' categorization functions change incrementally with exposure, and how those changes depend on the amount and cumulative distribution of phonetic evidence in the input listeners have experienced so far. The present study modified traditional distributional learning paradigm to investigate these questions. We found that listeners' categorization functions changed incrementally with exposure, and that the direction and magnitude of that change depended on listeners' prior expectations based on previously experienced speech input from other talkers (Prediction 1 from the introduction), and both the amount and distribution of phonetic evidence in the exposure input from the unfamiliar talker (Predictions 2a and 2b, respectively).

OVERVIEW HERE. 

Many of the insights that we discuss below were facilitated by a single Bayesian psychometric mixed-effects model. Psychometric models have long been used in research on, for example, visual decision-making [e.g., @prins2011; @wichman-hill2001; @OTHER-RECENT-REVIEW]. Some of the advantages of Bayesian psychometric models are discussed in @prinsXXX. Here, we used a mixed-effects version of such a model in order to fit a single model across all participants, while correcting for participant-specific lapse rates and while modeling block-by-block changes in participants' psychometric functions. While such models used to require expensive software, they can now be fit in freely available software [R, @r; @stan; @rstan; @rstanarm; @brms]. We hope that the present study will encourage other researchers to use similar models in their own research.

## How much evidence is needed for adaptive speech perception?
We found significant shifts in listeners' categorization function even after the briefest exposure tested. Exposure to 24 tokens each of shifted /d/ and /t/ was sufficient to significantly change how listeners interpreted subsequent inputs. Of note, only half of these exposure tokens labeled the intended category, the other half did not. Even when trials were labeled, labeling was indirect rather than through explicit feedback: on labeled trials, the two response options listeners saw both had the same onset stop (e.g., "din" and "dill"). Previous distributional learning studies have assessed exposure effects after *much* longer exposures, typically hundreds of trials [e.g., 192 trials in @harmon2019; 200 in @idemaru-holt2011; 228 in @clayards2008; @kleinschmidt-jaeger2016; 236 in @theodore-monto2019; 456 in @nixon2016]. The present results demonstrate that a fraction of the amount of exposure employed in previous studies is sufficient to elicit changes in listeners' categorization behavior.

This result also bears on ongoing discussions as to whether the type of adaptive changes observed in AA and LGPL/VGPL paradigms could plausibly originate in the same mechanisms as those observed in DL paradigms like in the present study [@bradlow-bent2008; @baese-berk2018; @zheng-samuel2020; @xie2023]. A number of studies have now demonstrated improvements in the speed or accuracy of speech perception after relatively short exposure to an unfamiliar L2-accented talker [@bradlow2023; @clarke-garrett2004; @xie2018; @xie2021]. For example, Xie and colleagues [-@xie2018] found improvements in both the speed and accuracy of cross-modal priming after exposure to only 18 sentences from an L2-accented talker---the shortest tested exposure we are aware of [see also @clarke-garrett2004]. Other AA work has directly assessed changes in the categorization function. For example, @xie2017 found changes in listeners categorization behavior after exposure to only 30 critical L2-accented words. The directionality of these changes was consistent with distributional learning accounts of adaptive speech perception. Together with evidence from additional experiments, Xie and colleagues concluded that "listeners dynamically update their own cue-weighting functions during rapid phonetic adaptation to foreign accents, and critically over much shorter time span[s] than shown in previous studies of second language phoneme learning". By demonstrating that DL paradigms can elicit qualitatively similar changes with similarly little exposure, the present study lends further plausibility the hypothesis that these changes are driven by the same underlying mechanisms.

Some experiments on LGPL and VGPL have demonstrated effects after even less exposure, with significant changes in listeners' categorization responses after as few as four exposures to visually or lexically labeled phonetically tokens [@cummings-theodore2023; @kleinschmidt-jaeger2011; @kleinschmidt-jaeger2012; @liu-jaeger2018; @liu-jaeger2019; @vroomen2007]. Our findings leave open whether DL paradigms can elicit similarly rapid effects. In comparing findings across the two types of paradigms, future work should keep in mind that DL and LGPL/VGPL paradigms differ in the amount of information conveyed by each exposure token. LGPL/VGPL paradigms typically employ exposure stimuli that a) are labeled and b) auditorily maximally ambiguous---falling between the two categories that the experiment focuses on. Distributional learning accounts predict that such stimuli should be highly informative, leading to comparatively large changes in categorization behavior. This is in line with recent findings: when stimuli in LGPL/VGPL experiments are shifted less than to the point of maximal auditory ambiguity, listeners exhibit smaller shifts in categorization behavior [@babel2019; @kleinschmidt-jaeger2012; @tzeng2021; for a numerical but non-significant replication, see also @cummings-theodore2023]. In contrast, DL paradigms a) typically employ only unlabeled stimuli [@clayards2008] or a mixture of unlabeled and labeled stimuli [e.g., @kleinschmidt-jaeger2016 and the present paradigm], and b) reflect a *distribution* of phonetic properties---ranging from more to less expected under listeners' prior expectations. This makes the speech inputs in DL paradigms more similar to what one would expect during exposure to natural accents and other cross-talker differences. But it also makes exposure tokens in DL experiments, on average, considerably less informative than in an LGPL/VGPL experiment. Future work that aims to compare the speed of adaptive speech perception across these two paradigms should thus do so *relative to the amount of information conveyed by each exposure*. 

<!-- TO DO: *could* add a figure here showing how the PSE would be predicted to change for our experiment under a certain kappa, nu combination, and compare that against PSE changes for the same data when all /d/ stimuli are set to *prior* PSE value and all /t/ stimuli are set to prior /t/ (or vice versa) -->

## Incremental adaptation based on the amount and distribution of phonetic evidence (Predictions 1 and 2a,b)
To the best of our knowledge, the present study is the first to assess the joint effects of prior and recent exposure gradiently unfold with increasing exposure, predictions 1 and 2a,b described in the introduction. While most contemporary theories of adaptive speech perception share these qualitative predictions, relatively few previous experiment have investigated how listeners' categorization functions change with continued exposure to a phonetic distribution. The majority of studies on AA, for example, continue to employ the popular exposure-test design. In this design, different groups of listeners are exposed to different speech input. The effects of that exposure are then assessed by a single post-exposure test, which typically is held identical across the groups. This design is well suited to assess the qualitative effects of exposure to different types of speech input---for example, whether familiarization with a talker's speech generally leads to improved speech recognition---but it shed's little light on *how* the phonetic properties of the speech input shape changes in listeners' perception. If repeated testing has been been employed in research on AA, it tended to be after considerably longer exposure [e.g., testing on different days, @REFs; but see @kurumada-xie2024]. The same largely holds for previous DL studies, which either employed a single batch test following exposure [e.g., @clayards2008; @idemaru-holt2020; @nixon2016; @schertz-REF] or repeated testing over the course of multiple days [e.g., @mcclelland1999]. 

One reason for the relative scarcity of studies on incremental changes during the early stages of exposure might originate in the focus of earlier research. As mentioned in the introduction, the pioneering generation of studies focused on the question of *whether* adaptation is observed, and *under what conditions* [for review, see @cummings-theodore2023]. Now that the existence of adaptive changes in speech perception is no longer in question, paradigms that inform and constrain the functional relation between exposure inputs and changes in listeners' perception have gained in importance. At the minimum, this includes a clearer understanding of how the amount and statistics of the exposure input drive changes in speech perception. Stronger tests of competing computational models will require such data. In a recent review of the field, @xie2023 demonstrated that the signature findings of some of the most popular paradigms in adaptive speech perception do not distinguish between radically different theoretical accounts: qualitative improvements in speech recognition can be explained by mechanisms ranging from early pre-linguistic perceptual normalization, changes in the representations of phonetic categories, or upstream changes in decision-making. Other recent reviews, too, have highlighted the need to develop stronger theories, sufficiently specific to be implemented as predictive computational models [@guest-martin2021; @kleinschmidt-jaeger2015; @norris2017; @yarkoni-westfall2017]. Effective comparisons of these theories will require quantitative data sets that constrain the way in which listeners' categorization behavior changes depending on the amount and nature of the input.

A second reason for the relative scarcity of research on incremental changes in speech perception might be that repeated testing comes with its own unique challenges. For example, if test tokens are sampled from natural accents---the most common approach in AA research---these tokens can themselves contain information about the target accent, thereby masking exposure effects [for a particularly clear demonstration, see @kurumada-xie2024]. Even for paradigm that employ synthesized stimuli, or otherwise control the informativity of test tokens [e.g., @chodroff], repeated testing can come with challenges. There is now evidence that repeated testing over unlabeled test continua that uniformly span the relevant phonetic space can reduce the effects of exposure [@cummings202X; @kraljic-samuel200X; @liu-jaeger2018; @liu-jaeger2019; @REF-theodore]. This is compatible with some distributional learning accounts of adaptive speech perception [for discussion, see @kleinschmidt-jaeger2015]: if the same learning mechanisms that operate during labeled and unlabeled exposure trials continue to operate during unlabeled test trials, the unexpected uniform distribution over the VOT continuum during test blocks should begin to undo the effects of preceding exposure.^[The specific predictions depend on the---as of yet unknown---way listeners adapt to unlabeled speech inputs [for an initial comparisons of several candidate models for unsupervised adaptation, see @yan-jaeger2018]. Additionally, it is possible that adaptation to unlabeled inputs involves different mechanisms than adaptation to labeled trials.] In the present study, we replicated this effect of repeated testing for the final three test blocks. For research on incremental adaptation this implies a methodological tension between longer test phases, which provide researchers with more observations, and the risk of diminishing effects [see also @liu-jaeger2018].

In the present study, we used a repeated exposure-test design to assess incremental changes in listeners' categorization functions from pre-exposure onward. We found that that listeners' categorization function shifted with increasing exposure to shifted phonetic distributions. The direction and magnitude of these shifts developed gradiently and were qualitatively consistent with the predictions of distributional learning accounts [e.g., @apfelbaum-mcmurray2015; @harmon2019; @johnson1997; @kleinschmidt-jaeger2015; @magnuson2020; @assmann-nearey2007; @sohoglu-davis2016; @xie2023]. This was the case both for shifts in listeners' categorization function relative to other exposure conditions (Table \@ref(tab:hypothesis-table-simple-effects-condition)) and for shifts in listeners' categorization function relative to their pre-exposure categorization function (Table \@ref(tab:hypothesis-table-simple-effects-block)). In both cases, every single test we conducted went in the direction predicted by distributional learning theories. 

Specifically, the inclusion of a pre-exposure test in our study made it possible to assess prediction (1)---that shifts in listeners' categorization function should depend on how the exposure distributions *relative to listeners' relevant prior experiences*. This prediction received support both from the fact that listeners' responses prior to exposure were well approximated based on a database of /d/ and /t/ productions, and from the fact that the direction of changes in listeners' PSEs *relative to pre-exposure* was predicted by the direction of the shift in /d/ and /t/ distributions relative to their distributions in prior experience (Figure \@ref(fig:exposure-means-database-matrix-plot)). 

Prediction (2a)---that the magnitude of changes in listeners' categorization function should gradiently increase with the *amount* of exposure---received support from the comparisons across blocks: increasing exposure consistently yielded additional shifts in listeners' PSE. This replicates in a DL paradigm recent findings from VGPL/LGPL experiments [@cummings-theodore2023; @kleinschmidt-jaeger2012; @liu-jaeger2018; @liu-jaeger2019; @vroomen2007]. In a particular careful study, Cummings and Theodore compared shifts in categorization function between groups of listeners after exposure to 1, 4, 10, or 20 lexically labeled shifted /s/ or /sh/ tokens (each matched by an equal number of unshifted tokens from the opposite category). Shifts in listeners' categorization functions increased with the number of exposure to tokens, and did so significantly for all comparisons, except but the comparison between 4 and 1 exposures. @vroomen2007 found similarly increasing shifts in categorization functions *within* participants, comparing the effects of 1, 2, 4, ..., 32 exposures to visually labeled shifted tokens [see also @kleinschmidt-jaeger2012].^[With increasing exposure, the direction of shift begins to reverse [returning to baseline after 128-256 exposures, @kleinschmidt2011; @vroomen2007] and can even change directional altogether, depending on the degree of the shift [@kleinschmidt-jaeger2012]. Later work showed that this reversal is accounted for by distributional learning models, and caused by the fact that the VGPL paradigm presents the exact same stimulus on each exposure trial [@kleinschmidt-jaeger2015].] The present study demonstrated similarly gradient effects with increasing exposure to a mixture of labeled and unlabeled exposure tokens that were randomly sampled from a *distribution* of phonetic tokens, thereby more closely resembling the situation listeners would experience during everyday speech perception. This aspect of our results thus adds to a growing number of similarities in the findings between LGPL/VGPL and DL paradigms, as expected under the hypothesis that changes observed in both paradigms originate in the same underlying mechanisms [see discussions in @kleinschmidt2015; @zheng-samuel2021; @xie2023].

Finally, prediction (2b)---that the direction and magnitude of changes in listeners' categorization function should depend on the *phonetic distribution* of the exposure input---received support from the within-block comparisons across exposure conditions: the direction of the shift of the /d/ and /t/ category means in the exposure input correctly predicted the relative ordering of listeners' PSEs in Test 1-4, and shifts in category means of larger magnitude (+40 vs. baseline compared to +10 vs. baseline) yielded larger shifts in listeners' PSE. This extends the findings from previous DL studies to demonstrate gradient incremental adaptation towards the exposure distribution. Going beyond this qualitative test of prediction (2b), post-hoc tests presented some initial steps towards stronger quantitative tests. One post-hoc test found some---at best moderate---evidence that the speed of incremental changes in listeners' PSE decreased with increasing exposure: the same amount and distribution of phonetic evidence yielded smaller *additional* changes in listeners' PSE when listeners, the more exposure blocks listeners had already experienced. These 'diminishing returns' resemble similar findings detected in post-hoc analyses presented in a recent study by @kleinschmidt2020. XXX-DESCRIBE HERE.<!-- TO DO: add description of Dave's study; incl. absence of incremental testing, and the way it was 'hacked'/approximated in the modeling in section XXX of his ms--> Such diminishing returns of exposure are explicitly predicted only by some distributional learning models [e.g., error-based models, @davis-sohoglu2020; @sohoglu-davis2016; Bayesian ideal adaptors, @kleinschmidt-jaeger2015; @kleinschmidt-jaeger2016]. If replicated in future work, this would raise the question under what conditions similar predictions follow from other distributional learning accounts [e.g., C-CuRE normalization, @mcmurray-jongman2011; exemplar models, @johnson1997; DNNs, @magnuson2020]. If, on the other hand, future tests fail to replicate these findings, this would be a serious problem for models that predict them.

If replicated, it would be tempting to also interpret these 'diminishing returns' as evidence that listeners have converged against the exposure distributions in the input---i.e., that adaptation has successfully completed. In particular, the hypothesis tests in Table \@ref(tab:hypothesis-table-simple-effects-block) suggested that there was at best anecdotal evidence that the final exposure block had any additional effect---including in the two conditions with the largest shifts. However, our findings suggests that this does *not* mean that listeners had successfully learned all required information about the unfamiliar talker: compared to PSEs predicted for idealized learners that have fully learned the exposure distributions, listeners' exhibited substantially smaller shifts in PSEs. We discuss possible explanations of this observation next.


## Constraints on (the early moments of) adaptive speech perception?

 Why constrainted? Why asymmetric?

+ regularizing priors pulling ...?
+ intermittend test undoing effects even within 12 trials? if so, that's interesting. future work can test this by ... 
 + could some form of moving window with historical decay explain the findings? On the one hand if the moving window is very small, that would not explain why we do see some *cumulative* changes across blocks (window must be at least 48 + 12 = 60 trials). on the other hand, the qualitative changes in the PSEs and slopes suggest that 12 trials can be enough to change some aspects of the categorisation function. it's thus *possible* that something that ways recent input much more strongly but also considers less recent input beyond 48 trials might explain the overall pattern.
 + COULD (but maybe not?) discuss potential that observed adaptation maximizes accuracy under the choice rule. use psychometric function fit during unlabeled exposure trials to calculate *accuracy* (not likelihood) on labeled trials under criterion and under proportional matching decision rules. compare against accuracy if ideal observers categorization functions are used instead.

+ limitations in incremental adaptation (that might potentially be overcome with longer-term exposure, cf. discussion in xie2023)

All of these tests were facilitated by the use of incremental testing, which thereby facilitated stronger---though still qualitative---tests of theories of adaptive speech perception. The use of incremental testing also revealed 

## Constraints on rapid adaptation?
But neither error-based learning nor Bayesian belief-updating models in their current forms, are sufficient to explain the marked slowdown and lack of convergence on the ideal boundary after the final exposure block.  
Under the conceptualisation of ideal adaptor models [@kleinschmidt-jaeger2015; @xie2023] the pace of adaptation or belief-updating is a function of confidence in prior expected values of the means and variances of the phonetic categories. The rapid change seen after the first exposure block indicates listeners have low confidence in their prior beliefs about the distributions and are therefore quick to adjust their categorisations---the shifted boundary should be dominated by the observations from the recent input rather than their prior beliefs. But weak prior beliefs under such a model of adaptation implicates sustained rapid shifts as the listener receives more evidence from the input which is not the result we found. For the +40 condition we even saw a retraction of the estimated boundary in test block 4. It is unclear whether this indicates that listeners had completely stopped adapting or if further shifts would have been observed with more exposure input. 

Adding more exposure trials alone is not likely to have a discernible impact on shifts as lack of convergence on ideal boundaries was also reported in [@kleinschmidt-jaeger2016] which was run with 222 trials. As discussed further in @kleinschmidt2020, all three conditions that were right-shifted from the estimated boundary of a typical talker produced boundaries that fell short of the ideal and the difference between the observed and ideal widened the more extreme the shift. Similarly, conditions which were left-shifted from the prior expected boundary also saw incomplete shifts. When these left-shifted distributions were extreme and included many tokens with negative VOT values the constraint on shifts was even stronger [@kleinschmidt2020 experiment 4]. 
Our results replicate those general findings. Among the left-shifted conditions, the further the exposure distribution from the prior, the lower the proportion of boundary shift. The ideal listener boundaries for the baseline and +40 conditions particularly were almost equidistant from the prior in opposite directions (+21ms vs. -18ms relative to the prior) but boundary changes in the baseline condition vascillated within a very tight range, achieving at most about a fifth of the total distance which was half the proportion achieved by the +40 condition. This asymmetry is best explained when taking into account listener prior beliefs. That listeners in the +40 conditioned moved their boundaries more freely corresponds to the distribution of /t/ tokens in encountered speech. Figure \@ref(fig:exposure-means-database-matrix-plot) shows the widely distributed VOT values for /t/ across two different speech styles indicating that listeners are likely to have encountered a wide range of /t/ tokens in their lifetime. In contrast, the distribution of /d/ tokens is much more narrow in variability. The asymmetry in the distribution of /t/ and /d/ tokens in the input is likely to have resulted in listeners having stronger constraints on movements of the left-shifted conditions since adapting would mean interpreting more /d/s as /t/s under prior expectations that /d/s are much more tightly clustered in the cue space. Furthermore, as the voiced category is shifted further leftwards more negative VOT tokens will be included in exposure. Pre-voicing in L1-US English while quite common, is not a primary cue for identifying the voiced category. While it could reinforce perception of a voiced category research on pre-voicing effects in true-voicing languages suggest it is unlikely to elicit gradient responses in the perception of the voiced category [@vanalphen-mcqueen2006; @vanalphen-smits2004; @clare-schertz2022]. This means that for the voiced category as VOT gets smaller and moves into the negative region there is less information to be gained from attending to the changes. This flip-side to the effect on perception as VOT increases makes sense because there is not a category to the left of the voiced one in a dual-contrast langauge (it's /d/s all the way down). 

Constrained adaptation should not be surprising since the need for perception to strike a balance between stability and flexibility has long been recognised. Constrained adaption is a logical result of a rational perceiver.

# Conclusions




