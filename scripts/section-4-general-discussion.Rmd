<!-- Do NOT knit this document. It is part of a larger document. Instead knit the main document (my-apa-formatted-article) -->

# General discussion
 
Landmark studies employing DL and LGPL and VGPL have qualitatively demonstrated how listeners' speech categorisation change in response to the phonetic properties of the input, providing abundant evidence that support broad claims made by theories for adaptive speech perception.  Few however, have tested the predictions concerning the cumulative and incremental process of adaptation and how the input is integrated with listeners' prior expectations. This study brings those predictions into sharper focus with a novel design that probed listeners categorisation behaviour before exposure and in regular intervals during exposure to the input. In addition, we have quantified listeners' incremental change relative to the predicted changes by an idealized listener who has fully learned the exposure distribution to investigate how far listeners are willing to move from their prior beliefs. 

Broadly, we can summarise the behavioural patterns we found in five main points: the first is that listeners changed their categorization behaviour in the direction of the exposure talker's distributional statistics (prediction 2b); Second, listeners changed their categorization in an incremental fashion. Third, adaptive changes were front-loaded, that is, the bulk of the total amount of shift in categorization happened very early and rapidly. Fourth, listeners did not converge fully on the ideal category boundary -- adaptation appears to be constrained. Finally, the degree of constraint depended on where the exposure distribution was placed relative to listeners' prior expectations of the test talker's cue realisations (as indicated by their pre-exposure categorisations). The latter two observations point towards a more complex prior-constrained feature of adaptive speech perception which current speech perception models are unable to account for. [CURRENT IA MODELS HAVE PRIORS TO CALIBRATE PACE OF ADAPTATION BUT THERE ARE OTHER PRIOR KNOWLEDGE CONSTRAINING ADAPTATION THAT IS NOT PARAMETERISED IN THE MODEL]

## Adaptation to shifted talker distributions is rapid
Like previous studies on accent adaptation, LGPL, and VGPL we find rapid adaptation to the exposure input. In fewer than 48 trials (taking only the unlabelled trials into account) the three exposure conditions significantly diverged from their identical categorisation functions pre-exposure towards the direction predicted by their respective exposure distributions. As far as DL paradigms are concerned, this is a novel finding because of the convention of assessing listener categorisation only after hundreds of exposure trials [@clayards2008; @kleinschmidt-jaeger2016; @theodore-monto2019]. Unlike in LGPL and VGPL where exposure trials are made up of ambiguous phonetic cues located in a narrow acoustic space and presented in maximally informative contexts, DL exposure trials form full distributions from which listeners need to infer the category membership of each stimulus. The relatively low informativeness of DL engenders the notion that a large number of trials may be required in order for learning to take effect. We did not however find this to be the case. The pace of adaptation (24 labelled trials) we observe in the second test block is comparable to that of LGPL studies which have reported between 4 and 20 labelled exposure trials for detectable differences between groups [@liu-jaeger2018; @cummings-theodore2023; @tzeng2021; @luthra2021]. The effects we report here are however not entirely comparable to LGPL or VGPL studies due to the difference in the scope of behavioural change evaluated post-exposure. Post-exposure categorisation in LGPL paradigms are made along a continuum of steps of ambiguous stimuli selected by the experimenter. LGPL effects thus reflect perceptual changes with respect to stimuli located in a region previously judged to be ambiguous unlike here where we find a wholesale shift along the actual cue continuum. 

## Does labelling quicken the pace of adaptation?
We did not design the study with a strong hypothesis about labelling given that previous studies found no effect of labelling on DL [@kleinschmidt2015] while studies in LGPL found that disambiguating labels were critical for phonetic adaptation [@norris2003]. What remains unclear is whether labelling could be effective in the earliest moments of exposure particularly for extremely shifted conditions which would presumably be the most challenging for listeners to adapt to. Because we planned for very short blocks of exposure, including labelled trials hedged our position in the event that labelling facilitates quicker DL. This would not interfere with our main experiment goals nor its ecological validity since real-life encounters would present a listener with both labelled and unlabelled input. Although this study does not provide us with conclusive evidence on the effects of labelling on DL, a future study similar in design to the present one, should test how the presence of labelling or the type of labelling could affect the pace of DL.

## Does adaptation proceed in an incremental and cumulative manner?
A more challenging/pertinent question we have sought to investigate is whether adaptive speech perception proceeds in proportion to the amount of recent evidence. To some extent, past studies [@kleinschmidt-jaeger2015; @kleinschmidt-jaeger2011] have shown that to be the case. To reiterate an earlier point however, prior evidence were obtained under paradigms that employ a limited range of stimuli and not with comprehensive phonetic distributions. The pattern of change we found with our exposure stimuli which covers the full extent of a talker's /d/s and /t/s qualitatively supports the prediction of incrementality. However, we also found several complexities in how the different groups responded as they progressively received more input which warrant deeper consideration.  
  
The +40 condition is where we saw the greatest degree of shift in listener categorisations as well as the strongest evidence for incremental adaptation which certain Bayesian models of inference predict [@kleinschmidt-jaeger2015]. Evidence for incremental change was found to a lesser degree in the +10 and baseline conditions -- both of which were left-shifted relative to pre-exposure categorization. A striking pattern shared between all conditions was the very rapid change in categorization after the first exposure block followed by diminished incremental changes in subsequent test blocks. Indeed, in all conditions a large proportion of the net total boundary shifts took effect after the first third of exposure. This pattern of is consistent with models of Bayesian inference and those that emphasize error-based learning [@olejarczuk2018; @harmon2019; @davis-sohoglu2020; for demonstration, see @jaeger2019] where adaptation is observed in behavioural and neural responses as a result of effort to reduce the disparity between the expected stimulus and the heard stimulus. As the experiment progressed this disparity narrowed thus resulting in reduced learning in later test blocks. 

But neither error-based learning nor Bayesian belief-updating models in their current forms, are sufficient to explain the marked slowdown and lack of convergence on the ideal boundary after the final exposure block.  
Under the conceptualisation of ideal adaptor models [@kleinschmidt-jaeger2015; @xie2023] the pace of adaptation or belief-updating is a function of confidence in prior expected values of the means and variances of the phonetic categories. The rapid change seen after the first exposure block indicates listeners have low confidence in their prior beliefs about the distributions and are therefore quick to adjust their categorisations -- the shifted boundary should be dominated by the observations from the recent input rather than their prior beliefs. But weak prior beliefs under such a model of adaptation implicates sustained rapid shifts as the listener receives more evidence from the input which is not the result we found. For the +40 condition we even saw a retraction of the estimated boundary in test block 4. It is unclear whether this indicates that listeners had completely stopped adapting or if further shifts would have been observed with more exposure input. *COMMENT*: I need help thinking this through. what would an error-driven model predict with a fast/slow learning rate? Is this worth discussing? If so, my thinking is that maybe we could look at how much error was there left in test block 2 and test block 3 (can this be estimated with the code in section 3 on surprisal right now it's just the overall mean surprisal at test) because the error-driven proponents would say that as long as there is error there is impetus to learn. But our results don't show that they wanted to keep moving. The other point that could be considered is that in some of those error-driven models, the capital lambda parameter determines the learning rate. When this is very slow, the representation from distributional learning more accurately reflects the frequency of the exposure distribution. But if the learning rate was fast then the mean categorisation converges on a log-transformed representation of the input distribution. Maybe it's not so relevant to spend too much time on (since the error-driven models are supposed to be in same class as Bayesian updating models) but this is what I read from @olejarczuk2018 *END OF COMMENT*

Lack of convergence on ideal boundaries was also reported in [@kleinschmidt-jaeger2016]. As discussed further in @kleinschmidt2020, all three conditions that were right-shifted from the estimated boundary of a typical talker (inferred prior) produced boundaries that fell short of the ideal and the difference between the observed and ideal widened the more extreme the shift. Similarly, conditions which were left-shifted from the prior expected boundary also saw incomplete shifts. When these left-shifted distributions were extreme and included many tokens with  negative VOT values the constraint on shifts was even stronger [@kleinschmidt2020 experiment 4]. 
Our results appear to replicate those general findings. Across conditions, the further the exposure distribution was left-shifted, the lower the propensity for listeners to shift their categorisation boundaries. The ideal listener boundaries for the baseline and +40 conditions particularly, were almost equidistant from the prior in opposite directions (+21ms vs. -18ms relative to the prior) but boundary changes in the baseline condition vascillated within a very tight range, achieving at most about a fifth of the total distance which was half the proportion achieved by the +40 condition. This asymmetry is best explained when taking into account listener prior beliefs. That listeners in the +40 conditioned moved their boundaries more freely corresponds to the distribution of /t/ tokens in encountered speech. Figure \@ref(fig:exposure-means-database-matrix-plot) shows the wide range of VOT values for /t/ across two different speech style indicating that listeners are likely to have encountered a wide range of /t/ tokens in their lifetime. In contrast, the distribution of /d/ tokens is much more constrained. The asymmetry in the distribution of /t/ and /d/ tokens in the input is likely to have resulted in listeners having stronger constraints on movements of the left-shifted conditions. Furthermore, as the voiced category is shifted further leftwards more negative VOT tokens will be included in exposure. Pre-voicing in L1-US English, while not exceedingly rare, is not a primary cue for identifying the voiced category. Nor does it seem to elicit gradient responses for category goodness [@REF]. *COMMENT* More discussion on voiced category distributions and how people treat it?



## Why do listeners not shift when distribution is shifted leftwards





 + discuss rapid adaptation. link to findings from LGPL and VGPL [cummings-theodore; lj18,19]
 + discuss fast-then-slow adaptation. link to findings in VGPL [kj11, 12, K20] 
 + discuss other evidence for constraints in DL work [kj16; k20], potentially also limits in vroomen 07, kj12 though these are harder to compare.

 
 + discuss consequences of findings for other accounts (decision-making; normalization)

 
 + could some form of moving window with historical decay explain the findings? On the one hand if the moving window is very small, that would not explain why we do see some *cumulative* changes across blocks (window must be at least 48 + 12 = 60 trials). on the other hand, the qualitative changes in the PSEs and slopes suggest that 12 trials can be enough to change some aspects of the categorisation function. it's thus *possible* that something that ways recent input much more strongly but also considers less recent input beyond 48 trials might explain the overall pattern.
 
<!-- TO DO: take note to make test stimuli relative to exposure stims in your next experiment? -->
 
 + discuss potential that observed adaptation maximizes accuracy under the choice rule. use psychometric function fit during unlabeled exposure trials to calculate *accuracy* (not likelihood) on labeled trials under criterion and under proportional matching decision rules. compare against accuracy if ideal observers categorization functions are used instead.




